{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af12f4c61ec00df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:13:00.973862Z",
     "start_time": "2024-04-25T18:13:00.964955Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练参数设定\n",
    "\n",
    "eta = 0.001  # 学习率\n",
    "gamma = 0.9  # 折扣因子\n",
    "capacity = 50  # 记忆体容量\n",
    "batch_size = 32  # 批次大小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbdec4079a25346",
   "metadata": {},
   "source": [
    "# 1 数据处理\n",
    "\n",
    "将数据分通道使用连续小波变换cwt进行处理，处理成每个类别的8通道数据\n",
    "\n",
    "## 处理过程\n",
    "\n",
    "读取文件，获得数据，整理数据格式\n",
    "\n",
    "设定计算必要的参数，分通道计算连续小波变换\n",
    "\n",
    "得到小波计算结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e143574fe79fbb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:27:44.605921Z",
     "start_time": "2024-04-25T03:59:01.881700Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pywt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpywt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrans\u001b[39m(csv_file):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    读取CSV文件，并应用连续小波变换\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    :param csv_file: 读取CSV文件的路径\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pywt'"
     ]
    }
   ],
   "source": [
    "# 分通道小波变换\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "\n",
    "\n",
    "def trans(csv_file):\n",
    "    \"\"\"\n",
    "    读取CSV文件，并应用连续小波变换\n",
    "    :param csv_file: 读取CSV文件的路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 数据获取\n",
    "    df = pd.read_csv(csv_file)  # 读取CSV文件\n",
    "    signal = df.iloc[:, :]  # 获取指定列的数据\n",
    "    length, channels = signal.shape  # 获取行数和列数\n",
    "    \n",
    "    # 假设采样频率为fs\n",
    "    fs = 1024  # 采样频率\n",
    "    dt = 1 / fs  # 采样间隔\n",
    "    widths = np.arange(1, 235)  # 定义尺度范围\n",
    "    \n",
    "    # 时频图像尺度数据\n",
    "    x = np.linspace(0, length * dt, length)\n",
    "    \n",
    "    # 初始化数据存储数组\n",
    "    coefficients = np.zeros((channels, len(widths), length))  # 小波变换系数\n",
    "    frequencies = np.zeros(len(widths))  # 小波变换频率\n",
    "\n",
    "    # 对每个频道进行小波变换\n",
    "    for i in range(0, channels):\n",
    "        signal_transed = signal.iloc[:, i]\n",
    "        print(f\"开始频道{i}的变换\")\n",
    "        coefficients[i, :, :], frequencies = pywt.cwt(signal_transed, widths, 'morl', dt)  # 使用morlet小波进行连续小波变换\n",
    "        print(f\"完成频道{i}的变换\")\n",
    "\n",
    "    return x, coefficients.astype(np.float32), frequencies\n",
    "\n",
    "# 数据文件列表\n",
    "\n",
    "files_20_0 = ['./data/gearset/Chipped_20_0.csv', './data/gearset/Health_20_0.csv', './data/gearset/Miss_20_0.csv', './data/gearset/Root_20_0.csv', './data/gearset/Surface_20_0.csv']\n",
    "\n",
    "files_30_2 = ['./data/gearset/Chipped_30_2.csv', './data/gearset/Health_30_2.csv', './data/gearset/Miss_30_2.csv', './data/gearset/Root_30_2.csv', './data/gearset/Surface_30_2.csv']\n",
    "\n",
    "# 处理开始\n",
    "files = files_30_2\n",
    "\n",
    "print(\"处理开始\")\n",
    "\n",
    "for file in files:\n",
    "    print(file, \"文件处理开始\")\n",
    "    \n",
    "    x_0, coe_0, freq_0 = trans(file)\n",
    "    \n",
    "    save_path = file.replace('data', 'dataset').replace('.csv', '.npy')\n",
    "    np.save(save_path, coe_0)\n",
    "    \n",
    "    print(file, \"文件处理完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba18f1f3649e55c",
   "metadata": {},
   "source": [
    "# 2 尝试建立DQN模型\n",
    "\n",
    "## 2’ 说明\n",
    "\n",
    "### 训练方案\n",
    "\n",
    "不采用有环境模型方式，改用读取数据+采样方式，通过采样来提供新的学习样本。\n",
    "\n",
    "状态：数据取样的一个批次\n",
    "\n",
    "动作：对于状态对应标签的判断（25种动作，包括改变和不改变）\n",
    "\n",
    "### 数据结构方案\n",
    "\n",
    "**小波变换得到的数据**：shape为(99, 1048559, 8)，三个维度分别是频率，时间，通道数。\n",
    "\n",
    "将数据按时间分割成(99, 99, 8)的10591个数据，丢弃最后的50个数据，由此作为DQN的输入数据。\n",
    "\n",
    "然后将数据整理为批次大小的整数倍，丢弃多余的部分，以适应训练需求\n",
    "\n",
    "### 包含的技术点\n",
    "\n",
    "- 离线强化学习：利用静态数据进行强化学习而不是动态学习。\n",
    "- 批量更新：利用大小为32的批次进行学习。\n",
    "- 经验回放或优先级经验回放：尝试使用经验回放进行Off-Policy学习，或者替换为优先级经验回放来得到较好的结果。\n",
    "- 固定Q目标\n",
    "- 模型蒸馏\n",
    "- 正则化、Dropout减少过拟合\n",
    "- 避免数据增强\n",
    "\n",
    "### 代码架构和构建原理\n",
    "\n",
    "1.数据处理部分：编写一个数据处理函数，用来自动化将数据整理为所需的方格形式\n",
    "\n",
    "2.数据加载部分：将上面一个部分处理好的数据文件加载出来，进行分批并处理成所需的格式\n",
    "\n",
    "3.DQN模型建立部分：分块用面向对象方式建立DQN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd64a759808e59ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:13:07.454914Z",
     "start_time": "2024-04-25T18:13:05.577121Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包引用\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a82f156cbd93c",
   "metadata": {},
   "source": [
    "## 2.1 数据处理\n",
    "\n",
    "编写一个数据处理函数，将数据处理为128*128的区块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58596d545a9c10bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:13:09.299039Z",
     "start_time": "2024-04-25T18:13:09.284970Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据处理函数（分割，整理，输出整理后的数据）\n",
    "\n",
    "# 模块说明：\n",
    "# 这个模块对一个形如(freq, time, channels)的数据进行处理\n",
    "# 将数据处理为一个按freq的大小确定的channels通道数组，每个通道的大小为freq*freq，并抛弃多余的数据\n",
    "# 函数返回分割好的数据和与之对应的类别标签\n",
    "\n",
    "# 数据处理函数定义\n",
    "\n",
    "def data_processing(data_processed, label_processed, batch_size_0):\n",
    "    # 输入数据：数据，这组数据的类别标签，及训练批次数据（用于适配训练方式）\n",
    "    \n",
    "    channels, freq, time = data_processed.shape  # 获取时频维度大小\n",
    "    parts_num = time // freq  # 确定分割的块数\n",
    "    parts_num = (parts_num // batch_size_0) * batch_size_0 # 根据训练批次重新确定分割方式\n",
    "    \n",
    "    data_striped = []  # 定义数据存储器\n",
    "    data_label = [label_processed for _ in range(parts_num)]\n",
    "    \n",
    "    for i in range(parts_num):  # 按块数分割\n",
    "        data_striped.append(data_processed[:, :, i * freq:(i + 1) * freq])  # 向存储器里添加分割的数据\n",
    "\n",
    "    # 上面的数据处理过程抛弃了多余的无法形成格式的数据块\n",
    "    # 返回分割好的数据列表\n",
    "    return data_striped, data_label\n",
    "\n",
    "# 这个函数在使用时要分别获取数据和索引已知对应的标签。\n",
    "# 本任务中数据的维度较高，二者的维度不同导致无法合并。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318317d41123a56d",
   "metadata": {},
   "source": [
    "## 2.2 数据加载部分\n",
    "\n",
    "数据按两种工况分为两部分，分别用不同数据集训练时运行不同部分的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e5f4b62ed61a32f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:13:41.306284Z",
     "start_time": "2024-04-25T18:13:11.889867Z"
    }
   },
   "outputs": [],
   "source": [
    "# 20Hz-0数据加载部分\n",
    "# 本部分从./dataset/gearset中加载数据并添加分类标签\n",
    "\n",
    "# 文件路径列表\n",
    "\n",
    "files_20_0 = ['./dataset/gearset/Chipped_20_0.npy', './dataset/gearset/Health_20_0.npy', './dataset/gearset/Miss_20_0.npy', './dataset/gearset/Root_20_0.npy', './dataset/gearset/Surface_20_0.npy']\n",
    "\n",
    "files_30_2 = ['./dataset/gearset/Chipped_30_2.npy', './dataset/gearset/Health_30_2.npy', './dataset/gearset/Miss_30_2.npy', './dataset/gearset/Root_30_2.npy', './dataset/gearset/Surface_30_2.npy']\n",
    "\n",
    "# 标签列表\n",
    "\n",
    "labels = np.array([0, 1, 2, 3, 4])\n",
    "# 对应的类别：['Chipped', 'Health', 'Miss', 'Root', 'Surface']\n",
    "\n",
    "# 指定所用路径\n",
    "\n",
    "files = files_30_2\n",
    "\n",
    "# 数据寄存器\n",
    "\n",
    "data = []  # 定义初始化列表型数据集\n",
    "label = []  # 定义初始化标签集\n",
    "data_sample = []\n",
    "label_sample = []\n",
    "\n",
    "# 装载数据\n",
    "\n",
    "for file in range(len(files)):\n",
    "    data_sample, label_sample = data_processing(np.load(files[file]), labels[file], batch_size)  # 加载数据并整理数据形式\n",
    "    sample_range = (len(label_sample) // batch_size) - 1  # 取样范围\n",
    "    sample_num = (len(label_sample) // (batch_size * 3)) // batch_size * batch_size  # 取样数量\n",
    "    random_index = random.sample(range(0, sample_range), sample_num)  # 制备索引，进行随机取样\n",
    "    for index in random_index:\n",
    "        data_sam = data_sample[index]\n",
    "        label_sam = label_sample[index]\n",
    "        data.append(data_sam) # 合并到总的数据集里\n",
    "        label.append(label_sam)  # 合并到总的分类集里\n",
    "\n",
    "# 列表转换成数组\n",
    "\n",
    "data = np.array(data)  # 数据数组\n",
    "label = np.array(label)  # 标签数组\n",
    "\n",
    "# 将数据转换为PyTorch的张量\n",
    "\n",
    "dataset = torch.tensor(data)\n",
    "labelset = torch.tensor(label, dtype=torch.long).unsqueeze(1)\n",
    "\n",
    "# 创建数据加载器\n",
    "\n",
    "dataset_tensored = TensorDataset(dataset, labelset)  # 数据集合并，信息获取：data, label = dataset[0]\n",
    "dataloader = DataLoader(dataset_tensored, batch_size=32, shuffle=True)  # 将数据加载为批次\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "12e5e78dfa1cca13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T07:30:22.091202Z",
     "start_time": "2024-04-25T07:30:22.066546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 234, 234])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"for batch in dataloader:\n",
    "    print(batch[0].shape)\n",
    "    temp_b, temp_l = batch[0]\n",
    "    print(temp_b.shape)\n",
    "    print(temp_l.shape)\"\"\"\n",
    "print(dataset_tensored[0][0].shape)\n",
    "temp_iter = iter(dataloader)\n",
    "next_iter = next(temp_iter)\n",
    "print(next_iter[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a089831119f5603",
   "metadata": {},
   "source": [
    "## 2.3 DQN模型的建立\n",
    "\n",
    "建立DQN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c17c49907efddbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:13:46.191902Z",
     "start_time": "2024-04-25T18:13:44.591645Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包引用\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf80092f829515e",
   "metadata": {},
   "source": [
    "## 2.3.1 经验重放\n",
    "\n",
    "- 构造批次化数据处理器\n",
    "- 训练过程稳定化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0de2b93d8a71cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:13:50.537691Z",
     "start_time": "2024-04-25T18:13:50.516626Z"
    }
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', 'state action next_state reward')  # 定义一个变换的元组类型\n",
    "\n",
    "class ReplayMemory:  # 经验重放记忆体\n",
    "    def __init__(self, capacity_0):\n",
    "        self.capacity = capacity_0  # 记忆体容量\n",
    "        self.memory = []  # 记忆体\n",
    "        self.index = 0  # 定义一个系数\n",
    "        \n",
    "    def push(self, state_0, action_0, next_action, reward_0):\n",
    "        if len(self.memory) < self.capacity:  # 如果记忆体没有装满的话\n",
    "            self.memory.append(Transition(state_0, action_0, next_action, reward_0))  # （占位）向里面添加一个数据\n",
    "        self.memory[self.index] = Transition(state_0, action_0, next_action, reward_0)  # 封装一个变换组\n",
    "        self.index = (self.index + 1) % self.capacity  # 记忆体的指针\n",
    "        \n",
    "    def sample(self, batch_size_r):  # 采样\n",
    "        return random.sample(self.memory, batch_size_r)  # 采样次数\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)  # 记忆体的长度\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee20afb113188e8",
   "metadata": {},
   "source": [
    "### 2.3.2 DQN network\n",
    "\n",
    "建立DQN神经网络\n",
    "\n",
    "#### 神经网络结构\n",
    "\n",
    "- 自定义卷积层fc1：使用一个卷积层将8通道512\\*512数据按3通道224\\*224输出，以作为ResNet-18的输入\n",
    "- ReLU函数：正则化图像\n",
    "- ResNet-18网络：处理输入的图像数据\n",
    "- 全连接层fc：重整ResNet-18的输出，将数据输出为分类数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a068f0865938b03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:13:52.184623Z",
     "start_time": "2024-04-25T18:13:52.166349Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions_0):  # 考虑注入n_states\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # 添加一个卷积层，用于数据转化\n",
    "        self.fc1 = nn.Conv2d(in_channels=8, out_channels=3, kernel_size=12, stride=1, padding=1, groups=1, bias=True)\n",
    "        # 定义第一个卷积核，将8通道234*234数据处理成3通道112*112数据，以输入ResNet-18网络\n",
    "        # 参数定义：入通道8，出通道3，卷积核数量64，步长1，边缘1，不分组，添加可学习偏置\n",
    "        # 利用F.interpolate函数动态调整图片大小为224*224，采用bilinear插值，在前向传播中实现\n",
    "        \n",
    "        # 定义激活函数\n",
    "        self.relu = nn.ReLU(inplace=True)  # 指定的激活函数ReLU\n",
    "        \n",
    "        # 定义ResNet-18网络\n",
    "        self.resnet = resnet18(weights=ResNet18_Weights.DEFAULT)  # 引入ResNet-18\n",
    "        for param in self.resnet.parameters():  # 遍历预训练的ResNet-18中的参数\n",
    "            param.requires_grad = False  # 冻结预训练的ResNet-18中的参数\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, n_actions_0)\n",
    "        )    # 重新定义网络的全连接层\n",
    "        # self.resnet.fc = nn.Linear(self.resnet.fc.in_features, n_actions_0)  # 重新定义网络的全连接层\n",
    "        \n",
    "        # 定义输出层\n",
    "        self.out = nn.Linear(in_features=n_actions_0, out_features=n_actions_0)  # 定义输出层\n",
    "        \n",
    "    def forward(self, x):  # 前向传播过程\n",
    "        # 输入：以batch_size作为批次大小的8通道512*512图像，shape：(batch_size, 8, 512, 512)\n",
    "        # 输出：以batch_size作为批次大小的分类（动作）数据，one-hot形式，shape：(batch_size, n_actions)\n",
    "        # print(f\"输入DQN的数据形状为：{x.shape}\")\n",
    "        x = self.fc1(x)\n",
    "        x = F.interpolate(x, size=224, mode='bilinear', align_corners=False)\n",
    "        x = self.relu(x)\n",
    "        x = self.resnet(x)  # 使用网络处理输入\n",
    "        # print(f\"输出网络的数据形状为：{x.shape}\")\n",
    "        return x  # 输出ResNet-18网络的输出\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5831639e67803",
   "metadata": {},
   "source": [
    "### 2.3.3 智能体\n",
    "\n",
    "定义一个智能体，作为网络的训练对象。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44742a9d1f3a092c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:14:26.230385Z",
     "start_time": "2024-04-25T18:14:26.210490Z"
    }
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, n_states_0, n_actions_0, eta_a, gamma_a, capacity_a, batch_size_a):\n",
    "        self.n_states = n_states_0  # 状态维度\n",
    "        self.n_actions = n_actions_0  # 动作维度\n",
    "        self.eta = eta_a  # 学习率\n",
    "        self.gamma = gamma_a  # 折扣因子\n",
    "        self.capacity = capacity_a  # 记忆体容量\n",
    "        self.batch_size = batch_size_a  # 批次大小\n",
    "        \n",
    "        self.memory = ReplayMemory(self.capacity)  # 生成记忆体\n",
    "        self.model = DQN(self.n_actions)  # DQN网络\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.eta)  # Adam优化器\n",
    "        self.criterion = nn.SmoothL1Loss()  # Huber Loss函数\n",
    "        \n",
    "    def _replay(self):\n",
    "        if len(self.memory) < self.batch_size:  # 如果记忆体比批次小而无法存储数据\n",
    "            return  # 直接打断训练过程\n",
    "        # 状态转化列表\n",
    "        \n",
    "        batch = self.memory.sample(1)  # 从记忆体里面采样一批状态\n",
    "        # 将一个batch里的所有元素按类别打包成batch_size长度的元组，合并成一个Transition\n",
    "        batch = Transition(*zip(*batch))  # 打包\n",
    "        \n",
    "        # 分类提取这批数据\n",
    "        state_batch = torch.cat(batch.state)  # 一批状态\n",
    "        action_batch = torch.cat(batch.action)  # 一批动作\n",
    "        reward_b_trans = torch.Tensor(batch.reward)\n",
    "        reward_batch = torch.cat([reward_b_trans])  # 一批回报但是有可能有空值\n",
    "        non_final_next_state_batch = torch.cat([s for s in batch.next_state if s is not None])  # 不为空的状态\n",
    "        \n",
    "        # 构造模型训练的输入和输出（true）\n",
    "        # 输入：状态 s_t\n",
    "        # 期望回报预测pred：Q值 Q(s_t, a_t)\n",
    "        # 实际回报值true：R_{t+1} + \\gamma\\cdot\\max\\limits_a Q(s_t, a)\n",
    "        # 训练目标：pred和true尽可能接近\n",
    "        \n",
    "        # 开启模型的评估模式eval()\n",
    "        self.model.eval()\n",
    "        \n",
    "        # 进行预测\n",
    "        action_batch = action_batch.to(dtype=torch.int64)\n",
    "        action_batch = action_batch.to(\"cuda\")\n",
    "        state_action_values = torch.gather(self.model(state_batch), dim=1, index=action_batch)  # 输入一批训练数据\n",
    "        \n",
    "        # gather：在第二个维度即动作维度上进行操作\n",
    "        # 根据action_batch中的索引选择状态对应动作的预测值\n",
    "        \n",
    "        # 计算真实回报\n",
    "        non_final_mask = torch.ByteTensor(tuple(map(lambda s: s is not None, batch.next_state[0])))  # 提取One-Hot形式的下一个动作\n",
    "        next_state_values = torch.zeros(self.batch_size)  # 创建下一个的状态-动作值组\n",
    "        # Q(s_{t+1}, a)\n",
    "        # 提取里面那个1的索引作为状态值，并取消这个值和梯度的关联\n",
    "        next_state_values = next_state_values.to(\"cuda\")\n",
    "        non_final_mask = non_final_mask.to(\"cuda\")\n",
    "        model_res = self.model(non_final_next_state_batch)\n",
    "        model_res = model_res.to(\"cuda\")\n",
    "        next_state_values[non_final_mask.to(dtype=torch.bool, device='cuda')] = model_res.max(dim=1)[0].detach()  # 将值装入\n",
    "        \n",
    "        # 计算期望的R值\n",
    "        # R_{t+1} + \\gamma\\cdot\\max\\limits_a Q(s_t, a)\n",
    "        reward_batch = reward_batch.to(\"cuda\")\n",
    "        expected_state_action_values = reward_batch + self.gamma * next_state_values\n",
    "        \n",
    "        # 开始进行训练\n",
    "        self.model.train()  # 使用开始训练开关\n",
    "        \n",
    "        # 计算loss\n",
    "        loss = self.criterion(state_action_values.to(dtype=torch.float64), expected_state_action_values.unsqueeze(1).to(dtype=torch.int64))\n",
    "        \n",
    "        self.optimizer.zero_grad()  # 清除梯度\n",
    "        loss.backward()  # 后向传播\n",
    "        self.optimizer.step()  # 进行更新\n",
    "        \n",
    "        return loss.item()\n",
    "        \n",
    "    # 因为self._replay()是私有的，所以定义一个函数来调用\n",
    "    def update_q_function(self):\n",
    "        ls = self._replay()\n",
    "        return ls\n",
    "        \n",
    "        \n",
    "    def memorize(self, state_m, action_m, next_state_m, reward_m):\n",
    "        self.memory.push(state_m, action_m, next_state_m, reward_m)\n",
    "    \n",
    "    # 动作选择策略\n",
    "    # 使用epsilon-贪心算法\n",
    "    # 探索-利用两个方向\n",
    "    def choose_action(self, state_a, episode_a):  # 参数：state状态，episode迭代代数\n",
    "        epsilon = 0.9 / (1 + episode_a)\n",
    "        if random.random() < epsilon:  # 在一定的概率下\n",
    "            # 进行探索\n",
    "            random_actions_list = [random.randrange(n_actions) for _ in range(batch_size)]\n",
    "            action_a = torch.IntTensor(random_actions_list).view(batch_size, 1)  # 随机选择一个动作\n",
    "            # action_a = torch.IntTensor([[random.randrange(self.n_actions)]])  # 随机选择一个动作\n",
    "        else:  # 否则\n",
    "            # 进行利用\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                action_a = self.model(state_a).max(1)[1].view(batch_size, 1)\n",
    "                \n",
    "        return action_a\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), \"model.pth\")\n",
    "    \n",
    "    def togpu(self, device_t):  # 数据迁移而进行GPU计算\n",
    "        self.model.to(device_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1928dd3e7b331b98",
   "metadata": {},
   "source": [
    "### 2.3.4 环境模型\n",
    "\n",
    "#### 定义如下\n",
    "\n",
    "状态：现在手里的一个图像\n",
    "\n",
    "动作：改变或不改变动作\n",
    "\n",
    "#### 逻辑\n",
    "\n",
    "这个逻辑非常简单。初始化时，创建一个迭代器\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a20e7ba56c3557ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:19:55.694149Z",
     "start_time": "2024-04-25T18:19:55.681277Z"
    }
   },
   "outputs": [],
   "source": [
    "# 环境模型的构建\n",
    "class DiagnoseEnv:\n",
    "    def __init__(self, dataloader_e):\n",
    "        self.dataloader = dataloader_e\n",
    "        self.dataiter = iter(self.dataloader)  # 创建一个迭代器\n",
    "        self.state_label = next(self.dataiter)  # 获取数据-标签组\n",
    "        self.state = self.state_label[0].to(\"cuda\")  # 获取一批数据\n",
    "        self.true_label = self.state_label[1].to(\"cuda\")  # 从数据中获取一组数据和标签来初始化\n",
    "        \n",
    "    def reset(self):  # 重置操作，返回一张随机图片\n",
    "        self.dataiter = iter(self.dataiter) # 重置迭代器\n",
    "        try:\n",
    "            self.state_label = next(self.dataiter)  # 尝试从数据中获取获取数据-标签组作为初始状态\n",
    "        except StopIteration:  # 如果没有元素\n",
    "            self.dataiter = iter(self.dataloader) # 重建迭代器\n",
    "            self.state_label = next(self.dataiter)\n",
    "            \n",
    "        self.state = self.state_label[0].to(\"cuda\")  # 获取一批数据\n",
    "        self.true_label = self.state_label[1].to(\"cuda\")  # 从数据中获取对应标签\n",
    "        return self.state  # 返回该图片\n",
    "    \n",
    "    def step(self, action_e):  # 智能体的行动\n",
    "        action_e.to(\"cuda\")\n",
    "        reward_e = self.reward_cnt(action_e).to(\"cuda\")  # 动作和真实标签相等则+1，否则-1\n",
    "        try:\n",
    "            self.state_label = next(self.dataiter)  # 尝试从数据中获取获取数据-标签组作为初始状态\n",
    "        except StopIteration:  # 如果没有元素\n",
    "            self.dataiter = iter(self.dataloader) # 重建迭代器\n",
    "            self.state_label = next(self.dataiter)\n",
    "        \n",
    "        self.state = self.state_label[0].to(\"cuda\")  # 获取一批数据\n",
    "        self.true_label = self.state_label[1].to(\"cuda\")  # 从数据中获取对应标签\n",
    "        return self.state, reward_e  # 返回状态和回报\n",
    "    \n",
    "    def observation_space(self):\n",
    "        return self.state.shape  # 返回状态的形状\n",
    "    \n",
    "    def action_space(self):\n",
    "        unique_values, _ = torch.unique(self.true_label, sorted=False, return_counts=True)  # 计算相同值的类别数\n",
    "        num_unique = len(unique_values)  # 计数\n",
    "        return num_unique  # 返回动作的形状\n",
    "    \n",
    "    def reward_cnt(self, action_r):  # 获取标签\n",
    "        self.true_label = self.true_label.to(\"cuda\")\n",
    "        action_r = action_r.to(\"cuda\")\n",
    "        equal_e = (action_r == self.true_label)  # 对比，提取相同标签的数量\n",
    "        num_e = torch.sum(equal_e)  # 相同元素的数量（分类正确）\n",
    "        num_t = torch.torch.prod(torch.tensor(action_r.shape))  # 计算总元素数量\n",
    "        num_diff = num_t - num_e  # 计算不同元素数量（分类错误）\n",
    "        \n",
    "        return num_e - num_diff  # 分类正确记为1，错误记为-1\n",
    "        \n",
    "\n",
    "    def togpu(self, device_e):\n",
    "        self.state = self.state.to(device_e)\n",
    "        self.true_label = self.true_label.to(device_e)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66999d5646481c0",
   "metadata": {},
   "source": [
    "# 3 训练过程\n",
    "\n",
    "分类任务的训练比较另类，因为没有最大步数，也不需要某些经典的内容\n",
    "\n",
    "基于这种处理，当前的状态被定义为一个图像，动作为选择一个类别\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2408e453e43b28aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:21:18.387866Z",
     "start_time": "2024-04-25T18:21:10.122646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备cuda进行训练\n",
      "回放缓存已满，开始训练\n",
      "训练代数：1/2000，用时4.0s，本轮分类准确率19.7%，本轮Loss值：12.886146602464953\n",
      "训练代数：2/2000，用时3.9s，本轮分类准确率21.3%，本轮Loss值：9.216114207888689\n",
      "训练代数：3/2000，用时3.9s，本轮分类准确率20.9%，本轮Loss值：7.409082141107217\n",
      "训练代数：4/2000，用时3.9s，本轮分类准确率20.9%，本轮Loss值：6.25654942597389\n",
      "训练代数：5/2000，用时4.0s，本轮分类准确率21.4%，本轮Loss值：5.871167123944088\n",
      "训练代数：6/2000，用时4.0s，本轮分类准确率21.2%，本轮Loss值：6.489740274040491\n",
      "训练代数：7/2000，用时4.0s，本轮分类准确率22.5%，本轮Loss值：6.3398783506213245\n",
      "训练代数：8/2000，用时4.0s，本轮分类准确率23.0%，本轮Loss值：5.533359368507251\n",
      "训练代数：9/2000，用时4.0s，本轮分类准确率21.9%，本轮Loss值：6.429309138839267\n",
      "训练代数：10/2000，用时4.0s，本轮分类准确率26.7%，本轮Loss值：6.238683763955715\n",
      "训练代数：11/2000，用时4.0s，本轮分类准确率20.7%，本轮Loss值：6.640701362922357\n",
      "训练代数：12/2000，用时4.0s，本轮分类准确率24.0%，本轮Loss值：5.052644972335566\n",
      "训练代数：13/2000，用时4.0s，本轮分类准确率25.3%，本轮Loss值：6.64477493790722\n",
      "训练代数：14/2000，用时4.0s，本轮分类准确率22.2%，本轮Loss值：5.768829583846037\n",
      "训练代数：15/2000，用时4.0s，本轮分类准确率26.6%，本轮Loss值：5.198050719881678\n",
      "训练代数：16/2000，用时4.0s，本轮分类准确率21.5%，本轮Loss值：5.876848910666558\n",
      "训练代数：17/2000，用时4.0s，本轮分类准确率24.1%，本轮Loss值：6.68217302539224\n",
      "训练代数：18/2000，用时4.0s，本轮分类准确率23.0%，本轮Loss值：5.539467305758637\n",
      "训练代数：19/2000，用时4.0s，本轮分类准确率24.1%，本轮Loss值：6.024063197231749\n",
      "训练代数：20/2000，用时3.9s，本轮分类准确率22.1%，本轮Loss值：5.575299302179724\n",
      "训练代数：21/2000，用时4.0s，本轮分类准确率24.5%，本轮Loss值：5.267527654702997\n",
      "训练代数：22/2000，用时4.0s，本轮分类准确率26.2%，本轮Loss值：5.465531577696697\n",
      "训练代数：23/2000，用时4.0s，本轮分类准确率24.4%，本轮Loss值：5.056509582190165\n",
      "训练代数：24/2000，用时4.0s，本轮分类准确率25.5%，本轮Loss值：6.231603982735544\n",
      "训练代数：25/2000，用时4.0s，本轮分类准确率24.2%，本轮Loss值：4.440458717110516\n",
      "训练代数：26/2000，用时4.0s，本轮分类准确率23.6%，本轮Loss值：5.543452760576668\n",
      "训练代数：27/2000，用时4.0s，本轮分类准确率20.5%，本轮Loss值：4.285235688249804\n",
      "训练代数：28/2000，用时4.0s，本轮分类准确率27.9%，本轮Loss值：4.886705798741934\n",
      "训练代数：29/2000，用时4.0s，本轮分类准确率23.4%，本轮Loss值：6.32385174327892\n",
      "训练代数：30/2000，用时4.0s，本轮分类准确率27.9%，本轮Loss值：4.2404440277751405\n",
      "训练代数：31/2000，用时4.0s，本轮分类准确率29.1%，本轮Loss值：4.250678291581744\n",
      "训练代数：32/2000，用时4.0s，本轮分类准确率24.5%，本轮Loss值：7.6524736383149845\n",
      "训练代数：33/2000，用时4.0s，本轮分类准确率23.8%，本轮Loss值：5.052590621996319\n",
      "训练代数：34/2000，用时4.0s，本轮分类准确率31.6%，本轮Loss值：6.114123494514388\n",
      "训练代数：35/2000，用时4.0s，本轮分类准确率37.6%，本轮Loss值：5.876810524605491\n",
      "训练代数：36/2000，用时4.0s，本轮分类准确率30.5%，本轮Loss值：8.395341403554363\n",
      "训练代数：37/2000，用时4.0s，本轮分类准确率33.0%，本轮Loss值：5.624078070969517\n",
      "训练代数：38/2000，用时4.0s，本轮分类准确率33.8%，本轮Loss值：5.100686963241197\n",
      "训练代数：39/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：4.028416184779848\n",
      "训练代数：40/2000，用时4.0s，本轮分类准确率27.5%，本轮Loss值：4.94795340414808\n",
      "训练代数：41/2000，用时4.0s，本轮分类准确率32.7%，本轮Loss值：5.949068584406677\n",
      "训练代数：42/2000，用时4.0s，本轮分类准确率36.3%，本轮Loss值：3.9404600634123197\n",
      "训练代数：43/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：3.586326275881453\n",
      "训练代数：44/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.4664268037914354\n",
      "训练代数：45/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.888922011335666\n",
      "训练代数：46/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：4.5223481433964\n",
      "训练代数：47/2000，用时4.0s，本轮分类准确率37.0%，本轮Loss值：3.4077325354636314\n",
      "训练代数：48/2000，用时4.0s，本轮分类准确率37.6%，本轮Loss值：4.52253103195269\n",
      "训练代数：49/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：4.619815583298882\n",
      "训练代数：50/2000，用时4.0s，本轮分类准确率37.8%，本轮Loss值：4.317522592164053\n",
      "训练代数：51/2000，用时4.0s，本轮分类准确率37.2%，本轮Loss值：4.232608278674019\n",
      "训练代数：52/2000，用时4.0s，本轮分类准确率40.7%，本轮Loss值：3.9892525197453863\n",
      "训练代数：53/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.699778939835099\n",
      "训练代数：54/2000，用时4.0s，本轮分类准确率41.8%，本轮Loss值：3.7443515518456367\n",
      "训练代数：55/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.879691363858586\n",
      "训练代数：56/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：4.425754450534794\n",
      "训练代数：57/2000，用时4.0s，本轮分类准确率41.5%，本轮Loss值：3.9881174639850085\n",
      "训练代数：58/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：5.229416055355898\n",
      "训练代数：59/2000，用时4.0s，本轮分类准确率32.9%，本轮Loss值：4.30780943110795\n",
      "训练代数：60/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：3.936815203423521\n",
      "训练代数：61/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.530368640256145\n",
      "训练代数：62/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.4602379193783035\n",
      "训练代数：63/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.10447793769909\n",
      "训练代数：64/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.8589894340025523\n",
      "训练代数：65/2000，用时4.0s，本轮分类准确率36.7%，本轮Loss值：4.302394474720009\n",
      "训练代数：66/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：4.882336644680822\n",
      "训练代数：67/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.494695227368035\n",
      "训练代数：68/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.4712873258462538\n",
      "训练代数：69/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.899813797658237\n",
      "训练代数：70/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.568067266771456\n",
      "训练代数：71/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.39241183246844\n",
      "训练代数：72/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.450999036418088\n",
      "训练代数：73/2000，用时4.0s，本轮分类准确率36.8%，本轮Loss值：3.2497090277516008\n",
      "训练代数：74/2000，用时4.0s，本轮分类准确率35.9%，本轮Loss值：4.8145594448355835\n",
      "训练代数：75/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.5101720784644557\n",
      "训练代数：76/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.5729647192135245\n",
      "训练代数：77/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.4937862334482532\n",
      "训练代数：78/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：2.616427978293197\n",
      "训练代数：79/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.493442942851516\n",
      "训练代数：80/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.9791955920973434\n",
      "训练代数：81/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.5652956961964577\n",
      "训练代数：82/2000，用时4.0s，本轮分类准确率34.2%，本轮Loss值：4.113621300762605\n",
      "训练代数：83/2000，用时4.0s，本轮分类准确率28.0%，本轮Loss值：6.936575159325253\n",
      "训练代数：84/2000，用时4.0s，本轮分类准确率20.7%，本轮Loss值：7.012598910743884\n",
      "训练代数：85/2000，用时4.0s，本轮分类准确率33.1%，本轮Loss值：5.435436676780125\n",
      "训练代数：86/2000，用时4.0s，本轮分类准确率26.9%，本轮Loss值：6.130841787342581\n",
      "训练代数：87/2000，用时4.0s，本轮分类准确率28.2%，本轮Loss值：5.163948582232388\n",
      "训练代数：88/2000，用时4.0s，本轮分类准确率26.7%，本轮Loss值：4.571985433209579\n",
      "训练代数：89/2000，用时4.0s，本轮分类准确率23.1%，本轮Loss值：5.1450650813486165\n",
      "训练代数：90/2000，用时4.0s，本轮分类准确率27.4%，本轮Loss值：5.867009723105207\n",
      "训练代数：91/2000，用时4.0s，本轮分类准确率22.5%，本轮Loss值：5.625480414803212\n",
      "训练代数：92/2000，用时4.0s，本轮分类准确率22.7%，本轮Loss值：6.22620883446408\n",
      "训练代数：93/2000，用时4.0s，本轮分类准确率34.7%，本轮Loss值：5.041285180732951\n",
      "训练代数：94/2000，用时4.0s，本轮分类准确率31.2%，本轮Loss值：4.640721596992535\n",
      "训练代数：95/2000，用时4.0s，本轮分类准确率33.8%，本轮Loss值：3.7202519659775364\n",
      "训练代数：96/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：4.003783822092737\n",
      "训练代数：97/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.7183079027765302\n",
      "训练代数：98/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：4.435205833197392\n",
      "训练代数：99/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：4.95300647807287\n",
      "训练代数：100/2000，用时4.0s，本轮分类准确率37.5%，本轮Loss值：3.7603621794682907\n",
      "训练代数：101/2000，用时4.1s，本轮分类准确率39.3%，本轮Loss值：3.9550049464129415\n",
      "训练代数：102/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.2998137708105815\n",
      "训练代数：103/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.7955823034528238\n",
      "训练代数：104/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.9626556280667105\n",
      "训练代数：105/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.30135080491645\n",
      "训练代数：106/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.0495659554014454\n",
      "训练代数：107/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：2.6492417623982845\n",
      "训练代数：108/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.9288126714181204\n",
      "训练代数：109/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.6733381117634223\n",
      "训练代数：110/2000，用时4.0s，本轮分类准确率38.3%，本轮Loss值：3.6084499045443494\n",
      "训练代数：111/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：2.973803102948884\n",
      "训练代数：112/2000，用时4.0s，本轮分类准确率30.4%，本轮Loss值：4.999314960885528\n",
      "训练代数：113/2000，用时4.0s，本轮分类准确率28.8%，本轮Loss值：6.300991457801433\n",
      "训练代数：114/2000，用时4.0s，本轮分类准确率30.5%，本轮Loss值：5.270790709062487\n",
      "训练代数：115/2000，用时4.0s，本轮分类准确率25.2%，本轮Loss值：6.837823752313261\n",
      "训练代数：116/2000，用时4.0s，本轮分类准确率28.3%，本轮Loss值：4.759447117641651\n",
      "训练代数：117/2000，用时4.0s，本轮分类准确率36.8%，本轮Loss值：4.186588208777278\n",
      "训练代数：118/2000，用时4.0s，本轮分类准确率34.6%，本轮Loss值：5.154353163029978\n",
      "训练代数：119/2000，用时4.0s，本轮分类准确率33.6%，本轮Loss值：3.740944196226195\n",
      "训练代数：120/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.7602997595468253\n",
      "训练代数：121/2000，用时4.0s，本轮分类准确率44.4%，本轮Loss值：4.420040781661385\n",
      "训练代数：122/2000，用时4.0s，本轮分类准确率30.3%，本轮Loss值：6.240665003403602\n",
      "训练代数：123/2000，用时4.0s，本轮分类准确率22.6%，本轮Loss值：6.352424904601117\n",
      "训练代数：124/2000，用时4.0s，本轮分类准确率24.5%，本轮Loss值：6.240443521369082\n",
      "训练代数：125/2000，用时4.1s，本轮分类准确率31.4%，本轮Loss值：5.903729356326005\n",
      "训练代数：126/2000，用时4.0s，本轮分类准确率34.1%，本轮Loss值：4.986056048478554\n",
      "训练代数：127/2000，用时4.0s，本轮分类准确率33.8%，本轮Loss值：3.463750760452149\n",
      "训练代数：128/2000，用时4.0s，本轮分类准确率28.9%，本轮Loss值：5.226214822442273\n",
      "训练代数：129/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：4.7084487842048475\n",
      "训练代数：130/2000，用时4.0s，本轮分类准确率35.7%，本轮Loss值：4.918938740921919\n",
      "训练代数：131/2000，用时4.0s，本轮分类准确率34.8%，本轮Loss值：4.893662361580925\n",
      "训练代数：132/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.6021414923214676\n",
      "训练代数：133/2000，用时4.0s，本轮分类准确率35.6%，本轮Loss值：3.9715897896050025\n",
      "训练代数：134/2000，用时4.0s，本轮分类准确率34.5%，本轮Loss值：4.79106510194944\n",
      "训练代数：135/2000，用时4.1s，本轮分类准确率37.9%，本轮Loss值：3.8833203202804385\n",
      "训练代数：136/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：3.7225873657657758\n",
      "训练代数：137/2000，用时4.0s，本轮分类准确率38.1%，本轮Loss值：3.513844991515998\n",
      "训练代数：138/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：3.376181160579563\n",
      "训练代数：139/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：3.117541943646947\n",
      "训练代数：140/2000，用时4.0s，本轮分类准确率37.1%，本轮Loss值：3.7154041220896232\n",
      "训练代数：141/2000，用时4.0s，本轮分类准确率36.7%，本轮Loss值：2.968063819320497\n",
      "训练代数：142/2000，用时4.0s，本轮分类准确率38.3%，本轮Loss值：3.095123628114371\n",
      "训练代数：143/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.8732576182713956\n",
      "训练代数：144/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：2.9797077172113946\n",
      "训练代数：145/2000，用时4.0s，本轮分类准确率36.6%，本轮Loss值：4.155408014458828\n",
      "训练代数：146/2000，用时4.0s，本轮分类准确率32.9%，本轮Loss值：3.5782281868270163\n",
      "训练代数：147/2000，用时4.0s，本轮分类准确率29.6%，本轮Loss值：6.21180289873015\n",
      "训练代数：148/2000，用时4.0s，本轮分类准确率36.3%，本轮Loss值：7.072016181765082\n",
      "训练代数：149/2000，用时4.0s，本轮分类准确率34.4%，本轮Loss值：4.452465671967365\n",
      "训练代数：150/2000，用时4.0s，本轮分类准确率32.9%，本轮Loss值：4.920738435095939\n",
      "训练代数：151/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.9143535324684193\n",
      "训练代数：152/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：4.325163363507357\n",
      "训练代数：153/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：4.274346444435139\n",
      "训练代数：154/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.2053122437582657\n",
      "训练代数：155/2000，用时4.0s，本轮分类准确率40.9%，本轮Loss值：5.014566715979609\n",
      "训练代数：156/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.981480647936303\n",
      "训练代数：157/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.5600136221540253\n",
      "训练代数：158/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.790498289347022\n",
      "训练代数：159/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：3.8631206729429266\n",
      "训练代数：160/2000，用时4.0s，本轮分类准确率41.1%，本轮Loss值：4.86592958946041\n",
      "训练代数：161/2000，用时4.0s，本轮分类准确率40.7%，本轮Loss值：4.714637046427972\n",
      "训练代数：162/2000，用时4.0s，本轮分类准确率40.7%，本轮Loss值：4.577274814171088\n",
      "训练代数：163/2000，用时4.0s，本轮分类准确率43.3%，本轮Loss值：4.84979369274218\n",
      "训练代数：164/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.460719885988285\n",
      "训练代数：165/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.362731734475881\n",
      "训练代数：166/2000，用时4.0s，本轮分类准确率42.5%，本轮Loss值：5.956077172921906\n",
      "训练代数：167/2000，用时4.0s，本轮分类准确率41.8%，本轮Loss值：4.896214041283438\n",
      "训练代数：168/2000，用时4.0s，本轮分类准确率36.1%，本轮Loss值：4.155259533860471\n",
      "训练代数：169/2000，用时4.0s，本轮分类准确率37.4%，本轮Loss值：4.358182333725412\n",
      "训练代数：170/2000，用时4.0s，本轮分类准确率33.4%，本轮Loss值：4.851448251621457\n",
      "训练代数：171/2000，用时3.9s，本轮分类准确率34.7%，本轮Loss值：5.499712112379302\n",
      "训练代数：172/2000，用时4.0s，本轮分类准确率35.6%，本轮Loss值：4.460631810332757\n",
      "训练代数：173/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：5.406337966490469\n",
      "训练代数：174/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：4.974501268854411\n",
      "训练代数：175/2000，用时4.0s，本轮分类准确率35.8%，本轮Loss值：6.154233418460047\n",
      "训练代数：176/2000，用时4.0s，本轮分类准确率40.8%，本轮Loss值：6.018009239692569\n",
      "训练代数：177/2000，用时3.9s，本轮分类准确率41.7%，本轮Loss值：4.099899102656821\n",
      "训练代数：178/2000，用时3.9s，本轮分类准确率44.0%，本轮Loss值：4.656169962760025\n",
      "训练代数：179/2000，用时3.9s，本轮分类准确率51.7%，本轮Loss值：5.487986305607263\n",
      "训练代数：180/2000，用时3.9s，本轮分类准确率51.3%，本轮Loss值：4.4506940929446595\n",
      "训练代数：181/2000，用时3.9s，本轮分类准确率50.2%，本轮Loss值：4.603562857345566\n",
      "训练代数：182/2000，用时3.9s，本轮分类准确率34.1%，本轮Loss值：6.935082518647332\n",
      "训练代数：183/2000，用时3.9s，本轮分类准确率26.8%，本轮Loss值：13.613961087653825\n",
      "训练代数：184/2000，用时3.9s，本轮分类准确率22.0%，本轮Loss值：6.8096184799948745\n",
      "训练代数：185/2000，用时4.1s，本轮分类准确率22.1%，本轮Loss值：6.363466877027918\n",
      "训练代数：186/2000，用时4.0s，本轮分类准确率20.5%，本轮Loss值：6.170471774303337\n",
      "训练代数：187/2000，用时3.9s，本轮分类准确率21.5%，本轮Loss值：5.129676368662535\n",
      "训练代数：188/2000，用时3.9s，本轮分类准确率23.6%，本轮Loss值：6.5773364415420925\n",
      "训练代数：189/2000，用时3.9s，本轮分类准确率29.1%，本轮Loss值：4.525168022564083\n",
      "训练代数：190/2000，用时4.0s，本轮分类准确率25.9%，本轮Loss值：5.446434847424575\n",
      "训练代数：191/2000，用时4.0s，本轮分类准确率25.2%，本轮Loss值：4.782590997993975\n",
      "训练代数：192/2000，用时4.0s，本轮分类准确率36.2%，本轮Loss值：4.354677176405983\n",
      "训练代数：193/2000，用时4.0s，本轮分类准确率29.8%，本轮Loss值：4.767516297819133\n",
      "训练代数：194/2000，用时4.0s，本轮分类准确率25.9%，本轮Loss值：5.831648958574851\n",
      "训练代数：195/2000，用时4.0s，本轮分类准确率34.2%，本轮Loss值：4.768412377780203\n",
      "训练代数：196/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.8162756566865768\n",
      "训练代数：197/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.8819598011858147\n",
      "训练代数：198/2000，用时4.1s，本轮分类准确率39.0%，本轮Loss值：3.589799499557489\n",
      "训练代数：199/2000，用时3.9s，本轮分类准确率39.1%，本轮Loss值：3.855449406412626\n",
      "训练代数：200/2000，用时4.1s，本轮分类准确率39.3%，本轮Loss值：3.0991598323632727\n",
      "训练代数：201/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.2421743545888146\n",
      "训练代数：202/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.910981061515932\n",
      "训练代数：203/2000，用时4.0s，本轮分类准确率36.8%，本轮Loss值：3.797910588452157\n",
      "训练代数：204/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：3.4229540836721526\n",
      "训练代数：205/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：4.269143658569033\n",
      "训练代数：206/2000，用时4.0s，本轮分类准确率37.9%，本轮Loss值：3.088028809599854\n",
      "训练代数：207/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.856062424879704\n",
      "训练代数：208/2000，用时4.0s，本轮分类准确率35.5%，本轮Loss值：3.925986316725397\n",
      "训练代数：209/2000，用时4.0s，本轮分类准确率31.2%，本轮Loss值：4.8774091145431155\n",
      "训练代数：210/2000，用时4.0s，本轮分类准确率26.6%，本轮Loss值：5.860399737072259\n",
      "训练代数：211/2000，用时3.9s，本轮分类准确率33.1%，本轮Loss值：5.234615834899069\n",
      "训练代数：212/2000，用时4.0s，本轮分类准确率37.6%，本轮Loss值：4.741869559896725\n",
      "训练代数：213/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.3347635799237367\n",
      "训练代数：214/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.1930054653058564\n",
      "训练代数：215/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.577260771750372\n",
      "训练代数：216/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.1829937287284564\n",
      "训练代数：217/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：2.924988219896659\n",
      "训练代数：218/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.085855074781\n",
      "训练代数：219/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.603754747196163\n",
      "训练代数：220/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.6447634511674294\n",
      "训练代数：221/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：2.7796443904062813\n",
      "训练代数：222/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.005845054920056\n",
      "训练代数：223/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.6931434328538075\n",
      "训练代数：224/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：2.7616030299772176\n",
      "训练代数：225/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.115476383921549\n",
      "训练代数：226/2000，用时4.0s，本轮分类准确率35.6%，本轮Loss值：4.395513117276377\n",
      "训练代数：227/2000，用时4.0s，本轮分类准确率26.4%，本轮Loss值：5.185335131095331\n",
      "训练代数：228/2000，用时4.0s，本轮分类准确率24.8%，本轮Loss值：8.993239586305128\n",
      "训练代数：229/2000，用时4.0s，本轮分类准确率22.0%，本轮Loss值：6.003036676537818\n",
      "训练代数：230/2000，用时4.0s，本轮分类准确率30.5%，本轮Loss值：5.167973724308683\n",
      "训练代数：231/2000，用时4.0s，本轮分类准确率25.4%，本轮Loss值：6.004428583790764\n",
      "训练代数：232/2000，用时4.0s，本轮分类准确率31.6%，本轮Loss值：5.587548455875549\n",
      "训练代数：233/2000，用时4.0s，本轮分类准确率32.0%，本轮Loss值：5.479213970893295\n",
      "训练代数：234/2000，用时4.0s，本轮分类准确率33.6%，本轮Loss值：4.981287362561875\n",
      "训练代数：235/2000，用时4.0s，本轮分类准确率36.4%，本轮Loss值：4.88443007212012\n",
      "训练代数：236/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：4.360884900242337\n",
      "训练代数：237/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.509101533671392\n",
      "训练代数：238/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.5507425328987834\n",
      "训练代数：239/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：4.044901149459389\n",
      "训练代数：240/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.4464789503655795\n",
      "训练代数：241/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.1700624024595725\n",
      "训练代数：242/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.1053422033851206\n",
      "训练代数：243/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.440265357138139\n",
      "训练代数：244/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.5412511565069904\n",
      "训练代数：245/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.569268568073414\n",
      "训练代数：246/2000，用时4.1s，本轮分类准确率39.1%，本轮Loss值：3.833723391047735\n",
      "训练代数：247/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.9982222245098797\n",
      "训练代数：248/2000，用时3.9s，本轮分类准确率39.3%，本轮Loss值：2.9757562785145892\n",
      "训练代数：249/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.150046881702545\n",
      "训练代数：250/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.751754775582742\n",
      "训练代数：251/2000，用时3.9s，本轮分类准确率39.1%，本轮Loss值：3.5751759101109997\n",
      "训练代数：252/2000，用时3.9s，本轮分类准确率39.4%，本轮Loss值：3.3569713933802148\n",
      "训练代数：253/2000，用时3.9s，本轮分类准确率39.4%，本轮Loss值：3.2183995219432857\n",
      "训练代数：254/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：4.657485934849694\n",
      "训练代数：255/2000，用时3.9s，本轮分类准确率39.2%，本轮Loss值：4.369500733561162\n",
      "训练代数：256/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.4287421269408727\n",
      "训练代数：257/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.5124646293483606\n",
      "训练代数：258/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：3.314652960818705\n",
      "训练代数：259/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：4.192317914178974\n",
      "训练代数：260/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.6347465054852477\n",
      "训练代数：261/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.720315979672691\n",
      "训练代数：262/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.469149266705125\n",
      "训练代数：263/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.6415857661025655\n",
      "训练代数：264/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.606054003332133\n",
      "训练代数：265/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.203653115038918\n",
      "训练代数：266/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.512192032040724\n",
      "训练代数：267/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：2.99028888236883\n",
      "训练代数：268/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：3.122538210628252\n",
      "训练代数：269/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.0165688953033394\n",
      "训练代数：270/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.0000538332102478\n",
      "训练代数：271/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.2198065660351913\n",
      "训练代数：272/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.0306898673872467\n",
      "训练代数：273/2000，用时3.9s，本轮分类准确率38.9%，本轮Loss值：4.202209520867586\n",
      "训练代数：274/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：2.8391130342003295\n",
      "训练代数：275/2000，用时3.9s，本轮分类准确率38.7%，本轮Loss值：2.9676629738320317\n",
      "训练代数：276/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.3695789025784535\n",
      "训练代数：277/2000，用时3.9s，本轮分类准确率39.4%，本轮Loss值：3.0720923333926806\n",
      "训练代数：278/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.461460199274688\n",
      "训练代数：279/2000，用时3.9s，本轮分类准确率38.8%，本轮Loss值：3.495308845400183\n",
      "训练代数：280/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.6222219528015787\n",
      "训练代数：281/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.8482111975117106\n",
      "训练代数：282/2000，用时4.0s，本轮分类准确率33.3%，本轮Loss值：4.836629685150916\n",
      "训练代数：283/2000，用时4.0s，本轮分类准确率28.5%，本轮Loss值：6.65757380369447\n",
      "训练代数：284/2000，用时4.0s，本轮分类准确率35.5%，本轮Loss值：4.326497258099027\n",
      "训练代数：285/2000，用时4.1s，本轮分类准确率39.1%，本轮Loss值：3.6044259517191053\n",
      "训练代数：286/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.3689597173376455\n",
      "训练代数：287/2000，用时4.0s，本轮分类准确率33.1%，本轮Loss值：4.960991542897983\n",
      "训练代数：288/2000，用时4.1s，本轮分类准确率27.3%，本轮Loss值：6.52470402860539\n",
      "训练代数：289/2000，用时4.0s，本轮分类准确率27.1%，本轮Loss值：5.40884899793009\n",
      "训练代数：290/2000，用时4.1s，本轮分类准确率30.3%，本轮Loss值：5.3079569731795235\n",
      "训练代数：291/2000，用时4.1s，本轮分类准确率36.9%，本轮Loss值：4.67284808013643\n",
      "训练代数：292/2000，用时4.1s，本轮分类准确率35.5%，本轮Loss值：3.6358560679216536\n",
      "训练代数：293/2000，用时4.0s，本轮分类准确率36.7%，本轮Loss值：4.108344735550202\n",
      "训练代数：294/2000，用时3.9s，本轮分类准确率39.3%，本轮Loss值：3.3639608020112632\n",
      "训练代数：295/2000，用时3.9s，本轮分类准确率39.0%，本轮Loss值：3.071415999409615\n",
      "训练代数：296/2000，用时3.9s，本轮分类准确率38.6%，本轮Loss值：3.6091035137075864\n",
      "训练代数：297/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.6905637094357586\n",
      "训练代数：298/2000，用时4.0s，本轮分类准确率37.9%，本轮Loss值：3.3954678642541696\n",
      "训练代数：299/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：2.901109745695783\n",
      "训练代数：300/2000，用时3.9s，本轮分类准确率36.2%，本轮Loss值：3.7282566884962423\n",
      "训练代数：301/2000，用时3.9s，本轮分类准确率38.4%，本轮Loss值：2.9270897558803997\n",
      "训练代数：302/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.36304170639512\n",
      "训练代数：303/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.184690035302984\n",
      "训练代数：304/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.840324677225837\n",
      "训练代数：305/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.2588594114568963\n",
      "训练代数：306/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.2953291963585913\n",
      "训练代数：307/2000，用时3.9s，本轮分类准确率38.4%，本轮Loss值：3.5454474897686623\n",
      "训练代数：308/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：4.422872119025842\n",
      "训练代数：309/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.2052993648673236\n",
      "训练代数：310/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.46618734931412\n",
      "训练代数：311/2000，用时3.9s，本轮分类准确率38.4%，本轮Loss值：3.7813266906194114\n",
      "训练代数：312/2000，用时3.9s，本轮分类准确率38.6%，本轮Loss值：3.0620213898638156\n",
      "训练代数：313/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.9561002904371265\n",
      "训练代数：314/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.8862521304405333\n",
      "训练代数：315/2000，用时4.0s，本轮分类准确率38.3%，本轮Loss值：4.09340870385247\n",
      "训练代数：316/2000，用时3.9s，本轮分类准确率37.8%，本轮Loss值：3.833882256464065\n",
      "训练代数：317/2000，用时3.9s，本轮分类准确率38.9%，本轮Loss值：3.772391785593379\n",
      "训练代数：318/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.002973590717565\n",
      "训练代数：319/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.71170142002446\n",
      "训练代数：320/2000，用时3.9s，本轮分类准确率38.6%，本轮Loss值：3.4014632393472\n",
      "训练代数：321/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.3918318297896035\n",
      "训练代数：322/2000，用时4.0s，本轮分类准确率38.1%，本轮Loss值：3.380392023843757\n",
      "训练代数：323/2000，用时3.9s，本轮分类准确率38.1%，本轮Loss值：3.619763593296304\n",
      "训练代数：324/2000，用时4.0s，本轮分类准确率37.5%，本轮Loss值：3.571566194382683\n",
      "训练代数：325/2000，用时3.9s，本轮分类准确率38.7%，本轮Loss值：3.438881665766732\n",
      "训练代数：326/2000，用时3.9s，本轮分类准确率38.2%，本轮Loss值：3.542523425060429\n",
      "训练代数：327/2000，用时3.9s，本轮分类准确率38.7%，本轮Loss值：3.459540429216213\n",
      "训练代数：328/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.217461055150841\n",
      "训练代数：329/2000，用时3.9s，本轮分类准确率38.0%，本轮Loss值：3.3027623306110967\n",
      "训练代数：330/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：3.8691994458152434\n",
      "训练代数：331/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：2.772594928908876\n",
      "训练代数：332/2000，用时4.0s，本轮分类准确率37.1%，本轮Loss值：3.404947519872786\n",
      "训练代数：333/2000，用时4.0s，本轮分类准确率26.2%，本轮Loss值：4.704769899975071\n",
      "训练代数：334/2000，用时4.1s，本轮分类准确率26.6%，本轮Loss值：5.57789084670502\n",
      "训练代数：335/2000，用时4.0s，本轮分类准确率32.2%，本轮Loss值：4.629413551319044\n",
      "训练代数：336/2000，用时4.0s，本轮分类准确率36.6%，本轮Loss值：5.386832028552442\n",
      "训练代数：337/2000，用时4.0s，本轮分类准确率40.3%，本轮Loss值：4.224635120509677\n",
      "训练代数：338/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：4.446436198591096\n",
      "训练代数：339/2000，用时3.9s，本轮分类准确率39.6%，本轮Loss值：3.4100448758658812\n",
      "训练代数：340/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：4.175041315531004\n",
      "训练代数：341/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：3.2266721196842725\n",
      "训练代数：342/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.8431051531116993\n",
      "训练代数：343/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.3722703146289406\n",
      "训练代数：344/2000，用时4.0s，本轮分类准确率36.5%，本轮Loss值：2.7184291546554418\n",
      "训练代数：345/2000，用时3.9s，本轮分类准确率33.8%，本轮Loss值：5.039870482187325\n",
      "训练代数：346/2000，用时3.9s，本轮分类准确率32.7%，本轮Loss值：4.9560267289664495\n",
      "训练代数：347/2000，用时3.9s，本轮分类准确率32.9%，本轮Loss值：4.944660561766602\n",
      "训练代数：348/2000，用时4.0s，本轮分类准确率32.7%，本轮Loss值：5.159866042722944\n",
      "训练代数：349/2000，用时4.0s，本轮分类准确率36.4%，本轮Loss值：4.562716199335864\n",
      "训练代数：350/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.3728489182625365\n",
      "训练代数：351/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.6403424606360657\n",
      "训练代数：352/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.029514713543958\n",
      "训练代数：353/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.362276209605878\n",
      "训练代数：354/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.424886896691251\n",
      "训练代数：355/2000，用时4.0s，本轮分类准确率38.3%，本轮Loss值：4.26240827461329\n",
      "训练代数：356/2000，用时4.0s，本轮分类准确率35.8%，本轮Loss值：3.9929868885642237\n",
      "训练代数：357/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：4.350137842993092\n",
      "训练代数：358/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.0133312814665145\n",
      "训练代数：359/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.88370652409933\n",
      "训练代数：360/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.1998199357509405\n",
      "训练代数：361/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.418633132088735\n",
      "训练代数：362/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.463429130913215\n",
      "训练代数：363/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.9847981108269463\n",
      "训练代数：364/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：4.340012410238705\n",
      "训练代数：365/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.509586837482982\n",
      "训练代数：366/2000，用时3.9s，本轮分类准确率38.9%，本轮Loss值：3.178080452230077\n",
      "训练代数：367/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.1654803324096976\n",
      "训练代数：368/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：2.976292658426354\n",
      "训练代数：369/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.137097899225435\n",
      "训练代数：370/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.5536549349115516\n",
      "训练代数：371/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：2.952975962485283\n",
      "训练代数：372/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.1224247806371523\n",
      "训练代数：373/2000，用时4.1s，本轮分类准确率39.1%，本轮Loss值：3.525675657398338\n",
      "训练代数：374/2000，用时4.1s，本轮分类准确率38.9%，本轮Loss值：3.829704543698668\n",
      "训练代数：375/2000，用时4.0s，本轮分类准确率31.8%，本轮Loss值：3.834810840537159\n",
      "训练代数：376/2000，用时4.1s，本轮分类准确率23.9%，本轮Loss值：6.287010947348369\n",
      "训练代数：377/2000，用时3.9s，本轮分类准确率26.7%，本轮Loss值：5.773488744227916\n",
      "训练代数：378/2000，用时3.9s，本轮分类准确率25.2%，本轮Loss值：4.209868611364049\n",
      "训练代数：379/2000，用时4.0s，本轮分类准确率29.0%，本轮Loss值：5.28440848766603\n",
      "训练代数：380/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.5224847764536324\n",
      "训练代数：381/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.273416673131789\n",
      "训练代数：382/2000，用时4.0s，本轮分类准确率37.0%，本轮Loss值：3.8493579306837065\n",
      "训练代数：383/2000，用时4.0s，本轮分类准确率30.9%，本轮Loss值：5.312512799251076\n",
      "训练代数：384/2000，用时4.0s，本轮分类准确率36.6%，本轮Loss值：4.3407924900605055\n",
      "训练代数：385/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.37397671239479\n",
      "训练代数：386/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.311393019609784\n",
      "训练代数：387/2000，用时4.2s，本轮分类准确率39.2%，本轮Loss值：2.8145867669641063\n",
      "训练代数：388/2000，用时4.1s，本轮分类准确率39.2%，本轮Loss值：3.0492243244234856\n",
      "训练代数：389/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.1553399809694156\n",
      "训练代数：390/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：2.4632830163688597\n",
      "训练代数：391/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.830693148890691\n",
      "训练代数：392/2000，用时4.1s，本轮分类准确率39.2%，本轮Loss值：3.6742206666313195\n",
      "训练代数：393/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.3203185200690997\n",
      "训练代数：394/2000，用时4.0s，本轮分类准确率36.3%，本轮Loss值：3.6091127971609183\n",
      "训练代数：395/2000，用时4.0s，本轮分类准确率37.5%，本轮Loss值：3.2625448050863612\n",
      "训练代数：396/2000，用时4.0s，本轮分类准确率37.1%，本轮Loss值：3.35486891422903\n",
      "训练代数：397/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.2270310897351466\n",
      "训练代数：398/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.6040427673374382\n",
      "训练代数：399/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.8237509842248385\n",
      "训练代数：400/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.6431089293666874\n",
      "训练代数：401/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：4.238576253895817\n",
      "训练代数：402/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.9208801059204577\n",
      "训练代数：403/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.5939381717833414\n",
      "训练代数：404/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.8079967551704756\n",
      "训练代数：405/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.492376423986181\n",
      "训练代数：406/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.952365690710502\n",
      "训练代数：407/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：3.2289670504239494\n",
      "训练代数：408/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.294883129269306\n",
      "训练代数：409/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.9201044811509234\n",
      "训练代数：410/2000，用时4.0s，本轮分类准确率35.3%，本轮Loss值：3.763389540524858\n",
      "训练代数：411/2000，用时4.0s，本轮分类准确率38.1%，本轮Loss值：4.315706931244907\n",
      "训练代数：412/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.528218596310046\n",
      "训练代数：413/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.3513377409545937\n",
      "训练代数：414/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：2.9172139715380156\n",
      "训练代数：415/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：2.9655966762365664\n",
      "训练代数：416/2000，用时4.0s，本轮分类准确率37.1%，本轮Loss值：3.7020291326542747\n",
      "训练代数：417/2000，用时4.0s，本轮分类准确率28.0%，本轮Loss值：5.227040707276421\n",
      "训练代数：418/2000，用时4.0s，本轮分类准确率26.1%，本轮Loss值：5.724787744149296\n",
      "训练代数：419/2000，用时4.0s，本轮分类准确率22.1%，本轮Loss值：5.265539111062219\n",
      "训练代数：420/2000，用时4.0s，本轮分类准确率29.6%，本轮Loss值：4.456488622235997\n",
      "训练代数：421/2000，用时4.0s，本轮分类准确率32.5%，本轮Loss值：5.619833599004994\n",
      "训练代数：422/2000，用时4.0s，本轮分类准确率31.6%，本轮Loss值：5.759043320950411\n",
      "训练代数：423/2000，用时4.0s，本轮分类准确率34.2%，本轮Loss值：5.242758794019653\n",
      "训练代数：424/2000，用时4.0s，本轮分类准确率36.1%，本轮Loss值：4.650078848513113\n",
      "训练代数：425/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.572748996521875\n",
      "训练代数：426/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.8961655682733407\n",
      "训练代数：427/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.2101998319667415\n",
      "训练代数：428/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.737105823283713\n",
      "训练代数：429/2000，用时4.1s，本轮分类准确率39.6%，本轮Loss值：4.71968633506475\n",
      "训练代数：430/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.601225031882558\n",
      "训练代数：431/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.843236751965321\n",
      "训练代数：432/2000，用时4.0s，本轮分类准确率35.7%，本轮Loss值：3.680321658258322\n",
      "训练代数：433/2000，用时4.0s，本轮分类准确率33.9%，本轮Loss值：4.479013905127045\n",
      "训练代数：434/2000，用时4.0s，本轮分类准确率38.3%，本轮Loss值：3.4106442243138417\n",
      "训练代数：435/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.3611614910271443\n",
      "训练代数：436/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.6425313560001884\n",
      "训练代数：437/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.516910255618808\n",
      "训练代数：438/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.1357659311557855\n",
      "训练代数：439/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.2397058633126674\n",
      "训练代数：440/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.373870353444403\n",
      "训练代数：441/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.4241592923189303\n",
      "训练代数：442/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.9733423519600906\n",
      "训练代数：443/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.4761858013743163\n",
      "训练代数：444/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.3426101964239\n",
      "训练代数：445/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.0210531878137856\n",
      "训练代数：446/2000，用时4.1s，本轮分类准确率39.5%，本轮Loss值：3.2384611097148905\n",
      "训练代数：447/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.5482558396976716\n",
      "训练代数：448/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：2.82114759234378\n",
      "训练代数：449/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.373009076199793\n",
      "训练代数：450/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.9710077996257267\n",
      "训练代数：451/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.701887498494682\n",
      "训练代数：452/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：5.009428999898086\n",
      "训练代数：453/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.783079805990738\n",
      "训练代数：454/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.058471968800407\n",
      "训练代数：455/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.048318703193414\n",
      "训练代数：456/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.4285346142092066\n",
      "训练代数：457/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.387275129607647\n",
      "训练代数：458/2000，用时4.1s，本轮分类准确率39.5%，本轮Loss值：3.7378633230379705\n",
      "训练代数：459/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.2257919601752065\n",
      "训练代数：460/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.5858497474972837\n",
      "训练代数：461/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.9342248963183493\n",
      "训练代数：462/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.690136450758388\n",
      "训练代数：463/2000，用时4.1s，本轮分类准确率39.0%，本轮Loss值：3.9120787336700404\n",
      "训练代数：464/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.0669679806001113\n",
      "训练代数：465/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.788149654468117\n",
      "训练代数：466/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.031118947919239\n",
      "训练代数：467/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.478434983505096\n",
      "训练代数：468/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.180083800933221\n",
      "训练代数：469/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：2.8660533903350314\n",
      "训练代数：470/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：2.784997368734267\n",
      "训练代数：471/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：3.274506777832914\n",
      "训练代数：472/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.19545881101908\n",
      "训练代数：473/2000，用时4.0s，本轮分类准确率36.6%，本轮Loss值：4.097242786922999\n",
      "训练代数：474/2000，用时4.0s，本轮分类准确率37.0%，本轮Loss值：3.2202793734075725\n",
      "训练代数：475/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.1358791357657507\n",
      "训练代数：476/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.594147994143009\n",
      "训练代数：477/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.4483685040952734\n",
      "训练代数：478/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.426155459834672\n",
      "训练代数：479/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：2.9526078176633375\n",
      "训练代数：480/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.045838628131352\n",
      "训练代数：481/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.433095548275523\n",
      "训练代数：482/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.6845513886045014\n",
      "训练代数：483/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.2039940179883954\n",
      "训练代数：484/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.7461217562484563\n",
      "训练代数：485/2000，用时4.0s，本轮分类准确率37.5%，本轮Loss值：3.913694622845776\n",
      "训练代数：486/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.526723947622929\n",
      "训练代数：487/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.6031703012300484\n",
      "训练代数：488/2000，用时4.1s，本轮分类准确率38.9%，本轮Loss值：3.782789287071529\n",
      "训练代数：489/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.8301161370002434\n",
      "训练代数：490/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.68915105231014\n",
      "训练代数：491/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：4.036499836296619\n",
      "训练代数：492/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.441029919237144\n",
      "训练代数：493/2000，用时4.0s，本轮分类准确率38.1%，本轮Loss值：3.2165763195703905\n",
      "训练代数：494/2000，用时4.0s，本轮分类准确率35.6%，本轮Loss值：4.0531389130500655\n",
      "训练代数：495/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.30267238762375\n",
      "训练代数：496/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：4.013657173450002\n",
      "训练代数：497/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.306175167405493\n",
      "训练代数：498/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.4568523173689045\n",
      "训练代数：499/2000，用时4.0s，本轮分类准确率37.2%，本轮Loss值：3.9980967002128067\n",
      "训练代数：500/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.8629486518443854\n",
      "训练代数：501/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.2816105360696897\n",
      "训练代数：502/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：2.649053098103624\n",
      "训练代数：503/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.8572021811082267\n",
      "训练代数：504/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.1346750866572934\n",
      "训练代数：505/2000，用时3.9s，本轮分类准确率39.1%，本轮Loss值：3.579589074646438\n",
      "训练代数：506/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.301152439637056\n",
      "训练代数：507/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：4.01706246993705\n",
      "训练代数：508/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：4.442502105707087\n",
      "训练代数：509/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.0948467324640916\n",
      "训练代数：510/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.6794355911877745\n",
      "训练代数：511/2000，用时4.0s，本轮分类准确率34.4%，本轮Loss值：4.101468845419677\n",
      "训练代数：512/2000，用时4.0s，本轮分类准确率25.9%，本轮Loss值：6.055952295801842\n",
      "训练代数：513/2000，用时4.0s，本轮分类准确率24.3%，本轮Loss值：5.958152078850787\n",
      "训练代数：514/2000，用时4.0s，本轮分类准确率25.4%，本轮Loss值：6.789794235823967\n",
      "训练代数：515/2000，用时4.0s，本轮分类准确率26.9%，本轮Loss值：5.707027177605914\n",
      "训练代数：516/2000，用时4.0s，本轮分类准确率31.1%，本轮Loss值：5.094372945752116\n",
      "训练代数：517/2000，用时4.1s，本轮分类准确率30.1%，本轮Loss值：5.554359519858531\n",
      "训练代数：518/2000，用时4.0s，本轮分类准确率35.0%，本轮Loss值：4.887841931949867\n",
      "训练代数：519/2000，用时4.0s，本轮分类准确率37.6%，本轮Loss值：3.8725601713978337\n",
      "训练代数：520/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.870396930872482\n",
      "训练代数：521/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.883168538119199\n",
      "训练代数：522/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.4041671796460946\n",
      "训练代数：523/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.1058221538123036\n",
      "训练代数：524/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：4.077521844791031\n",
      "训练代数：525/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.7592418132880483\n",
      "训练代数：526/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：4.128421748011377\n",
      "训练代数：527/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.3023091767960095\n",
      "训练代数：528/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：2.7016726253591314\n",
      "训练代数：529/2000，用时4.1s，本轮分类准确率38.8%，本轮Loss值：3.7334721069992156\n",
      "训练代数：530/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：2.7717995088150134\n",
      "训练代数：531/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：2.854739017101713\n",
      "训练代数：532/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.1183129673208527\n",
      "训练代数：533/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：2.690768687222794\n",
      "训练代数：534/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.4342524559781054\n",
      "训练代数：535/2000，用时4.1s，本轮分类准确率38.8%，本轮Loss值：3.463493484425308\n",
      "训练代数：536/2000，用时4.0s，本轮分类准确率38.3%，本轮Loss值：4.419410958292334\n",
      "训练代数：537/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.1216126794472956\n",
      "训练代数：538/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.190516439782118\n",
      "训练代数：539/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.678104755827536\n",
      "训练代数：540/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：2.7495397336882066\n",
      "训练代数：541/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：4.011418861385207\n",
      "训练代数：542/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.938261012106227\n",
      "训练代数：543/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.601401737923277\n",
      "训练代数：544/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.612087201418956\n",
      "训练代数：545/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.5334800985498958\n",
      "训练代数：546/2000，用时3.9s，本轮分类准确率39.1%，本轮Loss值：3.1352673169966976\n",
      "训练代数：547/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.8893476475977904\n",
      "训练代数：548/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.3214287973274024\n",
      "训练代数：549/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.325546919435027\n",
      "训练代数：550/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.6108580738565648\n",
      "训练代数：551/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.261660275003169\n",
      "训练代数：552/2000，用时3.9s，本轮分类准确率39.3%，本轮Loss值：3.2091473230728527\n",
      "训练代数：553/2000，用时3.9s，本轮分类准确率39.3%，本轮Loss值：3.509267000847058\n",
      "训练代数：554/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.3855688105795365\n",
      "训练代数：555/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.8024585289618726\n",
      "训练代数：556/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.7290467662404154\n",
      "训练代数：557/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.2745799902355914\n",
      "训练代数：558/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.8281551011676016\n",
      "训练代数：559/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：4.057456663542013\n",
      "训练代数：560/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.8600952175404672\n",
      "训练代数：561/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：2.581792394394435\n",
      "训练代数：562/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.2097569269768256\n",
      "训练代数：563/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：4.44362916531982\n",
      "训练代数：564/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.2799304959206297\n",
      "训练代数：565/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.249977052028305\n",
      "训练代数：566/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：2.981400057319368\n",
      "训练代数：567/2000，用时3.9s，本轮分类准确率39.4%，本轮Loss值：3.1820958699014654\n",
      "训练代数：568/2000，用时3.9s，本轮分类准确率38.6%，本轮Loss值：4.144250749987966\n",
      "训练代数：569/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：2.771479586850154\n",
      "训练代数：570/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.736938754527151\n",
      "训练代数：571/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：4.466089989517701\n",
      "训练代数：572/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：4.293626278369169\n",
      "训练代数：573/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.110477537957405\n",
      "训练代数：574/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.7553461889897335\n",
      "训练代数：575/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.3940298658229553\n",
      "训练代数：576/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.534592851173926\n",
      "训练代数：577/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.467680004656825\n",
      "训练代数：578/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.7271946976168095\n",
      "训练代数：579/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：2.7346900056624093\n",
      "训练代数：580/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.222422614643628\n",
      "训练代数：581/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.867675936186649\n",
      "训练代数：582/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.3888194812919807\n",
      "训练代数：583/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.2615393654162403\n",
      "训练代数：584/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.17249623814468\n",
      "训练代数：585/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.9729173600418335\n",
      "训练代数：586/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.5485356859098287\n",
      "训练代数：587/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.897826209376402\n",
      "训练代数：588/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：4.057627295048047\n",
      "训练代数：589/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.057066097129274\n",
      "训练代数：590/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.648000481322461\n",
      "训练代数：591/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.4654013295342905\n",
      "训练代数：592/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.118350730453608\n",
      "训练代数：593/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.4959051398280705\n",
      "训练代数：594/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.7957520587009896\n",
      "训练代数：595/2000，用时4.0s，本轮分类准确率37.0%，本轮Loss值：4.185293562706997\n",
      "训练代数：596/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：4.7519085196181665\n",
      "训练代数：597/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.9495035795288658\n",
      "训练代数：598/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.3798364516171775\n",
      "训练代数：599/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.5863904149733004\n",
      "训练代数：600/2000，用时4.0s，本轮分类准确率36.2%，本轮Loss值：4.1416900921193305\n",
      "训练代数：601/2000，用时4.0s，本轮分类准确率25.7%，本轮Loss值：6.457860895300135\n",
      "训练代数：602/2000，用时4.0s，本轮分类准确率28.0%，本轮Loss值：5.68138970629816\n",
      "训练代数：603/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：4.92912507987329\n",
      "训练代数：604/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：3.2735952725449353\n",
      "训练代数：605/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.4449509195053225\n",
      "训练代数：606/2000，用时4.0s，本轮分类准确率36.7%，本轮Loss值：3.727693433122988\n",
      "训练代数：607/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：4.204535415873238\n",
      "训练代数：608/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.705204138192164\n",
      "训练代数：609/2000，用时3.9s，本轮分类准确率38.9%，本轮Loss值：3.276612729932836\n",
      "训练代数：610/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.3143213077553013\n",
      "训练代数：611/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.1118933880926845\n",
      "训练代数：612/2000，用时3.9s，本轮分类准确率39.0%，本轮Loss值：3.391322544650717\n",
      "训练代数：613/2000，用时3.9s，本轮分类准确率39.3%，本轮Loss值：3.1389629005785538\n",
      "训练代数：614/2000，用时3.9s，本轮分类准确率38.3%，本轮Loss值：3.618683991175402\n",
      "训练代数：615/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.4210840852206474\n",
      "训练代数：616/2000，用时3.9s，本轮分类准确率38.6%，本轮Loss值：3.6222373443043665\n",
      "训练代数：617/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.058101417300466\n",
      "训练代数：618/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.5475272281936014\n",
      "训练代数：619/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.5242440534475463\n",
      "训练代数：620/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.427541442495888\n",
      "训练代数：621/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.8748449660034168\n",
      "训练代数：622/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.7597071601965384\n",
      "训练代数：623/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.9357369746724316\n",
      "训练代数：624/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：4.354793482840114\n",
      "训练代数：625/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.0751680509594506\n",
      "训练代数：626/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.515359504709829\n",
      "训练代数：627/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.378206269736097\n",
      "训练代数：628/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.363793704375405\n",
      "训练代数：629/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.314040274236851\n",
      "训练代数：630/2000，用时4.0s，本轮分类准确率37.8%，本轮Loss值：3.134738364379109\n",
      "训练代数：631/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.269721746377428\n",
      "训练代数：632/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.2467692887448036\n",
      "训练代数：633/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：2.1353443708102446\n",
      "训练代数：634/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.946215639678934\n",
      "训练代数：635/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.7357489101897245\n",
      "训练代数：636/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.7940975852769894\n",
      "训练代数：637/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.969725087215406\n",
      "训练代数：638/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.742345344445755\n",
      "训练代数：639/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.5471769888819837\n",
      "训练代数：640/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.8208516470537264\n",
      "训练代数：641/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.264100132171302\n",
      "训练代数：642/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.6738442809384138\n",
      "训练代数：643/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.9866809270387678\n",
      "训练代数：644/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：4.227645183053639\n",
      "训练代数：645/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.9333732803949317\n",
      "训练代数：646/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.0914337274536394\n",
      "训练代数：647/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.9762093470754136\n",
      "训练代数：648/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.6094386766208144\n",
      "训练代数：649/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.971003344999448\n",
      "训练代数：650/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.4959761092724846\n",
      "训练代数：651/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.8551429762996063\n",
      "训练代数：652/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.534145998191582\n",
      "训练代数：653/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.78537950592181\n",
      "训练代数：654/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.402931910746849\n",
      "训练代数：655/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.062959716761719\n",
      "训练代数：656/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.4357875847093964\n",
      "训练代数：657/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.594604987333409\n",
      "训练代数：658/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.890311182553603\n",
      "训练代数：659/2000，用时4.1s，本轮分类准确率39.3%，本轮Loss值：3.5518215723036777\n",
      "训练代数：660/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.206504590398552\n",
      "训练代数：661/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.530507137670932\n",
      "训练代数：662/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：2.7835827611211075\n",
      "训练代数：663/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.230932966998617\n",
      "训练代数：664/2000，用时4.1s，本轮分类准确率39.4%，本轮Loss值：3.8204188141366275\n",
      "训练代数：665/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.118445536259844\n",
      "训练代数：666/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：2.9102079504224405\n",
      "训练代数：667/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.371667068867501\n",
      "训练代数：668/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.8112020971164497\n",
      "训练代数：669/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.465820956475062\n",
      "训练代数：670/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：4.6340719390309575\n",
      "训练代数：671/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.722252661124858\n",
      "训练代数：672/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.0040961160617057\n",
      "训练代数：673/2000，用时3.9s，本轮分类准确率38.8%，本轮Loss值：3.369082097935004\n",
      "训练代数：674/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：4.141296302686885\n",
      "训练代数：675/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.1108911059605133\n",
      "训练代数：676/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.079433848474281\n",
      "训练代数：677/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.3534567733576752\n",
      "训练代数：678/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.055680940585316\n",
      "训练代数：679/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.6578878893779576\n",
      "训练代数：680/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.6279811741245735\n",
      "训练代数：681/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.9141495644432864\n",
      "训练代数：682/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：2.864971926894202\n",
      "训练代数：683/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.7825606570888994\n",
      "训练代数：684/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.383852738611063\n",
      "训练代数：685/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.7630084423414756\n",
      "训练代数：686/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.1857836001508533\n",
      "训练代数：687/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.8590911217498016\n",
      "训练代数：688/2000，用时4.1s，本轮分类准确率39.1%，本轮Loss值：3.4660118649427547\n",
      "训练代数：689/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.481933458802925\n",
      "训练代数：690/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.654118746380621\n",
      "训练代数：691/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.7576105852073654\n",
      "训练代数：692/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：2.7950974397268795\n",
      "训练代数：693/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.5460022710002392\n",
      "训练代数：694/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.3889862878482604\n",
      "训练代数：695/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：4.065646905573081\n",
      "训练代数：696/2000，用时4.0s，本轮分类准确率38.1%，本轮Loss值：3.3524216674327705\n",
      "训练代数：697/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.392637865038893\n",
      "训练代数：698/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：4.826640314619027\n",
      "训练代数：699/2000，用时3.9s，本轮分类准确率41.1%，本轮Loss值：3.6375214773971862\n",
      "训练代数：700/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.478325470067554\n",
      "训练代数：701/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.7971237724873506\n",
      "训练代数：702/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.017065571985438\n",
      "训练代数：703/2000，用时4.0s，本轮分类准确率35.9%，本轮Loss值：4.476698841662329\n",
      "训练代数：704/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.6984891336717056\n",
      "训练代数：705/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.5968314488329582\n",
      "训练代数：706/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.5339646372972653\n",
      "训练代数：707/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.2746372221934763\n",
      "训练代数：708/2000，用时4.0s，本轮分类准确率41.1%，本轮Loss值：4.277222830784933\n",
      "训练代数：709/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.337036608126442\n",
      "训练代数：710/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.9445151221308663\n",
      "训练代数：711/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.113875936133138\n",
      "训练代数：712/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.879529025072648\n",
      "训练代数：713/2000，用时4.0s，本轮分类准确率40.8%，本轮Loss值：3.977749485882083\n",
      "训练代数：714/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.046097534050131\n",
      "训练代数：715/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.1463963010638\n",
      "训练代数：716/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.544365748178106\n",
      "训练代数：717/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.719080945564613\n",
      "训练代数：718/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.13777873688158\n",
      "训练代数：719/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.3005445195053627\n",
      "训练代数：720/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：4.183853905507479\n",
      "训练代数：721/2000，用时3.9s，本轮分类准确率34.5%，本轮Loss值：3.9583818577649965\n",
      "训练代数：722/2000，用时4.0s，本轮分类准确率36.4%，本轮Loss值：4.00298163859394\n",
      "训练代数：723/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.852819517492878\n",
      "训练代数：724/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.4844950793206806\n",
      "训练代数：725/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.044870047822386\n",
      "训练代数：726/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：4.11731534245196\n",
      "训练代数：727/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.414141220211576\n",
      "训练代数：728/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：2.87330493167388\n",
      "训练代数：729/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.1036670439055882\n",
      "训练代数：730/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.153423652942635\n",
      "训练代数：731/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.5789136395646066\n",
      "训练代数：732/2000，用时4.1s，本轮分类准确率40.0%，本轮Loss值：4.039242103411922\n",
      "训练代数：733/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.690831171635023\n",
      "训练代数：734/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.273854558677098\n",
      "训练代数：735/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.034202023876622\n",
      "训练代数：736/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.551771218712659\n",
      "训练代数：737/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.487794162004133\n",
      "训练代数：738/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.327317746774275\n",
      "训练代数：739/2000，用时4.0s，本轮分类准确率37.4%，本轮Loss值：4.093038520221915\n",
      "训练代数：740/2000，用时4.0s，本轮分类准确率37.6%，本轮Loss值：3.8111412506551234\n",
      "训练代数：741/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.5045127031695302\n",
      "训练代数：742/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.6940978489014014\n",
      "训练代数：743/2000，用时4.0s，本轮分类准确率35.0%，本轮Loss值：4.4550745338161075\n",
      "训练代数：744/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.7072187871808127\n",
      "训练代数：745/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.756581870634437\n",
      "训练代数：746/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.8105593636216155\n",
      "训练代数：747/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.287810763497765\n",
      "训练代数：748/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.7484520766252674\n",
      "训练代数：749/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.363944516712047\n",
      "训练代数：750/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.8568154324284136\n",
      "训练代数：751/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.7263383829398946\n",
      "训练代数：752/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.7898026526569395\n",
      "训练代数：753/2000，用时4.0s，本轮分类准确率35.9%，本轮Loss值：4.165830623922849\n",
      "训练代数：754/2000，用时4.0s，本轮分类准确率28.5%，本轮Loss值：5.830465466529381\n",
      "训练代数：755/2000，用时4.0s，本轮分类准确率33.0%，本轮Loss值：6.51918702727248\n",
      "训练代数：756/2000，用时4.0s，本轮分类准确率24.2%，本轮Loss值：6.340578493972157\n",
      "训练代数：757/2000，用时4.0s，本轮分类准确率23.6%，本轮Loss值：5.73811973383547\n",
      "训练代数：758/2000，用时4.0s，本轮分类准确率30.7%，本轮Loss值：4.886193772761851\n",
      "训练代数：759/2000，用时4.0s，本轮分类准确率32.9%，本轮Loss值：4.355968502681321\n",
      "训练代数：760/2000，用时4.0s，本轮分类准确率29.8%，本轮Loss值：5.754365695393938\n",
      "训练代数：761/2000，用时4.0s，本轮分类准确率37.9%，本轮Loss值：4.844949024990854\n",
      "训练代数：762/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：2.767301957552422\n",
      "训练代数：763/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.6322233857921162\n",
      "训练代数：764/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.2668762623862704\n",
      "训练代数：765/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.958600921265173\n",
      "训练代数：766/2000，用时4.0s，本轮分类准确率40.4%，本轮Loss值：4.085113537420699\n",
      "训练代数：767/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.24274573533163\n",
      "训练代数：768/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.7360557345134056\n",
      "训练代数：769/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.5835260932658373\n",
      "训练代数：770/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：2.7686438454476616\n",
      "训练代数：771/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.5091830964211255\n",
      "训练代数：772/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.6216611380467016\n",
      "训练代数：773/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：4.1728221339804605\n",
      "训练代数：774/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.699794000785258\n",
      "训练代数：775/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.2997370097927474\n",
      "训练代数：776/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.418131417637542\n",
      "训练代数：777/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.427877024764365\n",
      "训练代数：778/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.461156614207931\n",
      "训练代数：779/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.3336253224581895\n",
      "训练代数：780/2000，用时4.0s，本轮分类准确率40.3%，本轮Loss值：3.6513788306560144\n",
      "训练代数：781/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.0578398240726585\n",
      "训练代数：782/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.891793317132533\n",
      "训练代数：783/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.9656702830102035\n",
      "训练代数：784/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.34022960357687\n",
      "训练代数：785/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.7746805771808027\n",
      "训练代数：786/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.980048131859701\n",
      "训练代数：787/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：3.439975812492861\n",
      "训练代数：788/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：2.978971002698162\n",
      "训练代数：789/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.7752694456687435\n",
      "训练代数：790/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：2.9486056424670153\n",
      "训练代数：791/2000，用时4.1s，本轮分类准确率39.8%，本轮Loss值：3.376492928581075\n",
      "训练代数：792/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.7638410497969033\n",
      "训练代数：793/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.482231101147275\n",
      "训练代数：794/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.79163746247458\n",
      "训练代数：795/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.099780507813475\n",
      "训练代数：796/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.8826971534695813\n",
      "训练代数：797/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：2.9441833580806955\n",
      "训练代数：798/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：4.276763747609692\n",
      "训练代数：799/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：2.918495580818643\n",
      "训练代数：800/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：2.66916304747553\n",
      "训练代数：801/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.0851509312206815\n",
      "训练代数：802/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.4941647949623102\n",
      "训练代数：803/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：2.7821747919752395\n",
      "训练代数：804/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.556698466023613\n",
      "训练代数：805/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.672422959525926\n",
      "训练代数：806/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.171819967480661\n",
      "训练代数：807/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.880593383022744\n",
      "训练代数：808/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.4955350008042814\n",
      "训练代数：809/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.867759868576587\n",
      "训练代数：810/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.6838509605853744\n",
      "训练代数：811/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：4.235542848150868\n",
      "训练代数：812/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.5495923814294428\n",
      "训练代数：813/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.637283915337136\n",
      "训练代数：814/2000，用时4.2s，本轮分类准确率39.8%，本轮Loss值：3.724152406555959\n",
      "训练代数：815/2000，用时4.1s，本轮分类准确率38.7%，本轮Loss值：3.700320553762032\n",
      "训练代数：816/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.969975143371073\n",
      "训练代数：817/2000，用时4.1s，本轮分类准确率39.8%，本轮Loss值：2.779133816520377\n",
      "训练代数：818/2000，用时4.1s，本轮分类准确率39.2%，本轮Loss值：3.4392852244344683\n",
      "训练代数：819/2000，用时4.1s，本轮分类准确率39.7%，本轮Loss值：3.9767362868850427\n",
      "训练代数：820/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.047038947169187\n",
      "训练代数：821/2000，用时4.1s，本轮分类准确率39.8%，本轮Loss值：3.6001947733707595\n",
      "训练代数：822/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.2445662330848135\n",
      "训练代数：823/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.31135447123728\n",
      "训练代数：824/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.883821975673095\n",
      "训练代数：825/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.095280952308252\n",
      "训练代数：826/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.358743776911621\n",
      "训练代数：827/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：2.9693365760789305\n",
      "训练代数：828/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.369777728018832\n",
      "训练代数：829/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.8933995249120104\n",
      "训练代数：830/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.8535954423643317\n",
      "训练代数：831/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.962083642677851\n",
      "训练代数：832/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.177236482598386\n",
      "训练代数：833/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.4948999631804867\n",
      "训练代数：834/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：4.04185836573316\n",
      "训练代数：835/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.428757119531872\n",
      "训练代数：836/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.434965381130786\n",
      "训练代数：837/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.8044460838611314\n",
      "训练代数：838/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.886078061816616\n",
      "训练代数：839/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.0263859474204677\n",
      "训练代数：840/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：2.780985264638889\n",
      "训练代数：841/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.3278076551509117\n",
      "训练代数：842/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.497048573257646\n",
      "训练代数：843/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.1740065462175524\n",
      "训练代数：844/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.114924416523436\n",
      "训练代数：845/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.190266780235615\n",
      "训练代数：846/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.6094309567103893\n",
      "训练代数：847/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.03823876698983\n",
      "训练代数：848/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.9918714583871235\n",
      "训练代数：849/2000，用时4.0s，本轮分类准确率37.8%，本轮Loss值：3.2038493582360106\n",
      "训练代数：850/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.2219940734685393\n",
      "训练代数：851/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：4.442626208873657\n",
      "训练代数：852/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.23850138515902\n",
      "训练代数：853/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.826528581986821\n",
      "训练代数：854/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.2166929705503975\n",
      "训练代数：855/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.641307491195923\n",
      "训练代数：856/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.3830356297681448\n",
      "训练代数：857/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.6416985295241915\n",
      "训练代数：858/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.477336732054377\n",
      "训练代数：859/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.7845731545710835\n",
      "训练代数：860/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.982022267272032\n",
      "训练代数：861/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.8556354066462917\n",
      "训练代数：862/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.4867474448628855\n",
      "训练代数：863/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.0374593636704477\n",
      "训练代数：864/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：4.1778317353166585\n",
      "训练代数：865/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.8300548517832285\n",
      "训练代数：866/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.723250791180439\n",
      "训练代数：867/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.3090336720777516\n",
      "训练代数：868/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.0337356052069056\n",
      "训练代数：869/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.272747413415692\n",
      "训练代数：870/2000，用时4.1s，本轮分类准确率40.1%，本轮Loss值：3.9959874571010885\n",
      "训练代数：871/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.548125455316162\n",
      "训练代数：872/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.599303764991279\n",
      "训练代数：873/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.221925810254052\n",
      "训练代数：874/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.085928224701038\n",
      "训练代数：875/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：3.2711628450159167\n",
      "训练代数：876/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.2558934151153807\n",
      "训练代数：877/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.545509857443497\n",
      "训练代数：878/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.4492018507740796\n",
      "训练代数：879/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.5478775223389762\n",
      "训练代数：880/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.619422209043458\n",
      "训练代数：881/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.852661250976962\n",
      "训练代数：882/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.6397004991589226\n",
      "训练代数：883/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.6223275355563658\n",
      "训练代数：884/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：3.08376697414993\n",
      "训练代数：885/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：2.9625156269590263\n",
      "训练代数：886/2000，用时4.0s，本轮分类准确率37.4%，本轮Loss值：3.64238017584764\n",
      "训练代数：887/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.072817982325995\n",
      "训练代数：888/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.719599151327597\n",
      "训练代数：889/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.489402287373642\n",
      "训练代数：890/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.7193986353051116\n",
      "训练代数：891/2000，用时4.0s，本轮分类准确率40.5%，本轮Loss值：4.67719201366566\n",
      "训练代数：892/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：7.422216538293353\n",
      "训练代数：893/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.740259185079566\n",
      "训练代数：894/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：3.2412378510940356\n",
      "训练代数：895/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.288064271343882\n",
      "训练代数：896/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.8406070920808757\n",
      "训练代数：897/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.399845692397264\n",
      "训练代数：898/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.638397721930116\n",
      "训练代数：899/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.231551023037113\n",
      "训练代数：900/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.961356499891477\n",
      "训练代数：901/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.166302456814589\n",
      "训练代数：902/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.2913950182940055\n",
      "训练代数：903/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.135889384689088\n",
      "训练代数：904/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.6548866771602944\n",
      "训练代数：905/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.8910803088601797\n",
      "训练代数：906/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：4.371755837630883\n",
      "训练代数：907/2000，用时3.9s，本轮分类准确率40.1%，本轮Loss值：3.8789750638633107\n",
      "训练代数：908/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.781724153340451\n",
      "训练代数：909/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.4991781794272243\n",
      "训练代数：910/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.6659751372609377\n",
      "训练代数：911/2000，用时3.9s，本轮分类准确率39.4%，本轮Loss值：3.932439152005273\n",
      "训练代数：912/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：2.757910936429718\n",
      "训练代数：913/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.9633480533591894\n",
      "训练代数：914/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.7687984790414277\n",
      "训练代数：915/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.028081199206246\n",
      "训练代数：916/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.841991053848909\n",
      "训练代数：917/2000，用时3.9s，本轮分类准确率39.3%，本轮Loss值：3.5141732887623336\n",
      "训练代数：918/2000，用时3.9s，本轮分类准确率38.2%，本轮Loss值：3.5598844464735095\n",
      "训练代数：919/2000，用时3.9s，本轮分类准确率39.4%，本轮Loss值：3.756596055377264\n",
      "训练代数：920/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.798022815536959\n",
      "训练代数：921/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.423277266688788\n",
      "训练代数：922/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.574312123256598\n",
      "训练代数：923/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.5058295017228374\n",
      "训练代数：924/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：3.7406010218263104\n",
      "训练代数：925/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：4.174227306261585\n",
      "训练代数：926/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：4.419575300883443\n",
      "训练代数：927/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.7850112176850756\n",
      "训练代数：928/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.42270847967263\n",
      "训练代数：929/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.2584561046710605\n",
      "训练代数：930/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.191821302562451\n",
      "训练代数：931/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.225150302863878\n",
      "训练代数：932/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：2.9464775255620195\n",
      "训练代数：933/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.0124883563839204\n",
      "训练代数：934/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.312572545288572\n",
      "训练代数：935/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：2.9638791157640667\n",
      "训练代数：936/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.767517803717084\n",
      "训练代数：937/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.9779847716745733\n",
      "训练代数：938/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.344456042730118\n",
      "训练代数：939/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.2972993561915613\n",
      "训练代数：940/2000，用时3.9s，本轮分类准确率39.2%，本轮Loss值：3.8758297933654093\n",
      "训练代数：941/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.414252035806956\n",
      "训练代数：942/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.5882839750105746\n",
      "训练代数：943/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.554407803886849\n",
      "训练代数：944/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.1544265820666224\n",
      "训练代数：945/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.113031066510857\n",
      "训练代数：946/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.797395813345895\n",
      "训练代数：947/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.072207122847081\n",
      "训练代数：948/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.475587637827755\n",
      "训练代数：949/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.8413189865700046\n",
      "训练代数：950/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.1868170884387554\n",
      "训练代数：951/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.2692839495666703\n",
      "训练代数：952/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.543651768858129\n",
      "训练代数：953/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.461589344407065\n",
      "训练代数：954/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.404198980821559\n",
      "训练代数：955/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.3684423818784355\n",
      "训练代数：956/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.932023533091487\n",
      "训练代数：957/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.785228729740038\n",
      "训练代数：958/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.1981612110670112\n",
      "训练代数：959/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.3828690112832476\n",
      "训练代数：960/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.0467563576483685\n",
      "训练代数：961/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.2567681297536124\n",
      "训练代数：962/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.989978064280541\n",
      "训练代数：963/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.7216595820473914\n",
      "训练代数：964/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.907915368013323\n",
      "训练代数：965/2000，用时4.1s，本轮分类准确率40.1%，本轮Loss值：2.7221372340895584\n",
      "训练代数：966/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：4.061459272774973\n",
      "训练代数：967/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.633638590911224\n",
      "训练代数：968/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.352760630189761\n",
      "训练代数：969/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：2.7638936990818195\n",
      "训练代数：970/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.6193619770739245\n",
      "训练代数：971/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.41426811983535\n",
      "训练代数：972/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.900043164002278\n",
      "训练代数：973/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：4.052017387844776\n",
      "训练代数：974/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：4.181688566201245\n",
      "训练代数：975/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.6325025078169433\n",
      "训练代数：976/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.240944122715095\n",
      "训练代数：977/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.9541232662302805\n",
      "训练代数：978/2000，用时4.1s，本轮分类准确率40.1%，本轮Loss值：3.6072686572513275\n",
      "训练代数：979/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.3038938877428308\n",
      "训练代数：980/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.0733637932179247\n",
      "训练代数：981/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.966432771778474\n",
      "训练代数：982/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.8623252494172418\n",
      "训练代数：983/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：3.6014828237989263\n",
      "训练代数：984/2000，用时3.9s，本轮分类准确率39.6%，本轮Loss值：3.543664753900515\n",
      "训练代数：985/2000，用时3.9s，本轮分类准确率40.2%，本轮Loss值：4.0192512929864765\n",
      "训练代数：986/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.815736757715365\n",
      "训练代数：987/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.3668185069189236\n",
      "训练代数：988/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：3.344507321232163\n",
      "训练代数：989/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.2880901656844883\n",
      "训练代数：990/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.204618688964726\n",
      "训练代数：991/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.0423617186456626\n",
      "训练代数：992/2000，用时3.9s，本轮分类准确率39.3%，本轮Loss值：3.8022674493362216\n",
      "训练代数：993/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.522724286663248\n",
      "训练代数：994/2000，用时3.9s，本轮分类准确率39.6%，本轮Loss值：3.728706532195676\n",
      "训练代数：995/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：2.677109662770866\n",
      "训练代数：996/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：4.061827051980103\n",
      "训练代数：997/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.55967538635266\n",
      "训练代数：998/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.26758916029857\n",
      "训练代数：999/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.958518986273299\n",
      "训练代数：1000/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：3.1716979990358483\n",
      "训练代数：1001/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.8768390337848073\n",
      "训练代数：1002/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：3.280381075274195\n",
      "训练代数：1003/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.1051592354065605\n",
      "训练代数：1004/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.6186373246465307\n",
      "训练代数：1005/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.7976966961230345\n",
      "训练代数：1006/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.302073694334382\n",
      "训练代数：1007/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.642486678294509\n",
      "训练代数：1008/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.3202495320697123\n",
      "训练代数：1009/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.9806884813374666\n",
      "训练代数：1010/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.4452592870161256\n",
      "训练代数：1011/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：2.514261114201068\n",
      "训练代数：1012/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.1380378102634667\n",
      "训练代数：1013/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.090829505133044\n",
      "训练代数：1014/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.7075697617009693\n",
      "训练代数：1015/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.1665050653617355\n",
      "训练代数：1016/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.1532911257646363\n",
      "训练代数：1017/2000，用时4.0s，本轮分类准确率30.5%，本轮Loss值：8.484185048169326\n",
      "训练代数：1018/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.770380729222677\n",
      "训练代数：1019/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.713393929296777\n",
      "训练代数：1020/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.888144712881845\n",
      "训练代数：1021/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.1996862640623873\n",
      "训练代数：1022/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.6888167119907678\n",
      "训练代数：1023/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.672180057697625\n",
      "训练代数：1024/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：2.7267092775053583\n",
      "训练代数：1025/2000，用时4.0s，本轮分类准确率35.7%，本轮Loss值：6.806869323167237\n",
      "训练代数：1026/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.674462424780444\n",
      "训练代数：1027/2000，用时3.9s，本轮分类准确率39.6%，本轮Loss值：3.1798757257223484\n",
      "训练代数：1028/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.7367996706210307\n",
      "训练代数：1029/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.6286980043378123\n",
      "训练代数：1030/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.551538201680887\n",
      "训练代数：1031/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.593968750421811\n",
      "训练代数：1032/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：3.16726049195683\n",
      "训练代数：1033/2000，用时4.1s，本轮分类准确率40.0%，本轮Loss值：3.1378021340092856\n",
      "训练代数：1034/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.026536420709524\n",
      "训练代数：1035/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.4389171756391024\n",
      "训练代数：1036/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：4.342523836831527\n",
      "训练代数：1037/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.398875064880457\n",
      "训练代数：1038/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.475910412336637\n",
      "训练代数：1039/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：4.496719300396637\n",
      "训练代数：1040/2000，用时3.9s，本轮分类准确率40.2%，本轮Loss值：3.569812554936496\n",
      "训练代数：1041/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.985248274023223\n",
      "训练代数：1042/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.6089650941082483\n",
      "训练代数：1043/2000，用时4.0s，本轮分类准确率40.4%，本轮Loss值：2.9365086939881535\n",
      "训练代数：1044/2000，用时4.0s，本轮分类准确率40.5%，本轮Loss值：3.956084394358348\n",
      "训练代数：1045/2000，用时4.0s，本轮分类准确率32.0%，本轮Loss值：6.681045681709361\n",
      "训练代数：1046/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.222611556513942\n",
      "训练代数：1047/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.170837020495981\n",
      "训练代数：1048/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.0835018697155676\n",
      "训练代数：1049/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.5154416729954505\n",
      "训练代数：1050/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.011055935603454\n",
      "训练代数：1051/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.4924198854476627\n",
      "训练代数：1052/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.09532332335215\n",
      "训练代数：1053/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.4132004438821384\n",
      "训练代数：1054/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.707566854131892\n",
      "训练代数：1055/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.1777942208836576\n",
      "训练代数：1056/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.466924532389112\n",
      "训练代数：1057/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.740434699079782\n",
      "训练代数：1058/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.3601205182715175\n",
      "训练代数：1059/2000，用时4.0s，本轮分类准确率38.1%，本轮Loss值：3.7982195185340544\n",
      "训练代数：1060/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：2.6527264327089823\n",
      "训练代数：1061/2000，用时4.0s，本轮分类准确率38.7%，本轮Loss值：2.6337809920575834\n",
      "训练代数：1062/2000，用时4.0s，本轮分类准确率37.0%，本轮Loss值：3.203341307109466\n",
      "训练代数：1063/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.786849082187575\n",
      "训练代数：1064/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.638584502030653\n",
      "训练代数：1065/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.9622471434372697\n",
      "训练代数：1066/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.852642222583441\n",
      "训练代数：1067/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.236242645326357\n",
      "训练代数：1068/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.265127119570039\n",
      "训练代数：1069/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.088033830938064\n",
      "训练代数：1070/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.6030648130478737\n",
      "训练代数：1071/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.350025236573413\n",
      "训练代数：1072/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.8939117161114383\n",
      "训练代数：1073/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.1376906386748487\n",
      "训练代数：1074/2000，用时4.0s，本轮分类准确率40.3%，本轮Loss值：3.855236876061994\n",
      "训练代数：1075/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.210765385722269\n",
      "训练代数：1076/2000，用时4.1s，本轮分类准确率39.6%，本轮Loss值：3.2486310968848158\n",
      "训练代数：1077/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.412465095367364\n",
      "训练代数：1078/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.117406335911755\n",
      "训练代数：1079/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.6349282420945457\n",
      "训练代数：1080/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.3989063724684883\n",
      "训练代数：1081/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.8636435346657008\n",
      "训练代数：1082/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.2650731102714756\n",
      "训练代数：1083/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.0117667670137878\n",
      "训练代数：1084/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.5065287602716153\n",
      "训练代数：1085/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.028714678302831\n",
      "训练代数：1086/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.6072773938772116\n",
      "训练代数：1087/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.8964434920113318\n",
      "训练代数：1088/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：4.848304615982178\n",
      "训练代数：1089/2000，用时3.8s，本轮分类准确率40.0%，本轮Loss值：3.628893899448909\n",
      "训练代数：1090/2000，用时3.8s，本轮分类准确率40.0%，本轮Loss值：3.4294588977569562\n",
      "训练代数：1091/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.920589987896227\n",
      "训练代数：1092/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.019548017170848\n",
      "训练代数：1093/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：4.20935228853607\n",
      "训练代数：1094/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：3.4871386238746593\n",
      "训练代数：1095/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.4000963286125936\n",
      "训练代数：1096/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.2591891807343645\n",
      "训练代数：1097/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.571240281191109\n",
      "训练代数：1098/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.7997398996818674\n",
      "训练代数：1099/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：4.367377605346758\n",
      "训练代数：1100/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.6758111610496145\n",
      "训练代数：1101/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.75043942612904\n",
      "训练代数：1102/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.171962423360702\n",
      "训练代数：1103/2000，用时3.9s，本轮分类准确率38.7%，本轮Loss值：3.42745490436441\n",
      "训练代数：1104/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.1245666227643794\n",
      "训练代数：1105/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.0958780017588823\n",
      "训练代数：1106/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：2.9138899250624006\n",
      "训练代数：1107/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：2.7595200484470666\n",
      "训练代数：1108/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.6082707707108908\n",
      "训练代数：1109/2000，用时4.0s，本轮分类准确率40.3%，本轮Loss值：3.055627868342256\n",
      "训练代数：1110/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.194557410727481\n",
      "训练代数：1111/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：3.5630832595392206\n",
      "训练代数：1112/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.7868912065197664\n",
      "训练代数：1113/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.3285538532925214\n",
      "训练代数：1114/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.7951548691734502\n",
      "训练代数：1115/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.280758588933145\n",
      "训练代数：1116/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.6193770337445614\n",
      "训练代数：1117/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.82473922506029\n",
      "训练代数：1118/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.8652532420266255\n",
      "训练代数：1119/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.435817687651647\n",
      "训练代数：1120/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.087971879441608\n",
      "训练代数：1121/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.5810643826891577\n",
      "训练代数：1122/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.578429789776962\n",
      "训练代数：1123/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.8074373483596617\n",
      "训练代数：1124/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.058297242610118\n",
      "训练代数：1125/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.403852207767025\n",
      "训练代数：1126/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：2.9452139498411696\n",
      "训练代数：1127/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.4077828132913455\n",
      "训练代数：1128/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.720522404339795\n",
      "训练代数：1129/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.966704170699205\n",
      "训练代数：1130/2000，用时3.9s，本轮分类准确率39.4%，本轮Loss值：3.3470106660993393\n",
      "训练代数：1131/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.4188145245924204\n",
      "训练代数：1132/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：5.096220460692163\n",
      "训练代数：1133/2000，用时3.9s，本轮分类准确率38.0%，本轮Loss值：3.8605630160868287\n",
      "训练代数：1134/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.906765440126449\n",
      "训练代数：1135/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.069467768251241\n",
      "训练代数：1136/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：3.81874971380748\n",
      "训练代数：1137/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：3.467326956873046\n",
      "训练代数：1138/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：4.463298119210004\n",
      "训练代数：1139/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.515800210954936\n",
      "训练代数：1140/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.882699215850633\n",
      "训练代数：1141/2000，用时3.9s，本轮分类准确率39.6%，本轮Loss值：3.935801287186004\n",
      "训练代数：1142/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.147920367488621\n",
      "训练代数：1143/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.7084576293424987\n",
      "训练代数：1144/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：2.8752438060945424\n",
      "训练代数：1145/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：2.993372951834343\n",
      "训练代数：1146/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：3.7686379009838733\n",
      "训练代数：1147/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.2902992797180417\n",
      "训练代数：1148/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.791178537330103\n",
      "训练代数：1149/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.5579870694179645\n",
      "训练代数：1150/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：2.8926379966631885\n",
      "训练代数：1151/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.065198095357121\n",
      "训练代数：1152/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.5324179158707723\n",
      "训练代数：1153/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.520323678653574\n",
      "训练代数：1154/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.8653351222274637\n",
      "训练代数：1155/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：4.191225315288134\n",
      "训练代数：1156/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.2689135121073063\n",
      "训练代数：1157/2000，用时4.1s，本轮分类准确率39.7%，本轮Loss值：3.4839234891054276\n",
      "训练代数：1158/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：2.7140002693865113\n",
      "训练代数：1159/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.2686637106274645\n",
      "训练代数：1160/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.5174320152113636\n",
      "训练代数：1161/2000，用时4.1s，本轮分类准确率39.5%，本轮Loss值：3.5999063015435353\n",
      "训练代数：1162/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.462752619407439\n",
      "训练代数：1163/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.4245542415826775\n",
      "训练代数：1164/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.2137960141446\n",
      "训练代数：1165/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.386582800279592\n",
      "训练代数：1166/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.274459355459362\n",
      "训练代数：1167/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.6969159443841617\n",
      "训练代数：1168/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：2.5914794242626895\n",
      "训练代数：1169/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.998028323111197\n",
      "训练代数：1170/2000，用时4.0s，本轮分类准确率40.3%，本轮Loss值：4.078286877560757\n",
      "训练代数：1171/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.545163284242497\n",
      "训练代数：1172/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.139832975082053\n",
      "训练代数：1173/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.2381941645586805\n",
      "训练代数：1174/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.0695267117211698\n",
      "训练代数：1175/2000，用时4.0s，本轮分类准确率37.8%，本轮Loss值：5.690433180929309\n",
      "训练代数：1176/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.169968968506788\n",
      "训练代数：1177/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.821601298319186\n",
      "训练代数：1178/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.3125861652123776\n",
      "训练代数：1179/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.6342335811955677\n",
      "训练代数：1180/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.268782833528769\n",
      "训练代数：1181/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.267064027533243\n",
      "训练代数：1182/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.761505840969593\n",
      "训练代数：1183/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.837813678637505\n",
      "训练代数：1184/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.377649029743469\n",
      "训练代数：1185/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.917588932168846\n",
      "训练代数：1186/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.8287978005164147\n",
      "训练代数：1187/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.3079391544528987\n",
      "训练代数：1188/2000，用时4.0s，本轮分类准确率40.4%，本轮Loss值：4.028949491007734\n",
      "训练代数：1189/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.480057684660167\n",
      "训练代数：1190/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.16347808816071\n",
      "训练代数：1191/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.6660888760776515\n",
      "训练代数：1192/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.2804257632366585\n",
      "训练代数：1193/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.951830889082572\n",
      "训练代数：1194/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.6129237368830642\n",
      "训练代数：1195/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.4202062539614557\n",
      "训练代数：1196/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.2128973897051907\n",
      "训练代数：1197/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.5209355716414903\n",
      "训练代数：1198/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.9113127396654677\n",
      "训练代数：1199/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.228741034377572\n",
      "训练代数：1200/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.4953203554678596\n",
      "训练代数：1201/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.433819367223191\n",
      "训练代数：1202/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.9567726711599307\n",
      "训练代数：1203/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.9859800474092055\n",
      "训练代数：1204/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.862523411895725\n",
      "训练代数：1205/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：4.416509115630964\n",
      "训练代数：1206/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.465671771847704\n",
      "训练代数：1207/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.8195701964570246\n",
      "训练代数：1208/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：4.633430892903886\n",
      "训练代数：1209/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.463525621434499\n",
      "训练代数：1210/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.305323788523529\n",
      "训练代数：1211/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.8971542381229964\n",
      "训练代数：1212/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：3.642213297608282\n",
      "训练代数：1213/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.7099868506888583\n",
      "训练代数：1214/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.4433872108140635\n",
      "训练代数：1215/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.3044807732633443\n",
      "训练代数：1216/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：4.2843152491566965\n",
      "训练代数：1217/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.55319180816426\n",
      "训练代数：1218/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.975564098161075\n",
      "训练代数：1219/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.422201539004405\n",
      "训练代数：1220/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：2.9937113269029454\n",
      "训练代数：1221/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.216013979347062\n",
      "训练代数：1222/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：2.8330872912991736\n",
      "训练代数：1223/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.205005759727396\n",
      "训练代数：1224/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：2.966736876886992\n",
      "训练代数：1225/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.019432098087665\n",
      "训练代数：1226/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.976825839090202\n",
      "训练代数：1227/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：2.8031920000059727\n",
      "训练代数：1228/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：4.299735098994762\n",
      "训练代数：1229/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.5359549775351296\n",
      "训练代数：1230/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.04360840484519\n",
      "训练代数：1231/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.312792095417805\n",
      "训练代数：1232/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.6485175860959034\n",
      "训练代数：1233/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.0297589984727153\n",
      "训练代数：1234/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：2.49751112036667\n",
      "训练代数：1235/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：3.0834893787969038\n",
      "训练代数：1236/2000，用时4.0s，本轮分类准确率37.3%，本轮Loss值：3.5946054782068244\n",
      "训练代数：1237/2000，用时4.0s，本轮分类准确率37.8%，本轮Loss值：3.1924123238616744\n",
      "训练代数：1238/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：3.253244819906672\n",
      "训练代数：1239/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.2686750288920505\n",
      "训练代数：1240/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.3967074731030267\n",
      "训练代数：1241/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.2280814729449787\n",
      "训练代数：1242/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.814010839485755\n",
      "训练代数：1243/2000，用时4.0s，本轮分类准确率38.4%，本轮Loss值：4.027035409920811\n",
      "训练代数：1244/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.3604869522936838\n",
      "训练代数：1245/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.443589881091222\n",
      "训练代数：1246/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.371527089284035\n",
      "训练代数：1247/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.179826400819832\n",
      "训练代数：1248/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.533542045025629\n",
      "训练代数：1249/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.3042766847650484\n",
      "训练代数：1250/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.8377195474283154\n",
      "训练代数：1251/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：3.668405606710678\n",
      "训练代数：1252/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：2.9660066242423113\n",
      "训练代数：1253/2000，用时4.0s，本轮分类准确率38.3%，本轮Loss值：3.3507940604488993\n",
      "训练代数：1254/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：4.157364651051194\n",
      "训练代数：1255/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.007874308332953\n",
      "训练代数：1256/2000，用时4.0s，本轮分类准确率35.5%，本轮Loss值：4.377753520266614\n",
      "训练代数：1257/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.9489968075517594\n",
      "训练代数：1258/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.2135945999232747\n",
      "训练代数：1259/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.932643501752932\n",
      "训练代数：1260/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.5407425413461793\n",
      "训练代数：1261/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.3870270645047755\n",
      "训练代数：1262/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.626735528353413\n",
      "训练代数：1263/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：2.894703500486409\n",
      "训练代数：1264/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.2908590473037522\n",
      "训练代数：1265/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.1865253989081994\n",
      "训练代数：1266/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.4935346680965664\n",
      "训练代数：1267/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.3679760148134137\n",
      "训练代数：1268/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.6523806078055543\n",
      "训练代数：1269/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.7143531400651226\n",
      "训练代数：1270/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.831985466722037\n",
      "训练代数：1271/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.2344434365107473\n",
      "训练代数：1272/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.627064957879648\n",
      "训练代数：1273/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：2.430527735999351\n",
      "训练代数：1274/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.082850461374955\n",
      "训练代数：1275/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.1131320220877625\n",
      "训练代数：1276/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.3930690400486325\n",
      "训练代数：1277/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.269240655016435\n",
      "训练代数：1278/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.5438645901577104\n",
      "训练代数：1279/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.9406830760022755\n",
      "训练代数：1280/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：4.511075935763975\n",
      "训练代数：1281/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.625638678624091\n",
      "训练代数：1282/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.7480569316259675\n",
      "训练代数：1283/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.584727595281939\n",
      "训练代数：1284/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.016909112998647\n",
      "训练代数：1285/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.7124753874605374\n",
      "训练代数：1286/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.5217820053243685\n",
      "训练代数：1287/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.4859191894875807\n",
      "训练代数：1288/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：4.71412357742499\n",
      "训练代数：1289/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.546418457227591\n",
      "训练代数：1290/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：2.9281643196196283\n",
      "训练代数：1291/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.564208412742488\n",
      "训练代数：1292/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.067395454295749\n",
      "训练代数：1293/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.44056303518247\n",
      "训练代数：1294/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.6086153180858473\n",
      "训练代数：1295/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.7119825628654324\n",
      "训练代数：1296/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.0407435894143076\n",
      "训练代数：1297/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.264849396965329\n",
      "训练代数：1298/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.1187794338302153\n",
      "训练代数：1299/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.1318911402068492\n",
      "训练代数：1300/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.4872383094063735\n",
      "训练代数：1301/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.276470889114498\n",
      "训练代数：1302/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.8923663816665197\n",
      "训练代数：1303/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.3270602929135804\n",
      "训练代数：1304/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.6988131404035243\n",
      "训练代数：1305/2000，用时4.1s，本轮分类准确率38.2%，本轮Loss值：3.443700089576481\n",
      "训练代数：1306/2000，用时4.1s，本轮分类准确率40.0%，本轮Loss值：3.497938007578918\n",
      "训练代数：1307/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.8409374325925056\n",
      "训练代数：1308/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.3609413118678417\n",
      "训练代数：1309/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.192988366231117\n",
      "训练代数：1310/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.5765352204777683\n",
      "训练代数：1311/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.1693126072543096\n",
      "训练代数：1312/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.6417541815480687\n",
      "训练代数：1313/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.504766599180198\n",
      "训练代数：1314/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.296776685620517\n",
      "训练代数：1315/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.4731452290169758\n",
      "训练代数：1316/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.753275151356621\n",
      "训练代数：1317/2000，用时4.1s，本轮分类准确率40.0%，本轮Loss值：3.5357849746130428\n",
      "训练代数：1318/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.392522268579282\n",
      "训练代数：1319/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.648193130019598\n",
      "训练代数：1320/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.8077530099306984\n",
      "训练代数：1321/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.198941627561192\n",
      "训练代数：1322/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.6002884373896906\n",
      "训练代数：1323/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.4083455630338393\n",
      "训练代数：1324/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：4.093527303844274\n",
      "训练代数：1325/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.3185307937960546\n",
      "训练代数：1326/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.1357888589266394\n",
      "训练代数：1327/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.0587790088242515\n",
      "训练代数：1328/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.9140324947715386\n",
      "训练代数：1329/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.7636374884759816\n",
      "训练代数：1330/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.9440090108539776\n",
      "训练代数：1331/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.1661457339506796\n",
      "训练代数：1332/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.1125125251404713\n",
      "训练代数：1333/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.7975664279870585\n",
      "训练代数：1334/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.128413142995183\n",
      "训练代数：1335/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.8799197088958466\n",
      "训练代数：1336/2000，用时3.9s，本轮分类准确率38.9%，本轮Loss值：3.49668849658286\n",
      "训练代数：1337/2000，用时3.9s，本轮分类准确率38.3%，本轮Loss值：4.6952307580741435\n",
      "训练代数：1338/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.508456771019135\n",
      "训练代数：1339/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：3.478787203280274\n",
      "训练代数：1340/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.071911778004446\n",
      "训练代数：1341/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.8575588432696493\n",
      "训练代数：1342/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.180373667774245\n",
      "训练代数：1343/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.7588809713745377\n",
      "训练代数：1344/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.5074821718434834\n",
      "训练代数：1345/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.4470667998799853\n",
      "训练代数：1346/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.9052552142964716\n",
      "训练代数：1347/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：4.169271829950196\n",
      "训练代数：1348/2000，用时4.0s，本轮分类准确率38.8%，本轮Loss值：3.144063293192417\n",
      "训练代数：1349/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：4.378302404681824\n",
      "训练代数：1350/2000，用时4.0s，本轮分类准确率37.6%，本轮Loss值：3.8334249191244796\n",
      "训练代数：1351/2000，用时4.0s，本轮分类准确率33.2%，本轮Loss值：5.21429907634006\n",
      "训练代数：1352/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.935703794661424\n",
      "训练代数：1353/2000，用时4.0s，本轮分类准确率38.1%，本轮Loss值：3.669433921392465\n",
      "训练代数：1354/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.611879239981124\n",
      "训练代数：1355/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：4.356139494745582\n",
      "训练代数：1356/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.033812630997872\n",
      "训练代数：1357/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.391904347632374\n",
      "训练代数：1358/2000，用时4.0s，本轮分类准确率40.3%，本轮Loss值：3.4657730727018077\n",
      "训练代数：1359/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.128861370675054\n",
      "训练代数：1360/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.093701841508943\n",
      "训练代数：1361/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：4.305688233464712\n",
      "训练代数：1362/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：4.4303812348287295\n",
      "训练代数：1363/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.6944082161214737\n",
      "训练代数：1364/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.598555402063928\n",
      "训练代数：1365/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.4235082648794135\n",
      "训练代数：1366/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.3473297133330675\n",
      "训练代数：1367/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.6689231106734326\n",
      "训练代数：1368/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.408281478890461\n",
      "训练代数：1369/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：4.046811266499475\n",
      "训练代数：1370/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.312771900430076\n",
      "训练代数：1371/2000，用时3.9s，本轮分类准确率39.6%，本轮Loss值：3.6175288332283997\n",
      "训练代数：1372/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.4981819678595825\n",
      "训练代数：1373/2000，用时3.9s，本轮分类准确率39.3%，本轮Loss值：3.686263475780552\n",
      "训练代数：1374/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.426205647600935\n",
      "训练代数：1375/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：3.815100942681204\n",
      "训练代数：1376/2000，用时3.9s，本轮分类准确率39.4%，本轮Loss值：4.24661746668323\n",
      "训练代数：1377/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：4.646749048705042\n",
      "训练代数：1378/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.7964534612810183\n",
      "训练代数：1379/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：4.022820520764344\n",
      "训练代数：1380/2000，用时3.9s，本轮分类准确率39.7%，本轮Loss值：3.6242558309125767\n",
      "训练代数：1381/2000，用时3.9s，本轮分类准确率39.3%，本轮Loss值：3.6216329737486577\n",
      "训练代数：1382/2000，用时3.9s，本轮分类准确率39.1%，本轮Loss值：3.4555581039830714\n",
      "训练代数：1383/2000，用时3.9s，本轮分类准确率39.9%，本轮Loss值：3.249852750001452\n",
      "训练代数：1384/2000，用时3.9s，本轮分类准确率40.0%，本轮Loss值：3.1297970604780145\n",
      "训练代数：1385/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.6150657704694282\n",
      "训练代数：1386/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.7122668274905353\n",
      "训练代数：1387/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.4531642584663134\n",
      "训练代数：1388/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.864780663987452\n",
      "训练代数：1389/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.7299885523102376\n",
      "训练代数：1390/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.5316306407921703\n",
      "训练代数：1391/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.337041059307259\n",
      "训练代数：1392/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.5362099502618975\n",
      "训练代数：1393/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.9530006776975113\n",
      "训练代数：1394/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.5209006087217403\n",
      "训练代数：1395/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.449698045639502\n",
      "训练代数：1396/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.686932814254166\n",
      "训练代数：1397/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.6256859943803534\n",
      "训练代数：1398/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.5789939580702876\n",
      "训练代数：1399/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.390578663076954\n",
      "训练代数：1400/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.4296248628492094\n",
      "训练代数：1401/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：3.213217029306233\n",
      "训练代数：1402/2000，用时4.0s，本轮分类准确率37.5%，本轮Loss值：3.962435647733622\n",
      "训练代数：1403/2000，用时4.0s，本轮分类准确率35.5%，本轮Loss值：4.520846252246519\n",
      "训练代数：1404/2000，用时4.0s，本轮分类准确率34.7%，本轮Loss值：4.760873865706117\n",
      "训练代数：1405/2000，用时4.0s，本轮分类准确率32.1%，本轮Loss值：5.887252786611805\n",
      "训练代数：1406/2000，用时4.0s，本轮分类准确率33.0%，本轮Loss值：6.453023924697073\n",
      "训练代数：1407/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：4.562241676770418\n",
      "训练代数：1408/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：4.090662752910333\n",
      "训练代数：1409/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.287522136072158\n",
      "训练代数：1410/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.9614693324534556\n",
      "训练代数：1411/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.821910283287923\n",
      "训练代数：1412/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.044174225929956\n",
      "训练代数：1413/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.27196116992468\n",
      "训练代数：1414/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.1781805361725617\n",
      "训练代数：1415/2000，用时4.0s，本轮分类准确率40.4%，本轮Loss值：3.237112352312741\n",
      "训练代数：1416/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.8582979105945383\n",
      "训练代数：1417/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.1664824996758854\n",
      "训练代数：1418/2000，用时4.1s，本轮分类准确率39.5%，本轮Loss值：3.1395364734659355\n",
      "训练代数：1419/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.479087121724086\n",
      "训练代数：1420/2000，用时3.9s，本轮分类准确率39.8%，本轮Loss值：3.517526443724441\n",
      "训练代数：1421/2000，用时3.9s，本轮分类准确率39.5%，本轮Loss值：3.606852035308026\n",
      "训练代数：1422/2000，用时4.1s，本轮分类准确率40.0%，本轮Loss值：3.379170281428111\n",
      "训练代数：1423/2000，用时4.1s，本轮分类准确率40.0%，本轮Loss值：3.5207298582977047\n",
      "训练代数：1424/2000，用时4.1s，本轮分类准确率39.9%，本轮Loss值：4.189314529561765\n",
      "训练代数：1425/2000，用时4.2s，本轮分类准确率39.2%，本轮Loss值：2.914660914039442\n",
      "训练代数：1426/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.339614800058476\n",
      "训练代数：1427/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.7350449443238745\n",
      "训练代数：1428/2000，用时4.0s，本轮分类准确率40.4%，本轮Loss值：3.5505532692213224\n",
      "训练代数：1429/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.7623187318743305\n",
      "训练代数：1430/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：4.434996823743418\n",
      "训练代数：1431/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.6474551368813026\n",
      "训练代数：1432/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.454485163283394\n",
      "训练代数：1433/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.57707024148437\n",
      "训练代数：1434/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：3.345766973529038\n",
      "训练代数：1435/2000，用时4.0s，本轮分类准确率37.3%，本轮Loss值：2.978886732816079\n",
      "训练代数：1436/2000，用时4.0s，本轮分类准确率37.3%，本轮Loss值：2.7468267268846374\n",
      "训练代数：1437/2000，用时4.0s，本轮分类准确率33.7%，本轮Loss值：4.551147459501476\n",
      "训练代数：1438/2000，用时4.0s，本轮分类准确率36.8%，本轮Loss值：5.044049679261468\n",
      "训练代数：1439/2000，用时4.0s，本轮分类准确率31.0%，本轮Loss值：5.274246951665714\n",
      "训练代数：1440/2000，用时4.0s，本轮分类准确率38.1%，本轮Loss值：7.124084879476766\n",
      "训练代数：1441/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：4.310216637735093\n",
      "训练代数：1442/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：3.7451348633720727\n",
      "训练代数：1443/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.7198501016341963\n",
      "训练代数：1444/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.684882616233878\n",
      "训练代数：1445/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.1844350450881365\n",
      "训练代数：1446/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：2.9667140006979595\n",
      "训练代数：1447/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：3.243237547362301\n",
      "训练代数：1448/2000，用时4.0s，本轮分类准确率38.6%，本轮Loss值：4.096559695589744\n",
      "训练代数：1449/2000，用时4.1s，本轮分类准确率35.3%，本轮Loss值：3.903227005949782\n",
      "训练代数：1450/2000，用时4.0s，本轮分类准确率37.9%，本轮Loss值：4.195991572890375\n",
      "训练代数：1451/2000，用时4.0s，本轮分类准确率37.8%，本轮Loss值：3.5401512758480522\n",
      "训练代数：1452/2000，用时4.0s，本轮分类准确率37.0%，本轮Loss值：5.077667874989902\n",
      "训练代数：1453/2000，用时4.1s，本轮分类准确率39.6%，本轮Loss值：4.643404770220627\n",
      "训练代数：1454/2000，用时4.1s，本轮分类准确率39.9%，本轮Loss值：3.909124247476052\n",
      "训练代数：1455/2000，用时4.1s，本轮分类准确率39.5%，本轮Loss值：3.6185921252602045\n",
      "训练代数：1456/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.2274122678312667\n",
      "训练代数：1457/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：3.3123839316915933\n",
      "训练代数：1458/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.446027414205642\n",
      "训练代数：1459/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.673668931008615\n",
      "训练代数：1460/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：4.125202612891471\n",
      "训练代数：1461/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：2.995577355265675\n",
      "训练代数：1462/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.401586282399427\n",
      "训练代数：1463/2000，用时4.1s，本轮分类准确率39.6%，本轮Loss值：3.6833793892528064\n",
      "训练代数：1464/2000，用时4.1s，本轮分类准确率38.7%，本轮Loss值：3.524868073699534\n",
      "训练代数：1465/2000，用时4.0s，本轮分类准确率37.9%，本轮Loss值：3.9060476934319808\n",
      "训练代数：1466/2000，用时4.0s，本轮分类准确率33.8%，本轮Loss值：3.9982709677777732\n",
      "训练代数：1467/2000，用时4.1s，本轮分类准确率37.9%，本轮Loss值：4.9108489950503325\n",
      "训练代数：1468/2000，用时4.0s，本轮分类准确率36.7%，本轮Loss值：9.536095733588832\n",
      "训练代数：1469/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.4809362274436295\n",
      "训练代数：1470/2000，用时4.0s，本轮分类准确率39.3%，本轮Loss值：4.465025660549651\n",
      "训练代数：1471/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：3.773163860444015\n",
      "训练代数：1472/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.530312713490403\n",
      "训练代数：1473/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.5061290184238003\n",
      "训练代数：1474/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.023079330194167\n",
      "训练代数：1475/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.187286521233818\n",
      "训练代数：1476/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：4.193212154846691\n",
      "训练代数：1477/2000，用时4.1s，本轮分类准确率40.0%，本轮Loss值：4.489105295442821\n",
      "训练代数：1478/2000，用时4.0s，本轮分类准确率39.7%，本轮Loss值：3.3400332537615185\n",
      "训练代数：1479/2000，用时4.0s，本轮分类准确率39.5%，本轮Loss值：3.474494007974721\n",
      "训练代数：1480/2000，用时4.1s，本轮分类准确率39.8%，本轮Loss值：4.178303562943611\n",
      "训练代数：1481/2000，用时4.0s，本轮分类准确率40.3%，本轮Loss值：4.007497265726218\n",
      "训练代数：1482/2000，用时4.0s，本轮分类准确率39.4%，本轮Loss值：3.646652345973197\n",
      "训练代数：1483/2000，用时4.0s，本轮分类准确率40.0%，本轮Loss值：6.746138198856738\n",
      "训练代数：1484/2000，用时4.0s，本轮分类准确率39.6%，本轮Loss值：3.151784731147006\n",
      "训练代数：1485/2000，用时4.0s，本轮分类准确率40.2%，本轮Loss值：3.302563888334896\n",
      "训练代数：1486/2000，用时4.0s，本轮分类准确率39.9%，本轮Loss值：3.38255608965772\n",
      "训练代数：1487/2000，用时4.0s，本轮分类准确率46.9%，本轮Loss值：5.619294832509018\n",
      "训练代数：1488/2000，用时4.0s，本轮分类准确率48.7%，本轮Loss值：7.469804386586591\n",
      "训练代数：1489/2000，用时4.1s，本轮分类准确率36.3%，本轮Loss值：5.987030960679673\n",
      "训练代数：1490/2000，用时4.1s，本轮分类准确率42.1%，本轮Loss值：7.23212642233305\n",
      "训练代数：1491/2000，用时4.0s，本轮分类准确率40.1%，本轮Loss值：5.182608597776571\n",
      "训练代数：1492/2000，用时4.0s，本轮分类准确率49.0%，本轮Loss值：6.255048797695247\n",
      "训练代数：1493/2000，用时4.0s，本轮分类准确率44.4%，本轮Loss值：4.219493092831939\n",
      "训练代数：1494/2000，用时4.0s，本轮分类准确率50.5%，本轮Loss值：6.582276538013349\n",
      "训练代数：1495/2000，用时4.0s，本轮分类准确率46.9%，本轮Loss值：5.989368730512957\n",
      "训练代数：1496/2000，用时4.0s，本轮分类准确率44.3%，本轮Loss值：6.835993999268224\n",
      "训练代数：1497/2000，用时4.0s，本轮分类准确率52.9%，本轮Loss值：6.117537356455993\n",
      "训练代数：1498/2000，用时4.0s，本轮分类准确率55.6%，本轮Loss值：5.828504751864886\n",
      "训练代数：1499/2000，用时4.0s，本轮分类准确率52.9%，本轮Loss值：4.256881623720307\n",
      "训练代数：1500/2000，用时4.0s，本轮分类准确率55.8%，本轮Loss值：4.420172706898217\n",
      "训练代数：1501/2000，用时4.0s，本轮分类准确率51.2%，本轮Loss值：4.75326579284893\n",
      "训练代数：1502/2000，用时4.1s，本轮分类准确率47.1%，本轮Loss值：4.841492909998258\n",
      "训练代数：1503/2000，用时4.0s，本轮分类准确率56.2%，本轮Loss值：4.325921997152073\n",
      "训练代数：1504/2000，用时4.0s，本轮分类准确率54.4%，本轮Loss值：5.116040774269405\n",
      "训练代数：1505/2000，用时4.0s，本轮分类准确率53.3%，本轮Loss值：5.341690386745758\n",
      "训练代数：1506/2000，用时4.0s，本轮分类准确率55.1%，本轮Loss值：4.553839263920858\n",
      "训练代数：1507/2000，用时4.0s，本轮分类准确率56.4%，本轮Loss值：4.228723501425731\n",
      "训练代数：1508/2000，用时4.0s，本轮分类准确率55.5%，本轮Loss值：3.6368908411497727\n",
      "训练代数：1509/2000，用时4.0s，本轮分类准确率53.6%，本轮Loss值：4.482808527313643\n",
      "训练代数：1510/2000，用时4.0s，本轮分类准确率55.6%，本轮Loss值：4.612316366090866\n",
      "训练代数：1511/2000，用时4.0s，本轮分类准确率57.7%，本轮Loss值：4.083839393278191\n",
      "训练代数：1512/2000，用时4.2s，本轮分类准确率55.9%，本轮Loss值：3.753729733090592\n",
      "训练代数：1513/2000，用时4.0s，本轮分类准确率55.7%，本轮Loss值：4.344002562914968\n",
      "训练代数：1514/2000，用时3.9s，本轮分类准确率55.0%，本轮Loss值：4.207465388964417\n",
      "训练代数：1515/2000，用时4.0s，本轮分类准确率47.9%，本轮Loss值：5.816551001459428\n",
      "训练代数：1516/2000，用时4.0s，本轮分类准确率54.0%，本轮Loss值：4.712204519982906\n",
      "训练代数：1517/2000，用时4.0s，本轮分类准确率57.3%，本轮Loss值：4.917057610303309\n",
      "训练代数：1518/2000，用时4.1s，本轮分类准确率58.4%，本轮Loss值：4.601409674773084\n",
      "训练代数：1519/2000，用时4.0s，本轮分类准确率57.5%，本轮Loss值：3.948560457168169\n",
      "训练代数：1520/2000，用时4.0s，本轮分类准确率58.1%，本轮Loss值：4.154158275209175\n",
      "训练代数：1521/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：4.555760675693054\n",
      "训练代数：1522/2000，用时4.0s，本轮分类准确率57.0%，本轮Loss值：3.7476875109922587\n",
      "训练代数：1523/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：4.083127539327049\n",
      "训练代数：1524/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.9576963993438468\n",
      "训练代数：1525/2000，用时4.0s，本轮分类准确率57.4%，本轮Loss值：3.1385986744298178\n",
      "训练代数：1526/2000，用时4.0s，本轮分类准确率57.9%，本轮Loss值：3.3666464407953898\n",
      "训练代数：1527/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：3.882098581507711\n",
      "训练代数：1528/2000，用时4.0s，本轮分类准确率58.1%，本轮Loss值：4.060694432302064\n",
      "训练代数：1529/2000，用时4.0s，本轮分类准确率57.5%，本轮Loss值：4.167711611667026\n",
      "训练代数：1530/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：3.8883354723464265\n",
      "训练代数：1531/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：3.4180958597107436\n",
      "训练代数：1532/2000，用时4.0s，本轮分类准确率58.3%，本轮Loss值：3.2558235405378326\n",
      "训练代数：1533/2000，用时4.0s，本轮分类准确率57.9%，本轮Loss值：3.650028332059864\n",
      "训练代数：1534/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.6744973527143174\n",
      "训练代数：1535/2000，用时4.0s，本轮分类准确率60.0%，本轮Loss值：3.288167391791501\n",
      "训练代数：1536/2000，用时4.0s，本轮分类准确率58.2%，本轮Loss值：3.8520997457445723\n",
      "训练代数：1537/2000，用时4.0s，本轮分类准确率57.6%，本轮Loss值：4.346952928027581\n",
      "训练代数：1538/2000，用时4.0s，本轮分类准确率57.8%，本轮Loss值：4.165454969338932\n",
      "训练代数：1539/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：4.75414069447945\n",
      "训练代数：1540/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：3.7862778388452916\n",
      "训练代数：1541/2000，用时4.0s，本轮分类准确率56.6%，本轮Loss值：5.003462008349752\n",
      "训练代数：1542/2000，用时4.1s，本轮分类准确率52.7%，本轮Loss值：4.701205523616364\n",
      "训练代数：1543/2000，用时4.0s，本轮分类准确率36.8%，本轮Loss值：7.203568985858252\n",
      "训练代数：1544/2000，用时4.0s，本轮分类准确率26.7%，本轮Loss值：7.267441139953851\n",
      "训练代数：1545/2000，用时4.0s，本轮分类准确率30.0%，本轮Loss值：7.050728657996262\n",
      "训练代数：1546/2000，用时4.0s，本轮分类准确率29.5%，本轮Loss值：6.459368559651057\n",
      "训练代数：1547/2000，用时4.0s，本轮分类准确率29.2%，本轮Loss值：5.6605478304888495\n",
      "训练代数：1548/2000，用时4.1s，本轮分类准确率34.3%，本轮Loss值：4.902819906760499\n",
      "训练代数：1549/2000，用时4.0s，本轮分类准确率35.8%，本轮Loss值：3.7510668664374633\n",
      "训练代数：1550/2000，用时4.0s，本轮分类准确率37.5%，本轮Loss值：4.162042062760645\n",
      "训练代数：1551/2000，用时4.0s，本轮分类准确率37.4%，本轮Loss值：4.389200905743968\n",
      "训练代数：1552/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：3.727570148647092\n",
      "训练代数：1553/2000，用时4.0s，本轮分类准确率36.8%，本轮Loss值：3.62397934154057\n",
      "训练代数：1554/2000，用时4.0s，本轮分类准确率39.1%，本轮Loss值：3.920838802117069\n",
      "训练代数：1555/2000，用时4.0s，本轮分类准确率36.1%，本轮Loss值：4.298475821836564\n",
      "训练代数：1556/2000，用时4.0s，本轮分类准确率37.1%，本轮Loss值：4.015852885872997\n",
      "训练代数：1557/2000，用时4.0s，本轮分类准确率36.2%，本轮Loss值：3.4531136181819533\n",
      "训练代数：1558/2000，用时4.0s，本轮分类准确率38.0%，本轮Loss值：3.7389254050715293\n",
      "训练代数：1559/2000，用时4.0s，本轮分类准确率39.2%，本轮Loss值：3.7407044913406935\n",
      "训练代数：1560/2000，用时4.0s，本轮分类准确率37.5%，本轮Loss值：3.9263186209880074\n",
      "训练代数：1561/2000，用时4.1s，本轮分类准确率34.8%，本轮Loss值：4.214636092226146\n",
      "训练代数：1562/2000，用时4.0s，本轮分类准确率36.4%，本轮Loss值：4.465891988237013\n",
      "训练代数：1563/2000，用时4.0s，本轮分类准确率38.2%，本轮Loss值：5.390648706401396\n",
      "训练代数：1564/2000，用时4.0s，本轮分类准确率39.0%，本轮Loss值：4.474788881191986\n",
      "训练代数：1565/2000，用时4.0s，本轮分类准确率42.9%，本轮Loss值：4.804813642278498\n",
      "训练代数：1566/2000，用时4.0s，本轮分类准确率46.4%，本轮Loss值：4.857664679371178\n",
      "训练代数：1567/2000，用时4.0s，本轮分类准确率42.9%，本轮Loss值：3.5940148739628497\n",
      "训练代数：1568/2000，用时4.0s，本轮分类准确率43.3%，本轮Loss值：5.438844136567477\n",
      "训练代数：1569/2000，用时4.0s，本轮分类准确率52.1%，本轮Loss值：5.255550527361558\n",
      "训练代数：1570/2000，用时4.0s，本轮分类准确率42.0%，本轮Loss值：5.768398559307341\n",
      "训练代数：1571/2000，用时3.9s，本轮分类准确率49.4%，本轮Loss值：4.429541922223495\n",
      "训练代数：1572/2000，用时4.0s，本轮分类准确率47.2%，本轮Loss值：3.7837927398784488\n",
      "训练代数：1573/2000，用时4.0s，本轮分类准确率45.4%，本轮Loss值：5.216721908500634\n",
      "训练代数：1574/2000，用时4.0s，本轮分类准确率46.1%，本轮Loss值：4.972798804127947\n",
      "训练代数：1575/2000，用时4.0s，本轮分类准确率49.3%，本轮Loss值：4.989269897495534\n",
      "训练代数：1576/2000，用时4.0s，本轮分类准确率47.1%，本轮Loss值：4.401465023270928\n",
      "训练代数：1577/2000，用时4.0s，本轮分类准确率55.9%，本轮Loss值：4.35658047729377\n",
      "训练代数：1578/2000，用时4.0s，本轮分类准确率51.8%，本轮Loss值：3.8554161224789096\n",
      "训练代数：1579/2000，用时4.0s，本轮分类准确率56.2%，本轮Loss值：4.598418086673404\n",
      "训练代数：1580/2000，用时4.0s，本轮分类准确率52.4%，本轮Loss值：5.2587501433808885\n",
      "训练代数：1581/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：4.147940920230566\n",
      "训练代数：1582/2000，用时4.0s，本轮分类准确率56.1%，本轮Loss值：4.6758136756934245\n",
      "训练代数：1583/2000，用时4.0s，本轮分类准确率58.2%，本轮Loss值：4.187608431355978\n",
      "训练代数：1584/2000，用时4.0s，本轮分类准确率57.6%，本轮Loss值：4.47006706946866\n",
      "训练代数：1585/2000，用时4.0s，本轮分类准确率58.0%，本轮Loss值：3.110521545579826\n",
      "训练代数：1586/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：4.304853677829539\n",
      "训练代数：1587/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.9646385989673747\n",
      "训练代数：1588/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：4.370068454342149\n",
      "训练代数：1589/2000，用时4.0s，本轮分类准确率57.0%，本轮Loss值：4.796507128304149\n",
      "训练代数：1590/2000，用时4.0s，本轮分类准确率58.3%，本轮Loss值：4.047492254737477\n",
      "训练代数：1591/2000，用时4.0s，本轮分类准确率57.5%，本轮Loss值：3.5602712426333056\n",
      "训练代数：1592/2000，用时4.0s，本轮分类准确率56.8%，本轮Loss值：3.3881857988079274\n",
      "训练代数：1593/2000，用时4.0s，本轮分类准确率54.9%，本轮Loss值：4.533043213173809\n",
      "训练代数：1594/2000，用时4.0s，本轮分类准确率52.2%，本轮Loss值：4.931635209170286\n",
      "训练代数：1595/2000，用时4.0s，本轮分类准确率44.6%，本轮Loss值：6.089732133801306\n",
      "训练代数：1596/2000，用时4.0s，本轮分类准确率37.8%，本轮Loss值：6.08234947230245\n",
      "训练代数：1597/2000，用时4.0s，本轮分类准确率28.8%，本轮Loss值：7.341693585206384\n",
      "训练代数：1598/2000，用时4.0s，本轮分类准确率27.2%，本轮Loss值：6.866060758128526\n",
      "训练代数：1599/2000，用时4.0s，本轮分类准确率27.0%，本轮Loss值：5.6260612958351315\n",
      "训练代数：1600/2000，用时4.0s，本轮分类准确率28.3%，本轮Loss值：6.0767381571628105\n",
      "训练代数：1601/2000，用时4.0s，本轮分类准确率29.9%，本轮Loss值：4.944913149167246\n",
      "训练代数：1602/2000，用时4.0s，本轮分类准确率35.2%，本轮Loss值：4.724203212306395\n",
      "训练代数：1603/2000，用时4.0s，本轮分类准确率31.5%，本轮Loss值：4.818229471897683\n",
      "训练代数：1604/2000，用时4.0s，本轮分类准确率38.5%，本轮Loss值：4.256226456308275\n",
      "训练代数：1605/2000，用时4.0s，本轮分类准确率31.6%，本轮Loss值：5.016379348688463\n",
      "训练代数：1606/2000，用时4.0s，本轮分类准确率31.2%，本轮Loss值：5.677973876807255\n",
      "训练代数：1607/2000，用时4.0s，本轮分类准确率35.7%，本轮Loss值：5.834623601931287\n",
      "训练代数：1608/2000，用时4.0s，本轮分类准确率33.7%，本轮Loss值：5.165842878716944\n",
      "训练代数：1609/2000，用时4.0s，本轮分类准确率39.8%，本轮Loss值：5.041901332693078\n",
      "训练代数：1610/2000，用时4.0s，本轮分类准确率38.9%，本轮Loss值：6.532299079779929\n",
      "训练代数：1611/2000，用时4.0s，本轮分类准确率43.8%，本轮Loss值：5.09020893794569\n",
      "训练代数：1612/2000，用时4.0s，本轮分类准确率51.4%，本轮Loss值：5.861445013080168\n",
      "训练代数：1613/2000，用时4.0s，本轮分类准确率52.4%，本轮Loss值：4.657774814800701\n",
      "训练代数：1614/2000，用时4.0s，本轮分类准确率56.5%，本轮Loss值：5.001386285231439\n",
      "训练代数：1615/2000，用时4.0s，本轮分类准确率56.1%，本轮Loss值：5.51285485050701\n",
      "训练代数：1616/2000，用时4.0s，本轮分类准确率57.5%，本轮Loss值：4.032972585491507\n",
      "训练代数：1617/2000，用时4.0s，本轮分类准确率56.4%，本轮Loss值：4.309769219856918\n",
      "训练代数：1618/2000，用时4.0s，本轮分类准确率56.8%，本轮Loss值：4.239956693001417\n",
      "训练代数：1619/2000，用时4.0s，本轮分类准确率53.5%，本轮Loss值：4.147072574090845\n",
      "训练代数：1620/2000，用时4.0s，本轮分类准确率54.4%，本轮Loss值：4.116986952931061\n",
      "训练代数：1621/2000，用时4.0s，本轮分类准确率56.3%，本轮Loss值：3.375673072227019\n",
      "训练代数：1622/2000，用时4.0s，本轮分类准确率55.7%，本轮Loss值：3.513586561916541\n",
      "训练代数：1623/2000，用时4.0s，本轮分类准确率57.6%，本轮Loss值：4.6823758445042305\n",
      "训练代数：1624/2000，用时4.0s，本轮分类准确率56.1%，本轮Loss值：3.453361030916946\n",
      "训练代数：1625/2000，用时4.0s，本轮分类准确率56.7%，本轮Loss值：4.081301910780966\n",
      "训练代数：1626/2000，用时4.0s，本轮分类准确率57.2%，本轮Loss值：3.154614288598851\n",
      "训练代数：1627/2000，用时4.0s，本轮分类准确率56.2%，本轮Loss值：3.8802691419451776\n",
      "训练代数：1628/2000，用时4.0s，本轮分类准确率56.4%，本轮Loss值：3.39491179139036\n",
      "训练代数：1629/2000，用时4.0s，本轮分类准确率55.1%，本轮Loss值：3.438072742909097\n",
      "训练代数：1630/2000，用时4.1s，本轮分类准确率58.9%，本轮Loss值：3.557915539931746\n",
      "训练代数：1631/2000，用时4.0s，本轮分类准确率57.9%，本轮Loss值：3.7875213407621287\n",
      "训练代数：1632/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：4.102393622827213\n",
      "训练代数：1633/2000，用时4.0s，本轮分类准确率58.3%，本轮Loss值：3.2558217576907027\n",
      "训练代数：1634/2000，用时4.0s，本轮分类准确率57.9%，本轮Loss值：4.103621399702644\n",
      "训练代数：1635/2000，用时4.0s，本轮分类准确率56.9%，本轮Loss值：4.1736479708666305\n",
      "训练代数：1636/2000，用时4.0s，本轮分类准确率56.6%，本轮Loss值：3.9547911586499955\n",
      "训练代数：1637/2000，用时4.0s，本轮分类准确率58.0%，本轮Loss值：3.875263940863087\n",
      "训练代数：1638/2000，用时4.0s，本轮分类准确率59.4%，本轮Loss值：4.326472677271212\n",
      "训练代数：1639/2000，用时4.0s，本轮分类准确率58.1%，本轮Loss值：3.594567406082632\n",
      "训练代数：1640/2000，用时4.0s，本轮分类准确率58.1%，本轮Loss值：2.9681440140145456\n",
      "训练代数：1641/2000，用时4.0s，本轮分类准确率57.0%，本轮Loss值：3.4822054912109595\n",
      "训练代数：1642/2000，用时4.0s，本轮分类准确率58.1%，本轮Loss值：3.580766901554899\n",
      "训练代数：1643/2000，用时4.1s，本轮分类准确率57.9%，本轮Loss值：4.305591492104568\n",
      "训练代数：1644/2000，用时4.1s，本轮分类准确率58.6%，本轮Loss值：3.942127610585003\n",
      "训练代数：1645/2000，用时4.0s，本轮分类准确率57.3%，本轮Loss值：3.899922082080637\n",
      "训练代数：1646/2000，用时4.0s，本轮分类准确率57.9%，本轮Loss值：3.5875636122369654\n",
      "训练代数：1647/2000，用时4.0s，本轮分类准确率57.3%，本轮Loss值：3.503010812601505\n",
      "训练代数：1648/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.9529382933998365\n",
      "训练代数：1649/2000，用时4.0s，本轮分类准确率58.1%，本轮Loss值：2.883047709572284\n",
      "训练代数：1650/2000，用时4.0s，本轮分类准确率58.0%，本轮Loss值：3.214241377908644\n",
      "训练代数：1651/2000，用时4.0s，本轮分类准确率57.7%，本轮Loss值：3.739502569645952\n",
      "训练代数：1652/2000，用时4.0s，本轮分类准确率56.6%，本轮Loss值：4.4163673304512745\n",
      "训练代数：1653/2000，用时4.0s，本轮分类准确率56.7%，本轮Loss值：4.636655794363617\n",
      "训练代数：1654/2000，用时4.0s，本轮分类准确率58.3%，本轮Loss值：3.091431894520331\n",
      "训练代数：1655/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.6199796272348097\n",
      "训练代数：1656/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：4.301344430147577\n",
      "训练代数：1657/2000，用时4.0s，本轮分类准确率57.6%，本轮Loss值：3.573420970232405\n",
      "训练代数：1658/2000，用时3.9s，本轮分类准确率57.1%，本轮Loss值：3.8824322912076417\n",
      "训练代数：1659/2000，用时3.9s，本轮分类准确率57.7%，本轮Loss值：3.6743312459674824\n",
      "训练代数：1660/2000，用时4.0s，本轮分类准确率56.8%，本轮Loss值：4.066851614379881\n",
      "训练代数：1661/2000，用时4.0s，本轮分类准确率56.9%，本轮Loss值：3.7651531364919464\n",
      "训练代数：1662/2000，用时3.9s，本轮分类准确率57.8%，本轮Loss值：3.6191546815732814\n",
      "训练代数：1663/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.9697429796406025\n",
      "训练代数：1664/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：3.2256898865594423\n",
      "训练代数：1665/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：4.098433859073995\n",
      "训练代数：1666/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：4.011381563090538\n",
      "训练代数：1667/2000，用时4.0s，本轮分类准确率56.4%，本轮Loss值：4.30269103228737\n",
      "训练代数：1668/2000，用时4.0s，本轮分类准确率58.3%，本轮Loss值：3.3608045991923747\n",
      "训练代数：1669/2000，用时4.0s，本轮分类准确率57.4%，本轮Loss值：3.8592318961666026\n",
      "训练代数：1670/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：3.5957939137234973\n",
      "训练代数：1671/2000，用时4.0s，本轮分类准确率58.2%，本轮Loss值：4.524356676205983\n",
      "训练代数：1672/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：3.4862744686043583\n",
      "训练代数：1673/2000，用时4.0s，本轮分类准确率56.2%，本轮Loss值：4.792687965825033\n",
      "训练代数：1674/2000，用时4.0s，本轮分类准确率58.0%，本轮Loss值：3.2385741508992796\n",
      "训练代数：1675/2000，用时4.0s，本轮分类准确率59.2%，本轮Loss值：3.560407775172416\n",
      "训练代数：1676/2000，用时4.0s，本轮分类准确率59.0%，本轮Loss值：3.766693354205927\n",
      "训练代数：1677/2000，用时4.0s，本轮分类准确率56.5%，本轮Loss值：3.973783056331424\n",
      "训练代数：1678/2000，用时4.0s，本轮分类准确率57.5%，本轮Loss值：4.6539439068918265\n",
      "训练代数：1679/2000，用时4.0s，本轮分类准确率57.0%，本轮Loss值：4.00674054086299\n",
      "训练代数：1680/2000，用时4.1s，本轮分类准确率58.8%，本轮Loss值：3.5077065711144457\n",
      "训练代数：1681/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：4.159485261839199\n",
      "训练代数：1682/2000，用时4.0s，本轮分类准确率58.8%，本轮Loss值：4.146048285983047\n",
      "训练代数：1683/2000，用时4.0s，本轮分类准确率57.9%，本轮Loss值：3.2606638041346394\n",
      "训练代数：1684/2000，用时4.0s，本轮分类准确率58.2%，本轮Loss值：3.349946038427067\n",
      "训练代数：1685/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.105346858644245\n",
      "训练代数：1686/2000，用时4.0s，本轮分类准确率58.8%，本轮Loss值：3.4432047748459675\n",
      "训练代数：1687/2000，用时4.0s，本轮分类准确率57.5%，本轮Loss值：4.049645569979258\n",
      "训练代数：1688/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.4384282980667313\n",
      "训练代数：1689/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：3.661168270783196\n",
      "训练代数：1690/2000，用时4.0s，本轮分类准确率59.2%，本轮Loss值：3.3119981032799783\n",
      "训练代数：1691/2000，用时4.0s，本轮分类准确率59.2%，本轮Loss值：3.0871056298886743\n",
      "训练代数：1692/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：3.7607322084076173\n",
      "训练代数：1693/2000，用时4.0s，本轮分类准确率56.7%，本轮Loss值：4.203911688045989\n",
      "训练代数：1694/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：4.11998521185096\n",
      "训练代数：1695/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.430518053174535\n",
      "训练代数：1696/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：4.622884789934202\n",
      "训练代数：1697/2000，用时4.0s，本轮分类准确率59.4%，本轮Loss值：3.4504418339321403\n",
      "训练代数：1698/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：3.452856321818075\n",
      "训练代数：1699/2000，用时4.1s，本轮分类准确率56.6%，本轮Loss值：5.065878980055501\n",
      "训练代数：1700/2000，用时4.1s，本轮分类准确率59.4%，本轮Loss值：4.484766693547871\n",
      "训练代数：1701/2000，用时4.1s，本轮分类准确率57.7%，本轮Loss值：3.66973681105614\n",
      "训练代数：1702/2000，用时4.2s，本轮分类准确率58.6%，本轮Loss值：3.5794130142322844\n",
      "训练代数：1703/2000，用时4.1s，本轮分类准确率59.1%，本轮Loss值：3.919650134704122\n",
      "训练代数：1704/2000，用时4.0s，本轮分类准确率59.2%，本轮Loss值：3.878518891540034\n",
      "训练代数：1705/2000，用时4.0s，本轮分类准确率57.3%，本轮Loss值：4.592996954247636\n",
      "训练代数：1706/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：3.702848224397912\n",
      "训练代数：1707/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：2.98050604823091\n",
      "训练代数：1708/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：3.719129942520257\n",
      "训练代数：1709/2000，用时4.0s，本轮分类准确率57.4%，本轮Loss值：3.8142974015464213\n",
      "训练代数：1710/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：3.8085674732878774\n",
      "训练代数：1711/2000，用时4.0s，本轮分类准确率58.8%，本轮Loss值：3.7420789441724054\n",
      "训练代数：1712/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.3861007539121544\n",
      "训练代数：1713/2000，用时4.0s，本轮分类准确率57.6%，本轮Loss值：3.2110176350087443\n",
      "训练代数：1714/2000，用时4.0s，本轮分类准确率56.6%，本轮Loss值：4.236887492418143\n",
      "训练代数：1715/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：4.067136341659671\n",
      "训练代数：1716/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.0522919920527274\n",
      "训练代数：1717/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：3.723183628220616\n",
      "训练代数：1718/2000，用时4.0s，本轮分类准确率58.3%，本轮Loss值：3.203705132401089\n",
      "训练代数：1719/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：4.242324502653323\n",
      "训练代数：1720/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：4.286260082777013\n",
      "训练代数：1721/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：4.020383982113151\n",
      "训练代数：1722/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.2944337137556645\n",
      "训练代数：1723/2000，用时4.0s，本轮分类准确率59.0%，本轮Loss值：3.53186582532791\n",
      "训练代数：1724/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.2094649580125436\n",
      "训练代数：1725/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.3672009347480296\n",
      "训练代数：1726/2000，用时4.0s，本轮分类准确率57.1%，本轮Loss值：2.472859985697845\n",
      "训练代数：1727/2000，用时4.0s，本轮分类准确率57.0%，本轮Loss值：4.323872925226588\n",
      "训练代数：1728/2000，用时4.0s，本轮分类准确率58.8%，本轮Loss值：4.523096181806707\n",
      "训练代数：1729/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.431186889097481\n",
      "训练代数：1730/2000，用时4.1s，本轮分类准确率57.6%，本轮Loss值：3.7432611044008155\n",
      "训练代数：1731/2000，用时4.0s，本轮分类准确率57.7%，本轮Loss值：3.0314582290278964\n",
      "训练代数：1732/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.6451370217780754\n",
      "训练代数：1733/2000，用时4.0s，本轮分类准确率57.4%，本轮Loss值：3.268744719921682\n",
      "训练代数：1734/2000，用时3.9s，本轮分类准确率58.7%，本轮Loss值：3.8020977302378136\n",
      "训练代数：1735/2000，用时3.9s，本轮分类准确率58.6%，本轮Loss值：3.4486787116313193\n",
      "训练代数：1736/2000，用时4.0s，本轮分类准确率59.5%，本轮Loss值：2.83081225712377\n",
      "训练代数：1737/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：3.876757460966593\n",
      "训练代数：1738/2000，用时4.0s，本轮分类准确率59.4%，本轮Loss值：4.218434763692383\n",
      "训练代数：1739/2000，用时3.9s，本轮分类准确率57.8%，本轮Loss值：4.205066150639476\n",
      "训练代数：1740/2000，用时3.9s，本轮分类准确率58.9%，本轮Loss值：3.4506819948945067\n",
      "训练代数：1741/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.247196275018257\n",
      "训练代数：1742/2000，用时4.0s，本轮分类准确率56.7%，本轮Loss值：3.4520459158411505\n",
      "训练代数：1743/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：3.221444353431315\n",
      "训练代数：1744/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.0235665805081937\n",
      "训练代数：1745/2000，用时4.0s，本轮分类准确率59.7%，本轮Loss值：4.403164013863031\n",
      "训练代数：1746/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.4579033221713105\n",
      "训练代数：1747/2000，用时4.0s，本轮分类准确率54.0%，本轮Loss值：3.7672242928270805\n",
      "训练代数：1748/2000，用时3.9s，本轮分类准确率59.7%，本轮Loss值：5.3545979849725684\n",
      "训练代数：1749/2000，用时4.0s，本轮分类准确率56.4%，本轮Loss值：3.698310145951725\n",
      "训练代数：1750/2000，用时4.0s，本轮分类准确率59.5%，本轮Loss值：3.6827019207047895\n",
      "训练代数：1751/2000，用时4.0s，本轮分类准确率56.6%，本轮Loss值：3.466380768639192\n",
      "训练代数：1752/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.817816613619743\n",
      "训练代数：1753/2000，用时3.9s，本轮分类准确率59.4%，本轮Loss值：3.854589659750559\n",
      "训练代数：1754/2000，用时3.9s，本轮分类准确率58.8%，本轮Loss值：3.156363625661328\n",
      "训练代数：1755/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：2.871345683071435\n",
      "训练代数：1756/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.726500291333852\n",
      "训练代数：1757/2000，用时4.1s，本轮分类准确率59.5%，本轮Loss值：3.3929167872188173\n",
      "训练代数：1758/2000，用时4.0s，本轮分类准确率57.9%，本轮Loss值：3.074495990042871\n",
      "训练代数：1759/2000，用时3.9s，本轮分类准确率56.2%，本轮Loss值：4.166264376424256\n",
      "训练代数：1760/2000，用时3.9s，本轮分类准确率57.9%，本轮Loss值：4.899353983357136\n",
      "训练代数：1761/2000，用时4.0s，本轮分类准确率57.0%，本轮Loss值：4.080116021365578\n",
      "训练代数：1762/2000，用时4.0s，本轮分类准确率58.8%，本轮Loss值：3.1306911575292715\n",
      "训练代数：1763/2000，用时4.1s，本轮分类准确率59.5%，本轮Loss值：2.9148467943636747\n",
      "训练代数：1764/2000，用时3.9s，本轮分类准确率59.6%，本轮Loss值：3.9208261521229444\n",
      "训练代数：1765/2000，用时3.9s，本轮分类准确率59.3%，本轮Loss值：3.71219903679372\n",
      "训练代数：1766/2000，用时3.9s，本轮分类准确率59.4%，本轮Loss值：3.6453333758360884\n",
      "训练代数：1767/2000，用时3.9s，本轮分类准确率59.1%，本轮Loss值：4.039694302104294\n",
      "训练代数：1768/2000，用时3.9s，本轮分类准确率59.1%，本轮Loss值：3.5617699543097934\n",
      "训练代数：1769/2000，用时4.0s，本轮分类准确率56.7%，本轮Loss值：3.348484785271893\n",
      "训练代数：1770/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.892869982659107\n",
      "训练代数：1771/2000，用时3.9s，本轮分类准确率58.0%，本轮Loss值：4.050042817747778\n",
      "训练代数：1772/2000，用时3.9s，本轮分类准确率58.2%，本轮Loss值：3.8212618864728327\n",
      "训练代数：1773/2000，用时4.0s，本轮分类准确率55.6%，本轮Loss值：3.6338377107755973\n",
      "训练代数：1774/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：4.021187091358593\n",
      "训练代数：1775/2000，用时3.9s，本轮分类准确率58.7%，本轮Loss值：3.238946030574584\n",
      "训练代数：1776/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：2.95208884382929\n",
      "训练代数：1777/2000，用时3.9s，本轮分类准确率57.5%，本轮Loss值：4.098866389199332\n",
      "训练代数：1778/2000，用时4.0s，本轮分类准确率56.2%，本轮Loss值：3.9575766308220417\n",
      "训练代数：1779/2000，用时3.9s，本轮分类准确率54.3%，本轮Loss值：4.210783889258352\n",
      "训练代数：1780/2000，用时4.0s，本轮分类准确率46.4%，本轮Loss值：6.354597979381545\n",
      "训练代数：1781/2000，用时3.9s，本轮分类准确率41.9%，本轮Loss值：5.317834097938142\n",
      "训练代数：1782/2000，用时4.0s，本轮分类准确率43.8%，本轮Loss值：6.114707583224404\n",
      "训练代数：1783/2000，用时3.9s，本轮分类准确率50.8%，本轮Loss值：4.833727565560333\n",
      "训练代数：1784/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：4.216310430647403\n",
      "训练代数：1785/2000，用时4.0s，本轮分类准确率56.9%，本轮Loss值：4.643493435362165\n",
      "训练代数：1786/2000，用时4.0s，本轮分类准确率59.2%，本轮Loss值：4.1828694232152515\n",
      "训练代数：1787/2000，用时3.9s，本轮分类准确率55.2%，本轮Loss值：4.244614970786806\n",
      "训练代数：1788/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：4.412822778712813\n",
      "训练代数：1789/2000，用时3.9s，本轮分类准确率57.1%，本轮Loss值：4.8034593365136855\n",
      "训练代数：1790/2000，用时3.9s，本轮分类准确率59.1%，本轮Loss值：3.5764800120170035\n",
      "训练代数：1791/2000，用时4.0s，本轮分类准确率59.7%，本轮Loss值：3.7295425373752322\n",
      "训练代数：1792/2000，用时4.0s，本轮分类准确率59.9%，本轮Loss值：3.6043992453480143\n",
      "训练代数：1793/2000，用时4.0s，本轮分类准确率58.8%，本轮Loss值：4.0260525542995085\n",
      "训练代数：1794/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.9669619454805116\n",
      "训练代数：1795/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.6065689018635423\n",
      "训练代数：1796/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.6433250187418365\n",
      "训练代数：1797/2000，用时4.1s，本轮分类准确率58.9%，本轮Loss值：4.424617857189\n",
      "训练代数：1798/2000，用时4.0s，本轮分类准确率59.9%，本轮Loss值：3.130229127503861\n",
      "训练代数：1799/2000，用时4.1s，本轮分类准确率59.1%，本轮Loss值：2.6966307654204114\n",
      "训练代数：1800/2000，用时4.0s，本轮分类准确率59.3%，本轮Loss值：3.130135291545025\n",
      "训练代数：1801/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.545354699590129\n",
      "训练代数：1802/2000，用时4.0s，本轮分类准确率57.3%，本轮Loss值：3.5286432458658816\n",
      "训练代数：1803/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.6765576747198994\n",
      "训练代数：1804/2000，用时4.0s，本轮分类准确率59.5%，本轮Loss值：4.528383438210642\n",
      "训练代数：1805/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：3.9605785916858935\n",
      "训练代数：1806/2000，用时4.0s，本轮分类准确率59.3%，本轮Loss值：2.8511509596433426\n",
      "训练代数：1807/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.5529959953860706\n",
      "训练代数：1808/2000，用时4.0s，本轮分类准确率59.5%，本轮Loss值：3.889575038849015\n",
      "训练代数：1809/2000，用时3.9s，本轮分类准确率58.6%，本轮Loss值：3.7900781788214415\n",
      "训练代数：1810/2000，用时4.0s，本轮分类准确率57.5%，本轮Loss值：4.643988188357682\n",
      "训练代数：1811/2000，用时4.0s，本轮分类准确率59.4%，本轮Loss值：3.734363814939681\n",
      "训练代数：1812/2000，用时4.0s，本轮分类准确率56.4%，本轮Loss值：5.873968111801899\n",
      "训练代数：1813/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：4.172870784986782\n",
      "训练代数：1814/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：3.537251676308666\n",
      "训练代数：1815/2000，用时4.1s，本轮分类准确率59.8%，本轮Loss值：3.7559501670758637\n",
      "训练代数：1816/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：3.449149516355925\n",
      "训练代数：1817/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：3.7740674673987287\n",
      "训练代数：1818/2000，用时4.0s，本轮分类准确率59.4%，本轮Loss值：3.322394589631395\n",
      "训练代数：1819/2000，用时4.0s，本轮分类准确率59.4%，本轮Loss值：3.794329530309389\n",
      "训练代数：1820/2000，用时3.9s，本轮分类准确率58.6%，本轮Loss值：4.070207004142668\n",
      "训练代数：1821/2000，用时3.9s，本轮分类准确率60.0%，本轮Loss值：2.7875812025952795\n",
      "训练代数：1822/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：3.784094719954342\n",
      "训练代数：1823/2000，用时3.9s，本轮分类准确率59.6%，本轮Loss值：3.89493119809359\n",
      "训练代数：1824/2000，用时4.0s，本轮分类准确率60.1%，本轮Loss值：3.93128727460535\n",
      "训练代数：1825/2000，用时3.9s，本轮分类准确率60.1%，本轮Loss值：3.6706888701360443\n",
      "训练代数：1826/2000，用时3.9s，本轮分类准确率59.0%，本轮Loss值：4.611829700624188\n",
      "训练代数：1827/2000，用时3.9s，本轮分类准确率59.8%，本轮Loss值：3.5487830665727644\n",
      "训练代数：1828/2000，用时4.0s，本轮分类准确率59.7%，本轮Loss值：3.1828819687803245\n",
      "训练代数：1829/2000，用时4.0s，本轮分类准确率58.8%，本轮Loss值：3.147232405747269\n",
      "训练代数：1830/2000，用时3.9s，本轮分类准确率58.4%，本轮Loss值：3.9664783297547417\n",
      "训练代数：1831/2000，用时3.9s，本轮分类准确率59.8%，本轮Loss值：3.386657593917923\n",
      "训练代数：1832/2000，用时3.9s，本轮分类准确率58.9%，本轮Loss值：3.6940154862086816\n",
      "训练代数：1833/2000，用时3.9s，本轮分类准确率59.2%，本轮Loss值：3.843021907341324\n",
      "训练代数：1834/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：3.5862205071142315\n",
      "训练代数：1835/2000，用时4.0s，本轮分类准确率59.7%，本轮Loss值：3.3622739829874746\n",
      "训练代数：1836/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：3.716077165299487\n",
      "训练代数：1837/2000，用时4.0s，本轮分类准确率60.0%，本轮Loss值：3.4428335611940297\n",
      "训练代数：1838/2000，用时4.0s，本轮分类准确率57.0%，本轮Loss值：3.761340994372046\n",
      "训练代数：1839/2000，用时4.0s，本轮分类准确率60.2%，本轮Loss值：3.7055899733264197\n",
      "训练代数：1840/2000，用时3.9s，本轮分类准确率59.9%，本轮Loss值：3.385451876946527\n",
      "训练代数：1841/2000，用时3.9s，本轮分类准确率59.5%，本轮Loss值：2.6498259350098463\n",
      "训练代数：1842/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：3.6957360681992584\n",
      "训练代数：1843/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：4.085919649724014\n",
      "训练代数：1844/2000，用时4.0s，本轮分类准确率59.4%，本轮Loss值：4.1636873860213495\n",
      "训练代数：1845/2000，用时4.0s，本轮分类准确率58.2%，本轮Loss值：3.9303876779598284\n",
      "训练代数：1846/2000，用时4.1s，本轮分类准确率59.1%，本轮Loss值：3.1935132382505627\n",
      "训练代数：1847/2000，用时4.1s，本轮分类准确率56.3%，本轮Loss值：4.157125964424386\n",
      "训练代数：1848/2000，用时4.1s，本轮分类准确率59.0%，本轮Loss值：4.895836828623049\n",
      "训练代数：1849/2000，用时4.1s，本轮分类准确率59.6%，本轮Loss值：3.3025873940711534\n",
      "训练代数：1850/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：4.013266198814112\n",
      "训练代数：1851/2000，用时4.0s，本轮分类准确率57.8%，本轮Loss值：3.6358114547652347\n",
      "训练代数：1852/2000，用时4.0s，本轮分类准确率59.3%，本轮Loss值：4.105992841137757\n",
      "训练代数：1853/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.256627235127354\n",
      "训练代数：1854/2000，用时4.0s，本轮分类准确率60.0%，本轮Loss值：3.480109727332439\n",
      "训练代数：1855/2000，用时4.0s，本轮分类准确率59.3%，本轮Loss值：3.07642189122451\n",
      "训练代数：1856/2000，用时4.0s，本轮分类准确率59.7%，本轮Loss值：3.5376266859781422\n",
      "训练代数：1857/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.524569215926488\n",
      "训练代数：1858/2000，用时4.0s，本轮分类准确率59.3%，本轮Loss值：3.474127900100129\n",
      "训练代数：1859/2000，用时4.0s，本轮分类准确率54.4%，本轮Loss值：3.362335424714945\n",
      "训练代数：1860/2000，用时4.0s，本轮分类准确率55.9%，本轮Loss值：3.3337114578850473\n",
      "训练代数：1861/2000，用时4.0s，本轮分类准确率55.9%，本轮Loss值：3.7078819783334724\n",
      "训练代数：1862/2000，用时4.0s，本轮分类准确率55.3%，本轮Loss值：3.9078031508928897\n",
      "训练代数：1863/2000，用时4.0s，本轮分类准确率43.8%，本轮Loss值：5.314989396594853\n",
      "训练代数：1864/2000，用时4.0s，本轮分类准确率43.7%，本轮Loss值：4.842805389085627\n",
      "训练代数：1865/2000，用时4.0s，本轮分类准确率43.7%，本轮Loss值：4.829764003681433\n",
      "训练代数：1866/2000，用时4.0s，本轮分类准确率49.7%，本轮Loss值：4.532659452306007\n",
      "训练代数：1867/2000，用时4.0s，本轮分类准确率49.5%，本轮Loss值：4.050971396565684\n",
      "训练代数：1868/2000，用时4.0s，本轮分类准确率53.3%，本轮Loss值：4.595026510529839\n",
      "训练代数：1869/2000，用时4.0s，本轮分类准确率41.8%，本轮Loss值：6.183172739780441\n",
      "训练代数：1870/2000，用时4.0s，本轮分类准确率33.6%，本轮Loss值：7.052677997552479\n",
      "训练代数：1871/2000，用时4.1s，本轮分类准确率31.9%，本轮Loss值：5.553466050826526\n",
      "训练代数：1872/2000，用时3.9s，本轮分类准确率37.3%，本轮Loss值：4.4915676005375245\n",
      "训练代数：1873/2000，用时4.0s，本轮分类准确率37.7%，本轮Loss值：3.7532931394606974\n",
      "训练代数：1874/2000，用时4.0s，本轮分类准确率40.5%，本轮Loss值：3.8527108848075557\n",
      "训练代数：1875/2000，用时3.9s，本轮分类准确率40.1%，本轮Loss值：4.524000331010794\n",
      "训练代数：1876/2000，用时4.0s，本轮分类准确率42.6%，本轮Loss值：4.169179765211643\n",
      "训练代数：1877/2000，用时4.0s，本轮分类准确率42.9%，本轮Loss值：3.512391419364903\n",
      "训练代数：1878/2000，用时4.0s，本轮分类准确率42.9%，本轮Loss值：3.473434778673527\n",
      "训练代数：1879/2000，用时4.0s，本轮分类准确率42.9%，本轮Loss值：3.0966925785842263\n",
      "训练代数：1880/2000，用时4.0s，本轮分类准确率50.0%，本轮Loss值：4.777311691049758\n",
      "训练代数：1881/2000，用时4.0s，本轮分类准确率46.5%，本轮Loss值：4.63814990677062\n",
      "训练代数：1882/2000，用时4.0s，本轮分类准确率51.8%，本轮Loss值：4.8963544666110845\n",
      "训练代数：1883/2000，用时4.0s，本轮分类准确率55.7%，本轮Loss值：4.520872931677842\n",
      "训练代数：1884/2000，用时4.0s，本轮分类准确率53.5%，本轮Loss值：4.142183272545039\n",
      "训练代数：1885/2000，用时4.0s，本轮分类准确率56.0%，本轮Loss值：4.442678969554424\n",
      "训练代数：1886/2000，用时4.0s，本轮分类准确率58.2%，本轮Loss值：4.002163653637396\n",
      "训练代数：1887/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：3.7507378215587837\n",
      "训练代数：1888/2000，用时4.0s，本轮分类准确率59.3%，本轮Loss值：3.57561897166035\n",
      "训练代数：1889/2000，用时3.9s，本轮分类准确率59.1%，本轮Loss值：3.631743535386417\n",
      "训练代数：1890/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：4.262586317231888\n",
      "训练代数：1891/2000，用时4.0s，本轮分类准确率57.3%，本轮Loss值：3.7941139432207462\n",
      "训练代数：1892/2000，用时4.0s，本轮分类准确率58.5%，本轮Loss值：3.744118639635798\n",
      "训练代数：1893/2000，用时4.0s，本轮分类准确率58.6%，本轮Loss值：3.8504462767638814\n",
      "训练代数：1894/2000，用时3.9s，本轮分类准确率59.2%，本轮Loss值：3.9963980716035508\n",
      "训练代数：1895/2000，用时4.0s，本轮分类准确率58.0%，本轮Loss值：3.578374140231895\n",
      "训练代数：1896/2000，用时4.0s，本轮分类准确率57.4%，本轮Loss值：4.0287267720976825\n",
      "训练代数：1897/2000，用时4.0s，本轮分类准确率58.1%，本轮Loss值：3.59452199642993\n",
      "训练代数：1898/2000，用时4.0s，本轮分类准确率58.4%，本轮Loss值：4.078214229062089\n",
      "训练代数：1899/2000，用时4.0s，本轮分类准确率59.2%，本轮Loss值：3.7259964482147723\n",
      "训练代数：1900/2000，用时3.9s，本轮分类准确率59.3%，本轮Loss值：4.341694220388055\n",
      "训练代数：1901/2000，用时4.0s，本轮分类准确率59.2%，本轮Loss值：3.3677694933379656\n",
      "训练代数：1902/2000，用时3.9s，本轮分类准确率59.3%，本轮Loss值：3.0363547174694787\n",
      "训练代数：1903/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.644750049895612\n",
      "训练代数：1904/2000，用时3.9s，本轮分类准确率58.6%，本轮Loss值：3.4948654766056535\n",
      "训练代数：1905/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.5243014949574105\n",
      "训练代数：1906/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.4917624029851853\n",
      "训练代数：1907/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.4657527112443605\n",
      "训练代数：1908/2000，用时4.0s，本轮分类准确率58.0%，本轮Loss值：3.0339364919953256\n",
      "训练代数：1909/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：3.5232209548402325\n",
      "训练代数：1910/2000，用时3.9s，本轮分类准确率58.8%，本轮Loss值：3.4623545418550323\n",
      "训练代数：1911/2000，用时4.0s，本轮分类准确率59.0%，本轮Loss值：3.557452588591269\n",
      "训练代数：1912/2000，用时4.0s，本轮分类准确率59.3%，本轮Loss值：3.1551123546110347\n",
      "训练代数：1913/2000，用时4.0s，本轮分类准确率58.1%，本轮Loss值：3.737267810982874\n",
      "训练代数：1914/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.9792931309832795\n",
      "训练代数：1915/2000，用时4.1s，本轮分类准确率59.8%，本轮Loss值：3.1051288523752874\n",
      "训练代数：1916/2000，用时4.1s，本轮分类准确率58.2%，本轮Loss值：3.7473601234702043\n",
      "训练代数：1917/2000，用时4.1s，本轮分类准确率58.9%，本轮Loss值：4.077548472423748\n",
      "训练代数：1918/2000，用时4.1s，本轮分类准确率59.1%，本轮Loss值：3.8586324751800474\n",
      "训练代数：1919/2000，用时4.1s，本轮分类准确率58.6%，本轮Loss值：3.676486913906973\n",
      "训练代数：1920/2000，用时4.1s，本轮分类准确率58.9%，本轮Loss值：3.8801179956907648\n",
      "训练代数：1921/2000，用时4.2s，本轮分类准确率59.6%，本轮Loss值：2.8856201110026034\n",
      "训练代数：1922/2000，用时4.2s，本轮分类准确率58.7%，本轮Loss值：4.004772312997292\n",
      "训练代数：1923/2000，用时4.1s，本轮分类准确率59.4%，本轮Loss值：3.174591988572254\n",
      "训练代数：1924/2000，用时4.1s，本轮分类准确率56.1%，本轮Loss值：3.496196982035235\n",
      "训练代数：1925/2000，用时4.1s，本轮分类准确率59.1%，本轮Loss值：3.5598280017287633\n",
      "训练代数：1926/2000，用时4.1s，本轮分类准确率58.7%，本轮Loss值：3.1011978822754003\n",
      "训练代数：1927/2000，用时4.2s，本轮分类准确率58.3%，本轮Loss值：3.5910431245342465\n",
      "训练代数：1928/2000，用时4.2s，本轮分类准确率58.9%，本轮Loss值：2.9315669734734855\n",
      "训练代数：1929/2000，用时4.1s，本轮分类准确率59.8%，本轮Loss值：3.1651790815062055\n",
      "训练代数：1930/2000，用时4.1s，本轮分类准确率58.8%，本轮Loss值：3.0672506082638393\n",
      "训练代数：1931/2000，用时4.1s，本轮分类准确率56.9%，本轮Loss值：4.071029778668663\n",
      "训练代数：1932/2000，用时4.1s，本轮分类准确率59.1%，本轮Loss值：3.557156206848137\n",
      "训练代数：1933/2000，用时4.3s，本轮分类准确率57.9%，本轮Loss值：4.161011305496407\n",
      "训练代数：1934/2000，用时4.1s，本轮分类准确率57.8%，本轮Loss值：3.324739180603418\n",
      "训练代数：1935/2000，用时4.1s，本轮分类准确率58.0%，本轮Loss值：3.3809676889100317\n",
      "训练代数：1936/2000，用时4.1s，本轮分类准确率58.0%，本轮Loss值：3.9574456328764938\n",
      "训练代数：1937/2000，用时4.0s，本轮分类准确率58.7%，本轮Loss值：3.54854093726228\n",
      "训练代数：1938/2000，用时4.0s，本轮分类准确率59.5%，本轮Loss值：4.174843555339882\n",
      "训练代数：1939/2000，用时4.0s，本轮分类准确率60.1%，本轮Loss值：3.5147017928471938\n",
      "训练代数：1940/2000，用时4.0s，本轮分类准确率60.0%，本轮Loss值：3.8824362461008435\n",
      "训练代数：1941/2000，用时4.1s，本轮分类准确率58.7%，本轮Loss值：3.7966801119202698\n",
      "训练代数：1942/2000，用时4.2s，本轮分类准确率59.0%，本轮Loss值：4.10937911605753\n",
      "训练代数：1943/2000，用时4.1s，本轮分类准确率58.8%，本轮Loss值：4.090010650145384\n",
      "训练代数：1944/2000，用时4.1s，本轮分类准确率58.5%，本轮Loss值：4.454745482900967\n",
      "训练代数：1945/2000，用时4.2s，本轮分类准确率59.2%，本轮Loss值：4.0042613649704375\n",
      "训练代数：1946/2000，用时4.0s，本轮分类准确率59.0%，本轮Loss值：3.6843047615891797\n",
      "训练代数：1947/2000，用时4.0s，本轮分类准确率58.3%，本轮Loss值：3.222908714676784\n",
      "训练代数：1948/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：4.140180266782178\n",
      "训练代数：1949/2000，用时4.2s，本轮分类准确率59.6%，本轮Loss值：3.2061958907033157\n",
      "训练代数：1950/2000，用时4.1s，本轮分类准确率60.1%，本轮Loss值：3.211463352940638\n",
      "训练代数：1951/2000，用时4.1s，本轮分类准确率59.5%，本轮Loss值：3.7284057445694443\n",
      "训练代数：1952/2000，用时4.1s，本轮分类准确率58.8%，本轮Loss值：3.676110103479195\n",
      "训练代数：1953/2000，用时4.1s，本轮分类准确率58.9%，本轮Loss值：4.188221929110113\n",
      "训练代数：1954/2000，用时4.1s，本轮分类准确率59.3%，本轮Loss值：3.6300250159842533\n",
      "训练代数：1955/2000，用时4.1s，本轮分类准确率58.2%，本轮Loss值：4.1590616843644055\n",
      "训练代数：1956/2000，用时4.1s，本轮分类准确率59.9%，本轮Loss值：3.5280084631986286\n",
      "训练代数：1957/2000，用时4.1s，本轮分类准确率59.2%，本轮Loss值：3.5713520705322397\n",
      "训练代数：1958/2000，用时4.1s，本轮分类准确率60.0%，本轮Loss值：3.417709752462687\n",
      "训练代数：1959/2000，用时4.1s，本轮分类准确率59.8%，本轮Loss值：3.245680698008047\n",
      "训练代数：1960/2000，用时4.1s，本轮分类准确率58.6%，本轮Loss值：3.7093695420072748\n",
      "训练代数：1961/2000，用时4.0s，本轮分类准确率59.5%，本轮Loss值：3.08579924132176\n",
      "训练代数：1962/2000，用时4.0s，本轮分类准确率59.5%，本轮Loss值：4.1975322832383455\n",
      "训练代数：1963/2000，用时4.0s，本轮分类准确率58.3%，本轮Loss值：3.566891377832454\n",
      "训练代数：1964/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：3.5413865139611347\n",
      "训练代数：1965/2000，用时4.0s，本轮分类准确率57.8%，本轮Loss值：3.5426412532377527\n",
      "训练代数：1966/2000，用时4.0s，本轮分类准确率59.9%，本轮Loss值：3.6551994729629684\n",
      "训练代数：1967/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：4.703652870128389\n",
      "训练代数：1968/2000，用时4.0s，本轮分类准确率57.9%，本轮Loss值：3.7810649866841595\n",
      "训练代数：1969/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.8914908092067555\n",
      "训练代数：1970/2000，用时4.0s，本轮分类准确率59.7%，本轮Loss值：4.499633713312301\n",
      "训练代数：1971/2000，用时4.0s，本轮分类准确率58.9%，本轮Loss值：3.569253563935775\n",
      "训练代数：1972/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.2373686660326593\n",
      "训练代数：1973/2000，用时4.0s，本轮分类准确率59.0%，本轮Loss值：2.8438937534863697\n",
      "训练代数：1974/2000，用时4.0s，本轮分类准确率59.7%，本轮Loss值：3.5864706331921044\n",
      "训练代数：1975/2000，用时4.0s，本轮分类准确率59.5%，本轮Loss值：3.6809516338070525\n",
      "训练代数：1976/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：3.4859299130631145\n",
      "训练代数：1977/2000，用时4.0s，本轮分类准确率59.3%，本轮Loss值：3.693313203835814\n",
      "训练代数：1978/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：2.8215677492995668\n",
      "训练代数：1979/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：2.8912376854758635\n",
      "训练代数：1980/2000，用时4.1s，本轮分类准确率59.6%，本轮Loss值：3.6806354401416\n",
      "训练代数：1981/2000，用时4.0s，本轮分类准确率59.1%，本轮Loss值：3.797050175150275\n",
      "训练代数：1982/2000，用时4.0s，本轮分类准确率59.5%，本轮Loss值：4.072000144750072\n",
      "训练代数：1983/2000，用时4.0s，本轮分类准确率59.9%，本轮Loss值：3.613251800569168\n",
      "训练代数：1984/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：3.6937658395606716\n",
      "训练代数：1985/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.843172933878182\n",
      "训练代数：1986/2000，用时4.0s，本轮分类准确率59.3%，本轮Loss值：4.286858373096362\n",
      "训练代数：1987/2000，用时4.0s，本轮分类准确率60.0%，本轮Loss值：3.4915680284865145\n",
      "训练代数：1988/2000，用时4.0s，本轮分类准确率59.9%，本轮Loss值：3.976707066937871\n",
      "训练代数：1989/2000，用时4.0s，本轮分类准确率60.3%，本轮Loss值：3.9433582285871465\n",
      "训练代数：1990/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.439798780215736\n",
      "训练代数：1991/2000，用时4.0s，本轮分类准确率59.2%，本轮Loss值：4.276810920888386\n",
      "训练代数：1992/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.913306032534467\n",
      "训练代数：1993/2000，用时4.0s，本轮分类准确率60.0%，本轮Loss值：3.6606568202714356\n",
      "训练代数：1994/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.575877666374018\n",
      "训练代数：1995/2000，用时4.0s，本轮分类准确率59.6%，本轮Loss值：2.9416608908622037\n",
      "训练代数：1996/2000，用时4.0s，本轮分类准确率59.9%，本轮Loss值：4.296495503976635\n",
      "训练代数：1997/2000，用时4.0s，本轮分类准确率60.0%，本轮Loss值：3.4641976769159926\n",
      "训练代数：1998/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.8784824781356577\n",
      "训练代数：1999/2000，用时4.0s，本轮分类准确率59.8%，本轮Loss值：3.622564516547669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练代数：2000/2000，用时4.0s，本轮分类准确率60.1%，本轮Loss值：3.3004314472460576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SongTi\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './result/Agent_Loss.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss值\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 86\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./result/Agent_Loss.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/drl/lib/python3.10/site-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/drl/lib/python3.10/site-packages/matplotlib/figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3374\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3375\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   3376\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m-> 3378\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/drl/lib/python3.10/site-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/miniconda3/envs/drl/lib/python3.10/site-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m~/miniconda3/envs/drl/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/drl/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 458\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/drl/lib/python3.10/site-packages/matplotlib/image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/drl/lib/python3.10/site-packages/PIL/Image.py:2436\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2436\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2439\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './result/Agent_Loss.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============== 训练预设 =================================\n",
    "import matplotlib.pyplot as plt\n",
    "import time as tm\n",
    "\n",
    "# =============== 环境设置 =================================\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"使用设备{device}进行训练\")\n",
    "\n",
    "env = DiagnoseEnv(dataloader)  # 环境建立\n",
    "env.togpu(device)  # 迁移到GPU\n",
    "n_states = env.observation_space()[0]  # 观测空间\n",
    "n_actions = env.action_space()  # 动作空间\n",
    "\n",
    "max_episodes = 2000  # 设置训练轮数\n",
    "max_steps = 80  # 设置最大步数\n",
    "\n",
    "complete_episodes = 0  # 完成的代数\n",
    "finished_flag = False  # 结束标志\n",
    "stop_flag = 1\n",
    "\n",
    "# =============== 模型设置 =================================\n",
    "\n",
    "agent = Agent(n_states, n_actions, eta, gamma, capacity, batch_size)  # 建立智能体\n",
    "agent.togpu(device)  # 迁移到GPU\n",
    "loss_e = 0  # 代内loss记录值\n",
    "correct = 0 # 正确分类记录值\n",
    "loss_temp = []  # 损失值记录缓存\n",
    "correct_temp = []  # 准确率记录缓存\n",
    "losses = []  # 记录损失值\n",
    "corrects = []  # 记录准确率\n",
    "\n",
    "# =============== 开始训练 =================================\n",
    "# 填入记忆\n",
    "state = env.reset()  # 重置环境\n",
    "state = state.to(device) # 迁移到GPU\n",
    "for get_memory in range(batch_size):\n",
    "    action = agent.choose_action(state, get_memory)  # 按状态和代数选择动作\n",
    "    action.to(device) # 移动到GPU\n",
    "    next_state, reward = env.step(action)  # 进行动作转化，拿下一个状态\n",
    "    next_state.to(device)\n",
    "    reward.to(device)\n",
    "    agent.memorize(state, action, next_state, reward)  # 记忆回放\n",
    "print(\"回放缓存已满，开始训练\")\n",
    "\n",
    "for episode in range(max_episodes):  # 训练轮数\n",
    "    epi_start = tm.time()  # 本轮开始时间\n",
    "    state = env.reset()  # 重置环境\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        \n",
    "        if episode <= 500:\n",
    "            episode_in = episode\n",
    "        else:\n",
    "            episode_in = episode / (episode // max_steps)\n",
    "        action = agent.choose_action(state, episode_in)  # 按状态和代数选择动作\n",
    "        action.to(device)\n",
    "        next_state, reward = env.step(action)  # 进行动作转化，拿下一个状态\n",
    "        next_state.to(device)\n",
    "        reward.to(device)\n",
    "        temp_reward = reward\n",
    "            \n",
    "        agent.memorize(state, action, next_state, reward)  # 记忆回放\n",
    "        loss_e = agent.update_q_function()  # 更新Q值\n",
    "        state = next_state  # 进入下个状态\n",
    "        loss_temp.append(loss_e)  # Loss值填入缓存\n",
    "        correct = (batch_size + reward) / 2\n",
    "        correct_temp.append(correct / batch_size * 100)  # 准确率填入缓存\n",
    "        \n",
    "    epi_end = tm.time()  # 本轮结束时间\n",
    "    print(f\"训练代数：{episode+1}/{max_episodes}，用时{(epi_end-epi_start):.1f}s，本轮分类准确率{sum(correct_temp) / len(correct_temp):.1f}%，本轮Loss值：{sum(loss_temp) / len(loss_temp)}\")\n",
    "    losses.append(sum(loss_temp) / len(loss_temp))  # 记录代内loss值\n",
    "    corrects.append(sum(correct_temp) / len(correct_temp))\n",
    "    loss_temp = []  # 清空缓存\n",
    "    correct_temp = []  # 清空缓存\n",
    "    \n",
    "    \n",
    "plt.figure()\n",
    "plt.rcParams['font.sans-serif'] = ['SongTi'] # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n",
    "epis = [i + 1 for i in range(len(losses))]\n",
    "plt.plot(epis, losses)\n",
    "plt.title(\"Loss曲线\")\n",
    "plt.xlabel(\"代数\")\n",
    "plt.ylabel(\"Loss值\")\n",
    "plt.show()\n",
    "plt.savefig(\"./result/Agent_Loss.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d23363319ceb18",
   "metadata": {},
   "source": [
    "# 模型改进方案\n",
    "\n",
    "1.对比使用预训练权重和不使用预训练权重的区别\n",
    "\n",
    "2.利用reward值来判断分类正确的次数。具体做法：设置temp值，获取当前reward，到下一次训练时再获取一次reward，判断if reward > gamma * temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d23933d7f9b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "loglosses = [np.log10(loss) for loss in losses]\n",
    "plt.figure()\n",
    "plt.plot(epis, loglosses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl",
   "language": "python",
   "name": "drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
