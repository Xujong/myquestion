{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 提取DQN进行训练\n",
    "\n",
    "将DQN网络单独提取出来以测定性能，研究是网络的问题或者是模型的问题"
   ],
   "id": "c89093b74a358185"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T12:32:31.855154Z",
     "start_time": "2024-04-28T12:32:29.549895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 包引用\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "from torchvision.models import resnet34, ResNet34_Weights"
   ],
   "id": "584be60bd9232fae",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 进行模型定义\n",
    "\n",
    "此处直接使用DQN的模型"
   ],
   "id": "304914768efcc615"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T16:06:20.494586Z",
     "start_time": "2024-04-28T16:06:20.477079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions_0):  # 考虑注入n_states\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # 添加一个卷积层，用于数据转化\n",
    "        # self.fc1 = nn.Conv2d(in_channels=8, out_channels=3, kernel_size=12, stride=1, padding=1, groups=1, bias=True)\n",
    "        # 定义第一个卷积核，将8通道234*234数据处理成3通道112*112数据，以输入ResNet-18网络\n",
    "        # 参数定义：入通道8，出通道3，卷积核数量64，步长1，边缘1，不分组，添加可学习偏置\n",
    "        # 利用F.interpolate函数动态调整图片大小为224*224，采用bilinear插值，在前向传播中实现\n",
    "        \n",
    "        # 定义激活函数\n",
    "        # self.relu = nn.ReLU(inplace=True)  # 指定的激活函数ReLU\n",
    "        \n",
    "        # 定义ResNet-34网络\n",
    "        self.resnet = resnet34(weights=ResNet34_Weights.DEFAULT)  # 引入ResNet-34\n",
    "        for param in self.resnet.parameters():  # 遍历预训练的ResNet-18中的参数\n",
    "            param.requires_grad = False  # 冻结预训练的ResNet-18中的参数\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, n_actions_0)\n",
    "        )    # 重新定义网络的全连接层\n",
    "        for param in self.resnet.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    def forward(self, x):  # 前向传播过程\n",
    "        # 输入：以batch_size作为批次大小的8通道512*512图像，shape：(batch_size, 8, 512, 512)\n",
    "        # 输出：以batch_size作为批次大小的分类（动作）数据，one-hot形式，shape：(batch_size, n_actions)\n",
    "        # x = self.fc1(x)\n",
    "        # x = F.interpolate(x, size=224, mode='bilinear', align_corners=False)\n",
    "        # x = self.relu(x)\n",
    "        x = self.resnet(x)  # 使用网络处理输入\n",
    "        return x  # 输出ResNet-18网络的输出"
   ],
   "id": "ca8f83975fe00ac2",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T16:08:51.882483Z",
     "start_time": "2024-04-28T16:08:51.876945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 超参数定义\n",
    "num_classes = 10\n",
    "batch_size = 16\n",
    "num_epoches = 1000\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "4514b2692e9cfe0",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T12:32:31.932358Z",
     "start_time": "2024-04-28T12:32:31.917715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据处理函数定义\n",
    "\n",
    "def data_processing(data_processed, label_processed, batch_size_0):\n",
    "    # 输入数据：数据，这组数据的类别标签，及训练批次数据（用于适配训练方式）\n",
    "    \n",
    "    channels, freq, time = data_processed.shape  # 获取时频维度大小\n",
    "    parts_num = time // (freq * 2)  # 确定分割的块数\n",
    "    parts_num = (parts_num // batch_size_0) * batch_size_0 # 根据训练批次重新确定分割方式\n",
    "    \n",
    "    data_striped = []  # 定义数据存储器\n",
    "    data_label = [label_processed for _ in range(parts_num)]\n",
    "    \n",
    "    for i in range(parts_num):  # 按块数分割\n",
    "        data_striped.append(data_processed[:, :, i * freq:(i + 1) * freq])  # 向存储器里添加分割的数据\n",
    "\n",
    "    # 上面的数据处理过程抛弃了多余的无法形成格式的数据块\n",
    "    # 返回分割好的数据列表\n",
    "    return data_striped, data_label\n",
    "\n",
    "# 这个函数在使用时要分别获取数据和索引已知对应的标签。\n",
    "# 本任务中数据的维度较高，二者的维度不同导致无法合并。"
   ],
   "id": "d20f94422a94ff6d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:42:57.901540Z",
     "start_time": "2024-04-28T14:42:38.271091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 20Hz-0数据加载部分\n",
    "# 本部分从./dataset/gearset中加载数据并添加分类标签\n",
    "\n",
    "# 文件路径列表\n",
    "\n",
    "files_20_0 = ['./dataset/gearset/Chipped_20_0.npy', './dataset/gearset/Health_20_0.npy', './dataset/gearset/Miss_20_0.npy', './dataset/gearset/Root_20_0.npy', './dataset/gearset/Surface_20_0.npy']\n",
    "\n",
    "files_30_2 = ['./dataset/gearset/Chipped_30_2.npy', './dataset/gearset/Miss_30_2.npy', './dataset/gearset/Root_30_2.npy', './dataset/gearset/Surface_30_2.npy']\n",
    "\n",
    "# files_30_2 = ['./dataset/gearset/Chipped_30_2.npy', './dataset/gearset/Health_30_2.npy']\n",
    "# 标签列表\n",
    "\n",
    "labels = np.array([1, 2, 3, 4, 5])\n",
    "# 对应的类别：['Chipped', 'Health', 'Miss', 'Root', 'Surface']\n",
    "\n",
    "# 指定所用路径\n",
    "\n",
    "files = files_30_2\n",
    "\n",
    "# 数据寄存器\n",
    "\n",
    "data = []  # 定义初始化列表型数据集\n",
    "label = []  # 定义初始化标签集\n",
    "data_sample = []\n",
    "label_sample = []\n",
    "\n",
    "# 装载数据\n",
    "\n",
    "for file in range(len(files)):\n",
    "    data_sample, label_sample = data_processing(np.load(files[file]), labels[file], batch_size)  # 加载数据并整理数据形式\n",
    "    sample_range = (len(label_sample) // batch_size) - 1  # 取样范围\n",
    "    sample_num = (len(label_sample) // (batch_size * 2)) // batch_size * batch_size  # 取样数量\n",
    "    random_index = random.sample(range(0, sample_range), sample_num)  # 制备索引，进行随机取样\n",
    "    for index in random_index:\n",
    "        data_sam = data_sample[index]\n",
    "        label_sam = label_sample[index]\n",
    "        data.append(data_sam) # 合并到总的数据集里\n",
    "        label.append(label_sam)  # 合并到总的分类集里\n",
    "\n",
    "# 列表转换成数组\n",
    "\n",
    "data = np.array(data)  # 数据数组\n",
    "label = np.array(label)  # 标签数组\n",
    "\n",
    "# 将数据转换为PyTorch的张量\n",
    "\n",
    "dataset = torch.tensor(data)\n",
    "labelset = torch.tensor(label, dtype=torch.long).unsqueeze(1)\n",
    "\n",
    "# 创建数据加载器\n",
    "\n",
    "dataset_tensored = TensorDataset(dataset, labelset)  # 数据集合并，信息获取：data, label = dataset[0]\n",
    "dataloader = DataLoader(dataset_tensored, batch_size=batch_size, shuffle=True)  # 将数据加载为批次\n"
   ],
   "id": "e4e79f16c7bfc4",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 标准数据集测试\n",
   "id": "6f0924cf0000d5df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T16:09:16.033678Z",
     "start_time": "2024-04-28T16:09:15.552999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 加载CIFAR-10数据集\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./dataset', train=True, download=False, transform=transform)\n",
    "# 创建DataLoader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,shuffle=True)"
   ],
   "id": "b6862e44ffeb8a36",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T16:09:19.616453Z",
     "start_time": "2024-04-28T16:09:19.592527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_test = next(iter(trainloader))\n",
    "data_t = data_test[0]\n",
    "label_t = data_test[1]\n",
    "print(data_t.shape)\n",
    "print(label_t)"
   ],
   "id": "88a4d693612052bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n",
      "tensor([7, 0, 7, 7, 1, 1, 9, 2, 5, 4, 0, 7, 8, 2, 7, 9])\n"
     ]
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 模型初始化",
   "id": "15ce7e77a2ad9e41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T16:06:28.388166Z",
     "start_time": "2024-04-28T16:06:28.076093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = DQN(num_classes)\n",
    "model = model.to(device)\n",
    "criterion = F.mse_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "c5940029b0746cf4",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T16:25:31.309562Z",
     "start_time": "2024-04-28T16:19:05.793662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "acc = []\n",
    "loss_s = []\n",
    "# model = DQN(num_classes)\n",
    "# model.load_state_dict(torch.load('model.pth')) \n",
    "# model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    model.train()\n",
    "    \n",
    "    dataiter = iter(trainloader)\n",
    "    # for batch_idx, batch in enumerate(trainloader):\n",
    "    for step in range(50):\n",
    "        batch = next(dataiter)\n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        output = model(images)\n",
    "        output_get = output.max(1)[1].view(batch_size, 1)# .add_(1)\n",
    "        output_get = output_get.to(dtype=torch.float32)\n",
    "        labels_get = labels.to(dtype=torch.float32)\n",
    "        loss = criterion(output_get.squeeze(1), labels_get)\n",
    "        loss_temp = loss.detach()\n",
    "    \n",
    "        # 后向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 检查正确率\n",
    "        index_corrects = (output_get.squeeze(1) == labels_get)\n",
    "        num_corrects = torch.sum(index_corrects)\n",
    "        acc_temp = 100.0 * num_corrects / batch_size\n",
    "        \n",
    "        acc.append(acc_temp)\n",
    "        loss_s.append(loss_temp)\n",
    "        \n",
    "    model.eval()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'代数：{epoch+1}/{num_epoches}，正确率：{sum(acc) / len(acc): .2f}%，Loss：{sum(loss_s) / len(loss_s): .5f}')\n",
    "        acc = []\n",
    "        loss_s = []\n",
    "\n",
    "torch.save(model.state_dict(), './model.pth')"
   ],
   "id": "97e7fdb077510a77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "代数：100/1000，正确率： 9.48%，Loss： 23.71995\n",
      "代数：200/1000，正确率： 9.48%，Loss： 23.67736\n",
      "代数：300/1000，正确率： 9.41%，Loss： 23.76876\n",
      "代数：400/1000，正确率： 9.67%，Loss： 23.71010\n",
      "代数：500/1000，正确率： 9.70%，Loss： 23.62358\n",
      "代数：600/1000，正确率： 9.50%，Loss： 23.74121\n",
      "代数：700/1000，正确率： 9.51%，Loss： 23.76466\n",
      "代数：800/1000，正确率： 9.54%，Loss： 23.76806\n",
      "代数：900/1000，正确率： 9.28%，Loss： 23.78275\n",
      "代数：1000/1000，正确率： 9.60%，Loss： 23.67884\n"
     ]
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T15:30:14.216456Z",
     "start_time": "2024-04-28T15:30:13.683343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_model = DQN(num_classes)\n",
    "test_model.load_state_dict(torch.load('model.pth')) \n",
    "test_model = test_model.to(device)\n",
    "test_dl = next(iter(dataloader))\n",
    "test_data, test_label = test_dl[0].to(device), test_dl[1].to(device)\n",
    "test_output = test_model(test_data).max(1)[1].view(1, batch_size).add_(1)\n",
    "print(test_output)\n",
    "print(test_label.view(1, batch_size))"
   ],
   "id": "c5637f342affe00f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 1, 4, 4, 1, 4, 4, 4, 4, 4, 4, 2, 3, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 3,\n",
      "         4, 2, 4, 4, 4, 2, 2, 4]], device='cuda:0')\n",
      "tensor([[2, 2, 4, 4, 3, 3, 3, 4, 4, 1, 1, 2, 2, 4, 4, 4, 3, 2, 3, 3, 3, 4, 2, 1,\n",
      "         3, 2, 4, 4, 4, 4, 3, 1]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T16:18:23.742828Z",
     "start_time": "2024-04-28T16:18:23.736293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(output_get.shape)\n",
    "print(labels_get.shape)"
   ],
   "id": "493a825b2afad09d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "execution_count": 157
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
